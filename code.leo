<?xml version="1.0" encoding="UTF-8"?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="57" clone_windows="0"/>
<globals body_outline_ratio="0.267906976744">
	<global_window_position top="70" left="86" height="636" width="1075"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="aum.20060506215300" a="E"><vh>PyFCP</vh></v>
<v t="aum.20060516115529"><vh>TODO</vh></v>
<v t="aum.20060528180449" a="E"><vh>notes</vh>
<v t="aum.20060528180449.1"><vh>freedisk</vh></v>
</v>
<v t="aum.20060513180215" a="E"><vh>Release files</vh>
<v t="aum.20060513180215.1" tnodeList="aum.20060513180215.1"><vh>@nosent README</vh></v>
<v t="aum.20060522200735" tnodeList="aum.20060522200735"><vh>@nosent README.freedisk</vh></v>
<v t="aum.20060513180716" tnodeList="aum.20060513180716"><vh>@nosent INSTALL</vh></v>
<v t="aum.20060513180932" tnodeList="aum.20060513180932"><vh>@nosent AUTHORS</vh></v>
<v t="aum.20060513181137" tnodeList="aum.20060513181137"><vh>@nosent COPYING</vh></v>
<v t="aum.20060513181205" tnodeList="aum.20060513181205"><vh>@nosent BUGS</vh></v>
<v t="aum.20060513181313" tnodeList="aum.20060513181313"><vh>@nosent CHANGELOG</vh></v>
<v t="aum.20060513182312" tnodeList="aum.20060513182312"><vh>@nosent release.py</vh></v>
<v t="aum.20060515193950" tnodeList="aum.20060515193950"><vh>@nosent setup.py</vh></v>
</v>
<v t="aum.20060514232355"><vh>Tutorials</vh>
<v t="aum.20060514232355.1" tnodeList="aum.20060514232355.1"><vh>@nosent tutorial.py</vh></v>
</v>
<v t="aum.20060513073239" a="E"><vh>Package 'fcp'</vh>
<v t="aum.20060516141235" tnodeList="aum.20060516141235"><vh>@nosent __init__.py</vh></v>
<v t="aum.20060506215707" a="E" tnodeList="aum.20060506215707,aum.20060506215707.1,aum.20060506220237,aum.20060506215707.2,aum.20060506215707.3,aum.20060607085345,aum.20060506220237.1,aum.20060506220237.2,aum.20060514223716,aum.20060506231352.1,aum.20060506231352,aum.20060507003931,aum.20060511001853,aum.20060521180804,aum.20060506224238,aum.20060514224855,aum.20060514224919,aum.20060514225725,aum.20060514223936,aum.20060514223822,aum.20060514223845,aum.20060514224020,aum.20060514124642,aum.20060514191601,aum.20060511205201,aum.20060506232639,aum.20060506232639.1,aum.20060511222538,aum.20060512101715,aum.20060511205201.1,aum.20060511205201.2,aum.20060506223545,aum.20060506224238.1,aum.20060506231352.2,aum.20060506220856,aum.20060506222005,aum.20060507124316,aum.20060511103841,aum.20060511103841.1,aum.20060511103952,aum.20060511103952.1,aum.20060604204143,aum.20060514134235,aum.20060512181209,aum.20060514162944,aum.20060514124934,aum.20060512102840,aum.20060514164052,aum.20060509184020.1,aum.20060509184020.2,aum.20060509224119,aum.20060509224221,aum.20060603170554,aum.20060603231840,aum.20060603231840.1,aum.20060603231840.2"><vh>@nosent node.py</vh>
<v t="aum.20060506215707.1"><vh>imports</vh></v>
<v t="aum.20060506220237"><vh>exceptions</vh></v>
<v t="aum.20060506215707.2"><vh>globals</vh></v>
<v t="aum.20060506215707.3" a="E"><vh>class FCPNodeConnection</vh>
<v t="aum.20060607085345"><vh>attribs</vh></v>
<v t="aum.20060506220237.1"><vh>__init__</vh></v>
<v t="aum.20060506220237.2"><vh>__del__</vh></v>
<v t="aum.20060514223716" a="E"><vh>FCP Primitives</vh>
<v t="aum.20060506231352.1"><vh>genkey</vh></v>
<v t="aum.20060506231352"><vh>get</vh></v>
<v t="aum.20060507003931"><vh>put</vh></v>
<v t="aum.20060511001853" a="V"><vh>putdir</vh></v>
<v t="aum.20060521180804"><vh>invertprivate</vh></v>
</v>
<v t="aum.20060506224238" a="E"><vh>Other High Level Methods</vh>
<v t="aum.20060514224855"><vh>listenGlobal</vh></v>
<v t="aum.20060514224919"><vh>ignoreGlobal</vh></v>
<v t="aum.20060514225725"><vh>purgePersistentJobs</vh></v>
<v t="aum.20060514223936"><vh>getAllJobs</vh></v>
<v t="aum.20060514223822"><vh>getPersistentJobs</vh></v>
<v t="aum.20060514223845"><vh>getGlobalJobs</vh></v>
<v t="aum.20060514224020"><vh>getTransientJobs</vh></v>
<v t="aum.20060514124642"><vh>refreshPersistentRequests</vh></v>
<v t="aum.20060514191601"><vh>setVerbosity</vh></v>
<v t="aum.20060511205201"><vh>shutdown</vh></v>
</v>
<v t="aum.20060506232639" a="E"><vh>Manager Thread</vh>
<v t="aum.20060506232639.1"><vh>_mgrThread</vh></v>
<v t="aum.20060511222538"><vh>_msgIncoming</vh></v>
<v t="aum.20060512101715"><vh>_submitCmd</vh></v>
<v t="aum.20060511205201.1"><vh>_on_rxMsg</vh></v>
<v t="aum.20060511205201.2"><vh>_on_clientReq</vh></v>
</v>
<v t="aum.20060506223545" a="E"><vh>Low Level Methods</vh>
<v t="aum.20060506224238.1"><vh>_hello</vh></v>
<v t="aum.20060506231352.2"><vh>_getUniqueId</vh></v>
<v t="aum.20060506220856"><vh>_txMsg</vh></v>
<v t="aum.20060506222005"><vh>_rxMsg</vh></v>
<v t="aum.20060507124316"><vh>_log</vh></v>
</v>
</v>
<v t="aum.20060511103841" a="E"><vh>class JobTicket</vh>
<v t="aum.20060511103841.1"><vh>__init__</vh></v>
<v t="aum.20060511103952"><vh>isComplete</vh></v>
<v t="aum.20060511103952.1"><vh>wait</vh></v>
<v t="aum.20060604204143"><vh>waitTillReqSent</vh></v>
<v t="aum.20060514134235"><vh>getResult</vh></v>
<v t="aum.20060512181209"><vh>callback</vh></v>
<v t="aum.20060514162944"><vh>cancel</vh></v>
<v t="aum.20060514124934"><vh>_appendMsg</vh></v>
<v t="aum.20060512102840"><vh>_putResult</vh></v>
<v t="aum.20060514164052"><vh>__repr__</vh></v>
</v>
<v t="aum.20060509184020.1" a="E"><vh>util funcs</vh>
<v t="aum.20060509184020.2"><vh>toBool</vh></v>
<v t="aum.20060509224119"><vh>readdir</vh></v>
<v t="aum.20060509224221"><vh>guessMimetype</vh></v>
<v t="aum.20060603170554"><vh>uriIsPrivate</vh></v>
<v t="aum.20060603231840" a="E"><vh>base64 stuff</vh>
<v t="aum.20060603231840.1"><vh>base64encode</vh></v>
<v t="aum.20060603231840.2"><vh>base64decode</vh></v>
</v>
</v>
</v>
<v t="aum.20060511101147" tnodeList="aum.20060511101147,aum.20060511113333,aum.20060511113333.1,aum.20060516143534,aum.20060511114439,aum.20060511114439.1,aum.20060512150118,aum.20060511114439.2,aum.20060511114604,aum.20060511114604.1,aum.20060511120059,aum.20060516184736,aum.20060516192715,aum.20060516200626,aum.20060516194958,aum.20060516194016,aum.20060511113333.3,aum.20060513071956,aum.20060507124316,aum.20060511130507,aum.20060516142202,aum.20060511120024"><vh>@nosent sitemgr.py</vh>
<v t="aum.20060511113333"><vh>imports</vh></v>
<v t="aum.20060511113333.1"><vh>config</vh></v>
<v t="aum.20060516143534"><vh>globals</vh></v>
<v t="aum.20060511114439" a="E"><vh>class SiteMgr</vh>
<v t="aum.20060511114439.1"><vh>__init__</vh></v>
<v t="aum.20060512150118"><vh>__del__</vh></v>
<v t="aum.20060511114439.2"><vh>createConfig</vh></v>
<v t="aum.20060511114604"><vh>loadConfig</vh></v>
<v t="aum.20060511114604.1"><vh>saveConfig</vh></v>
<v t="aum.20060511120059"><vh>createNode</vh></v>
<v t="aum.20060516184736"><vh>hasSite</vh></v>
<v t="aum.20060516192715"><vh>addSite</vh></v>
<v t="aum.20060516200626"><vh>removeSite</vh></v>
<v t="aum.20060516194958"><vh>getSiteInfo</vh></v>
<v t="aum.20060516194016"><vh>getSiteNames</vh></v>
<v t="aum.20060511113333.3"><vh>update</vh></v>
<v t="aum.20060513071956"><vh>shutdown</vh></v>
<v t="aum.20060507124316"><vh>_log</vh></v>
</v>
<v t="aum.20060511130507"><vh>help</vh></v>
<v t="aum.20060516142202"><vh>run</vh></v>
<v t="aum.20060511120024"><vh>mainline</vh></v>
</v>
<v t="aum.20060512172707" tnodeList="aum.20060512172707,aum.20060512172843,aum.20060512173027,aum.20060512175041,aum.20060512175041.1,aum.20060512175218,aum.20060507155016,aum.20060507162314,aum.20060507162314.2,aum.20060507162314.3,aum.20060507162543.1,aum.20060507195029,aum.20060507163143,aum.20060507154638,aum.20060507195029.1,aum.20060506224545"><vh>@nosent xmlrpc.py</vh>
<v t="aum.20060512172843"><vh>imports</vh></v>
<v t="aum.20060512173027"><vh>globals</vh></v>
<v t="aum.20060512175041" a="E"><vh>class FCPXMLRPCServer</vh>
<v t="aum.20060512175041.1"><vh>__init__</vh></v>
<v t="aum.20060512175218"><vh>run</vh></v>
</v>
<v t="aum.20060507155016" a="E"><vh>class FreenetXMLRPCRequestHandler</vh>
<v t="aum.20060507162314"><vh>__init__</vh></v>
<v t="aum.20060507162314.2"><vh>get</vh></v>
<v t="aum.20060507162314.3"><vh>put</vh></v>
<v t="aum.20060507162543.1"><vh>genkey</vh></v>
</v>
<v t="aum.20060507195029"><vh>usage</vh></v>
<v t="aum.20060507163143"><vh>testServer</vh></v>
<v t="aum.20060507154638"><vh>runServer</vh></v>
<v t="aum.20060507195029.1"><vh>main</vh></v>
<v t="aum.20060506224545"><vh>mainline</vh></v>
</v>
<v t="aum.20060528175118" tnodeList="aum.20060528175118,aum.20060528175118.1,aum.20060528175118.2,aum.20060528175118.3,aum.20060528175118.4,aum.20060528175118.5,aum.20060528175118.6,aum.20060528175118.7,aum.20060528175118.8,aum.20060528175118.9,aum.20060528175118.10,aum.20060528175118.11,aum.20060528175118.12,aum.20060528175118.13,aum.20060528175118.14,aum.20060528175118.15,aum.20060528175118.16,aum.20060528175118.17,aum.20060528175118.18,aum.20060528175118.19,aum.20060528175118.20,aum.20060603153411,aum.20060603160206,aum.20060528175118.21,aum.20060528175118.22,aum.20060528175118.23,aum.20060528175118.24"><vh>@file xmlobject.py</vh>
<v t="aum.20060528175118.1"><vh>imports</vh></v>
<v t="aum.20060528175118.2"><vh>globals</vh></v>
<v t="aum.20060528175118.3"><vh>exceptions</vh></v>
<v t="aum.20060528175118.4" a="E"><vh>class XMLFile</vh>
<v t="aum.20060528175118.5"><vh>__init__</vh></v>
<v t="aum.20060528175118.6"><vh>save</vh></v>
<v t="aum.20060528175118.7"><vh>saveAs</vh></v>
<v t="aum.20060528175118.8"><vh>toxml</vh></v>
<v t="aum.20060528175118.9"><vh>__len__</vh></v>
<v t="aum.20060528175118.10"><vh>__getitem__</vh></v>
</v>
<v t="aum.20060528175118.11" a="E"><vh>class XMLNode</vh>
<v t="aum.20060528175118.12"><vh>__init__</vh></v>
<v t="aum.20060528175118.13"><vh>_render</vh></v>
<v t="aum.20060528175118.14"><vh>__repr__</vh></v>
<v t="aum.20060528175118.15"><vh>__getattr__</vh></v>
<v t="aum.20060528175118.16"><vh>__setattr__</vh></v>
<v t="aum.20060528175118.17"><vh>_keys</vh></v>
<v t="aum.20060528175118.18"><vh>__len__</vh></v>
<v t="aum.20060528175118.19"><vh>__getitem__</vh></v>
<v t="aum.20060528175118.20"><vh>_addNode</vh></v>
<v t="aum.20060603153411"><vh>_getChild</vh></v>
<v t="aum.20060603160206"><vh>_delChild</vh></v>
<v t="aum.20060528175118.21"><vh>_addText</vh></v>
<v t="aum.20060528175118.22"><vh>_addComment</vh></v>
<v t="aum.20060528175118.23"><vh>_save</vh></v>
<v t="aum.20060528175118.24"><vh>_toxml</vh></v>
</v>
</v>
<v t="aum.20060521163823" a="E" tnodeList="aum.20060521163823,aum.20060521163823.1,aum.20060521175433,aum.20060521175052,aum.20060521163823.2,aum.20060521163823.5,aum.20060521163823.3,aum.20060604212311,aum.20060604210617,aum.20060604212311.1,aum.20060604213643,aum.20060604223923,aum.20060604223923.1,aum.20060604223923.2,aum.20060521185642,aum.20060521163823.14,aum.20060521163823.15,aum.20060521163823.25,aum.20060521163823.6,aum.20060527195652,aum.20060526163608,aum.20060604143559,aum.20060521163823.8,aum.20060521163823.13,aum.20060521163823.18,aum.20060521163823.17,aum.20060521163823.20,aum.20060521163823.21,aum.20060521163823.7,aum.20060521163823.23,aum.20060528214253,aum.20060528214707,aum.20060521163823.12,aum.20060521163823.10,aum.20060521163823.24,aum.20060521163823.11,aum.20060521163823.16,aum.20060521163823.9,aum.20060521163823.19,aum.20060521163823.22,aum.20060528221744,aum.20060530234330,aum.20060530151504,aum.20060528221758,aum.20060530151453.1,aum.20060530151453,aum.20060530234330.1,aum.20060530234330.2,aum.20060606204304,aum.20060526071442,aum.20060526112020,aum.20060521163823.4,aum.20060521185946,aum.20060527114534,aum.20060527114743,aum.20060522231936,aum.20060522225626,aum.20060521190048,aum.20060521190048.1,aum.20060521232922,aum.20060606204304.1,aum.20060525194744,aum.20060521191057,aum.20060604212812,aum.20060604212812.1,aum.20060606204304.2,aum.20060606204304.3,aum.20060521175052.6,aum.20060521175052.4,aum.20060521175052.5,aum.20060606232825,aum.20060525225133,aum.20060601233442,aum.20060525225133.1,aum.20060525225603,aum.20060525225713,aum.20060527140140.2,aum.20060526072230,aum.20060527114053,aum.20060530202714,aum.20060530202714.1,aum.20060530202714.2,aum.20060530202714.3,aum.20060525193858,aum.20060525194744.1,aum.20060529184826,aum.20060529123536,aum.20060521163823.26"><vh>@file freenetfs.py</vh>
<v t="aum.20060521163823.1"><vh>imports</vh></v>
<v t="aum.20060521175433"><vh>globals</vh></v>
<v t="aum.20060521175052"><vh>class ErrnoWrapper</vh></v>
<v t="aum.20060521163823.2" a="E"><vh>class FreenetBaseFS</vh>
<v t="aum.20060521163823.5"><vh>attribs</vh></v>
<v t="aum.20060521163823.3"><vh>__init__</vh></v>
<v t="aum.20060604212311" a="E"><vh>command handlers</vh>
<v t="aum.20060604210617"><vh>executeCommand</vh></v>
<v t="aum.20060604212311.1"><vh>cmd_hello</vh></v>
<v t="aum.20060604213643"><vh>cmd_mount</vh></v>
<v t="aum.20060604223923"><vh>cmd_umount</vh></v>
<v t="aum.20060604223923.1"><vh>cmd_update</vh></v>
<v t="aum.20060604223923.2"><vh>cmd_commit</vh></v>
</v>
<v t="aum.20060521185642" a="E"><vh>fs primitives</vh>
<v t="aum.20060521163823.14"><vh>chmod</vh></v>
<v t="aum.20060521163823.15"><vh>chown</vh></v>
<v t="aum.20060521163823.25"><vh>fsync</vh></v>
<v t="aum.20060521163823.6" a="E"><vh>getattr</vh>
<v t="aum.20060527195652"><vh>&lt;&lt;generate keypair&gt;&gt;</vh></v>
<v t="aum.20060526163608"><vh>&lt;&lt;retrieve/cache key&gt;&gt;</vh></v>
<v t="aum.20060604143559"><vh>&lt;&lt;base64 command&gt;&gt;</vh></v>
</v>
<v t="aum.20060521163823.8"><vh>getdir</vh></v>
<v t="aum.20060521163823.13"><vh>link</vh></v>
<v t="aum.20060521163823.18"><vh>mkdir</vh></v>
<v t="aum.20060521163823.17"><vh>mknod</vh></v>
<v t="aum.20060521163823.20"><vh>open</vh></v>
<v t="aum.20060521163823.21"><vh>read</vh></v>
<v t="aum.20060521163823.7"><vh>readlink</vh></v>
<v t="aum.20060521163823.23" a="E"><vh>release</vh>
<v t="aum.20060528214253"><vh>&lt;&lt;insert to freenet&gt;&gt;</vh></v>
<v t="aum.20060528214707"><vh>&lt;&lt;write to freedisk&gt;&gt;</vh></v>
</v>
<v t="aum.20060521163823.12"><vh>rename</vh></v>
<v t="aum.20060521163823.10"><vh>rmdir</vh></v>
<v t="aum.20060521163823.24"><vh>statfs</vh></v>
<v t="aum.20060521163823.11"><vh>symlink</vh></v>
<v t="aum.20060521163823.16"><vh>truncate</vh></v>
<v t="aum.20060521163823.9"><vh>unlink</vh></v>
<v t="aum.20060521163823.19"><vh>utime</vh></v>
<v t="aum.20060521163823.22"><vh>write</vh></v>
</v>
<v t="aum.20060528221744" a="E"><vh>freedisk methods</vh>
<v t="aum.20060530234330"><vh>setupFreedisks</vh></v>
<v t="aum.20060530151504"><vh>addDisk</vh></v>
<v t="aum.20060528221758"><vh>delDisk</vh></v>
<v t="aum.20060530151453.1"><vh>commitDisk</vh></v>
<v t="aum.20060530151453"><vh>updateDisk</vh></v>
<v t="aum.20060530234330.1"><vh>getManifest</vh></v>
<v t="aum.20060530234330.2"><vh>putManifest</vh></v>
</v>
<v t="aum.20060606204304" a="E"><vh>util methods</vh>
<v t="aum.20060526071442"><vh>setupFiles</vh></v>
<v t="aum.20060526112020"><vh>connectToNode</vh></v>
<v t="aum.20060521163823.4"><vh>mythread</vh></v>
<v t="aum.20060521185946"><vh>hashpath</vh></v>
<v t="aum.20060527114534"><vh>addToCache</vh></v>
<v t="aum.20060527114743"><vh>delFromCache</vh></v>
<v t="aum.20060522231936"><vh>statFromKw</vh></v>
<v t="aum.20060522225626"><vh>statToDict</vh></v>
<v t="aum.20060521190048"><vh>getReadURI</vh></v>
<v t="aum.20060521190048.1"><vh>getWriteURI</vh></v>
<v t="aum.20060521232922"><vh>log</vh></v>
</v>
<v t="aum.20060606204304.1"><vh>deprecated methods</vh>
<v t="aum.20060525194744"><vh>__getDirStat</vh></v>
<v t="aum.20060521191057"><vh>_loadConfig</vh></v>
</v>
</v>
<v t="aum.20060604212812" a="E"><vh>class Freedisk</vh>
<v t="aum.20060604212812.1"><vh>__init__</vh></v>
</v>
<v t="aum.20060606204304.2" a="E"><vh>class FreenetFuseFS</vh>
<v t="aum.20060606204304.3"><vh>attribs</vh></v>
<v t="aum.20060521175052.6"><vh>run</vh></v>
<v t="aum.20060521175052.4"><vh>GetContent</vh></v>
<v t="aum.20060521175052.5"><vh>Invalidate</vh></v>
<v t="aum.20060606232825"><vh>tickThread</vh></v>
</v>
<v t="aum.20060525225133" a="E"><vh>class FileRecord</vh>
<v t="aum.20060601233442"><vh>attribs</vh></v>
<v t="aum.20060525225133.1"><vh>__init__</vh></v>
<v t="aum.20060525225603"><vh>__getattr__</vh></v>
<v t="aum.20060525225713"><vh>__setattr__</vh></v>
<v t="aum.20060527140140.2"><vh>write</vh></v>
<v t="aum.20060526072230"><vh>addChild</vh></v>
<v t="aum.20060527114053"><vh>delChild</vh></v>
</v>
<v t="aum.20060530202714"><vh>class FreediskMgr</vh>
<v t="aum.20060530202714.1"><vh>__init__</vh></v>
<v t="aum.20060530202714.2"><vh>update</vh></v>
<v t="aum.20060530202714.3"><vh>commit</vh></v>
</v>
<v t="aum.20060525193858"><vh>pathToInode</vh></v>
<v t="aum.20060525194744.1"><vh>timeNow</vh></v>
<v t="aum.20060529184826"><vh>usage</vh></v>
<v t="aum.20060529123536"><vh>main</vh></v>
<v t="aum.20060521163823.26"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060521111625" a="E"><vh>Client Apps</vh>
<v t="aum.20060513073239.2" a="E"><vh>freesitemgr</vh>
<v t="aum.20060516145032" a="E" tnodeList="aum.20060516145032,aum.20060516145032.1,aum.20060514132715,aum.20060514132715.1,aum.20060516150511,aum.20060516184736.1,aum.20060516193650,aum.20060516153119,aum.20060516143534.1,aum.20060516144850,aum.20060516143534.2,aum.20060514132715.2,aum.20060514132715.3"><vh>@nosent freesitemgr.py</vh>
<v t="aum.20060516145032.1" a="E"><vh>freesitemgr-script</vh>
<v t="aum.20060514132715"><vh>imports</vh></v>
<v t="aum.20060514132715.1"><vh>globals</vh></v>
<v t="aum.20060516150511"><vh>editCreateConfig</vh></v>
<v t="aum.20060516184736.1"><vh>addSite</vh></v>
<v t="aum.20060516193650"><vh>removeSite</vh></v>
<v t="aum.20060516153119"><vh>getYesNo</vh></v>
<v t="aum.20060516143534.1"><vh>help</vh></v>
<v t="aum.20060516144850"><vh>usage</vh></v>
<v t="aum.20060516143534.2"><vh>main</vh></v>
<v t="aum.20060514132715.2"><vh>main_old</vh></v>
<v t="aum.20060514132715.3"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060512140230" tnodeList="aum.20060512140230,aum.20060516145032.1,aum.20060514132715,aum.20060514132715.1,aum.20060516150511,aum.20060516184736.1,aum.20060516193650,aum.20060516153119,aum.20060516143534.1,aum.20060516144850,aum.20060516143534.2,aum.20060514132715.2,aum.20060514132715.3"><vh>@nosent freesitemgr</vh>
<v t="aum.20060516145032.1" a="E"><vh>freesitemgr-script</vh>
<v t="aum.20060514132715"><vh>imports</vh></v>
<v t="aum.20060514132715.1"><vh>globals</vh></v>
<v t="aum.20060516150511"><vh>editCreateConfig</vh></v>
<v t="aum.20060516184736.1"><vh>addSite</vh></v>
<v t="aum.20060516193650"><vh>removeSite</vh></v>
<v t="aum.20060516153119"><vh>getYesNo</vh></v>
<v t="aum.20060516143534.1"><vh>help</vh></v>
<v t="aum.20060516144850"><vh>usage</vh></v>
<v t="aum.20060516143534.2"><vh>main</vh></v>
<v t="aum.20060514132715.2"><vh>main_old</vh></v>
<v t="aum.20060514132715.3"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060513073239.3" tnodeList="aum.20060513073239.3"><vh>@nosent start.sh</vh></v>
<v t="aum.20060513073239.4" tnodeList="aum.20060513073239.4"><vh>@nosent stop.sh</vh></v>
</v>
<v t="aum.20060513073239.1"><vh>XML-RPC Server</vh>
<v t="aum.20060515195621" a="E" tnodeList="aum.20060515195621,aum.20060515195621.2,aum.20060515195621.1,aum.20060515195621.3,aum.20060515200029"><vh>@nosent fcpxmlrpc.cgi</vh>
<v t="aum.20060515195621.2"><vh>imports </vh></v>
<v t="aum.20060515195621.1"><vh>configs</vh></v>
<v t="aum.20060515195621.3"><vh>main</vh></v>
<v t="aum.20060515200029"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060521111625.1"><vh>get/put/genkey</vh>
<v t="aum.20060521133455" a="E"><vh>fcpget</vh>
<v t="aum.20060521133455.1" a="E" tnodeList="aum.20060521133455.1,aum.20060521133455.2,aum.20060521111727.1,aum.20060521131205,aum.20060521131205.1,aum.20060521131205.2,aum.20060521111727.2,aum.20060521111727.3"><vh>@nosent fcpget</vh>
<v t="aum.20060521133455.2" a="E"><vh>fcpget code</vh>
<v t="aum.20060521111727.1"><vh>imports</vh></v>
<v t="aum.20060521131205"><vh>globals</vh></v>
<v t="aum.20060521131205.1"><vh>usage</vh></v>
<v t="aum.20060521131205.2"><vh>help</vh></v>
<v t="aum.20060521111727.2"><vh>main</vh></v>
<v t="aum.20060521111727.3"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060521111727" tnodeList="aum.20060521111727,aum.20060521133455.2,aum.20060521111727.1,aum.20060521131205,aum.20060521131205.1,aum.20060521131205.2,aum.20060521111727.2,aum.20060521111727.3"><vh>@nosent fcpget.py</vh>
<v t="aum.20060521133455.2"><vh>fcpget code</vh>
<v t="aum.20060521111727.1"><vh>imports</vh></v>
<v t="aum.20060521131205"><vh>globals</vh></v>
<v t="aum.20060521131205.1"><vh>usage</vh></v>
<v t="aum.20060521131205.2"><vh>help</vh></v>
<v t="aum.20060521111727.2"><vh>main</vh></v>
<v t="aum.20060521111727.3"><vh>mainline</vh></v>
</v>
</v>
</v>
<v t="aum.20060521134332" a="E"><vh>fcpput</vh>
<v t="aum.20060521134332.1" a="E" tnodeList="aum.20060521134332.1,aum.20060521134737,aum.20060521134737.1,aum.20060521134737.2,aum.20060521134737.3,aum.20060521134737.4,aum.20060521134737.5,aum.20060521134737.6"><vh>@nosent fcpput</vh>
<v t="aum.20060521134737" a="E"><vh>fcpput code</vh>
<v t="aum.20060521134737.1"><vh>imports</vh></v>
<v t="aum.20060521134737.2"><vh>globals</vh></v>
<v t="aum.20060521134737.3"><vh>usage</vh></v>
<v t="aum.20060521134737.4"><vh>help</vh></v>
<v t="aum.20060521134737.5"><vh>main</vh></v>
<v t="aum.20060521134737.6"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060521135828" tnodeList="aum.20060521135828,aum.20060521134737,aum.20060521134737.1,aum.20060521134737.2,aum.20060521134737.3,aum.20060521134737.4,aum.20060521134737.5,aum.20060521134737.6"><vh>@nosent fcpput.py</vh>
<v t="aum.20060521134737"><vh>fcpput code</vh>
<v t="aum.20060521134737.1"><vh>imports</vh></v>
<v t="aum.20060521134737.2"><vh>globals</vh></v>
<v t="aum.20060521134737.3"><vh>usage</vh></v>
<v t="aum.20060521134737.4"><vh>help</vh></v>
<v t="aum.20060521134737.5"><vh>main</vh></v>
<v t="aum.20060521134737.6"><vh>mainline</vh></v>
</v>
</v>
</v>
<v t="aum.20060521182836"><vh>fcpgenkey</vh>
<v t="aum.20060521183025" tnodeList="aum.20060521183025,aum.20060521183025.1,aum.20060521183025.2,aum.20060521183025.3,aum.20060521183025.4,aum.20060521183025.5,aum.20060521183025.6,aum.20060521183025.7"><vh>@nosent fcpgenkey</vh>
<v t="aum.20060521183025.1" a="E"><vh>fcpgenkey code</vh>
<v t="aum.20060521183025.2"><vh>imports</vh></v>
<v t="aum.20060521183025.3"><vh>globals</vh></v>
<v t="aum.20060521183025.4"><vh>usage</vh></v>
<v t="aum.20060521183025.5"><vh>help</vh></v>
<v t="aum.20060521183025.6"><vh>main</vh></v>
<v t="aum.20060521183025.7"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060521183205" a="E" tnodeList="aum.20060521183205,aum.20060521183025.1,aum.20060521183025.2,aum.20060521183025.3,aum.20060521183025.4,aum.20060521183025.5,aum.20060521183025.6,aum.20060521183025.7"><vh>@nosent fcpgenkey.py</vh>
<v t="aum.20060521183025.1" a="E"><vh>fcpgenkey code</vh>
<v t="aum.20060521183025.2"><vh>imports</vh></v>
<v t="aum.20060521183025.3"><vh>globals</vh></v>
<v t="aum.20060521183025.4"><vh>usage</vh></v>
<v t="aum.20060521183025.5"><vh>help</vh></v>
<v t="aum.20060521183025.6"><vh>main</vh></v>
<v t="aum.20060521183025.7"><vh>mainline</vh></v>
</v>
</v>
</v>
</v>
<v t="aum.20060521163241" a="E"><vh>freedisk</vh>
<v t="aum.20060529191729" tnodeList="aum.20060529191729"><vh>@file mount.freenetfs</vh></v>
<v t="aum.20060602094531" a="E"><vh>Front ends</vh>
<v t="aum.20060530170840" a="E" tnodeList="aum.20060530170840,aum.20060529123536.1,aum.20060529163723,aum.20060529163723.1,aum.20060603114446,aum.20060604194409,aum.20060604194834,aum.20060603114247,aum.20060530143459.3,aum.20060607092808,aum.20060530143459.4,aum.20060530143459.5,aum.20060530143459.6,aum.20060530143459.7,aum.20060530143459.8,aum.20060530143459.9,aum.20060603164555,aum.20060604144241,aum.20060604143852,aum.20060603121718,aum.20060603125105,aum.20060603121718.1,aum.20060603121848,aum.20060603122324,aum.20060603125848,aum.20060603132557,aum.20060603131227,aum.20060603154804,aum.20060603155318,aum.20060603162815,aum.20060603155642,aum.20060603125405,aum.20060603125405.1,aum.20060529164147,aum.20060529164147.1,aum.20060530160322,aum.20060531160838,aum.20060603100604,aum.20060603100604.1,aum.20060603100604.2,aum.20060603125812,aum.20060603132247,aum.20060529163723.2,aum.20060530142805.1,aum.20060530143459,aum.20060604200719,aum.20060529163723.4"><vh>@file freedisk.py</vh>
<v t="aum.20060529123536.1" a="E"><vh>freedisk app</vh>
<v t="aum.20060529163723"><vh>imports</vh></v>
<v t="aum.20060529163723.1"><vh>globals</vh></v>
<v t="aum.20060603114446" a="E"><vh>class FreediskMgr</vh>
<v t="aum.20060604194409"><vh>__init__</vh></v>
<v t="aum.20060604194834"><vh>run</vh></v>
<v t="aum.20060603114247"><vh>cmd_init</vh></v>
<v t="aum.20060530143459.3"><vh>cmd_start</vh></v>
<v t="aum.20060607092808"><vh>cmd_run</vh></v>
<v t="aum.20060530143459.4"><vh>cmd_stop</vh></v>
<v t="aum.20060530143459.5"><vh>cmd_new</vh></v>
<v t="aum.20060530143459.6"><vh>cmd_add</vh></v>
<v t="aum.20060530143459.7"><vh>cmd_del</vh></v>
<v t="aum.20060530143459.8"><vh>cmd_update</vh></v>
<v t="aum.20060530143459.9"><vh>cmd_commit</vh></v>
<v t="aum.20060603164555"><vh>cmd_list</vh></v>
<v t="aum.20060604144241"><vh>cmd_cmd</vh></v>
<v t="aum.20060604143852"><vh>doFsCommand</vh></v>
</v>
<v t="aum.20060603121718" a="E"><vh>class FreediskConfig</vh>
<v t="aum.20060603125105"><vh>attribs</vh></v>
<v t="aum.20060603121718.1"><vh>__init__</vh></v>
<v t="aum.20060603121848"><vh>load</vh></v>
<v t="aum.20060603122324"><vh>create</vh></v>
<v t="aum.20060603125848"><vh>save</vh></v>
<v t="aum.20060603132557"><vh>abort</vh></v>
<v t="aum.20060603131227"><vh>setPassword</vh></v>
<v t="aum.20060603154804"><vh>addDisk</vh></v>
<v t="aum.20060603155318"><vh>getDisk</vh></v>
<v t="aum.20060603162815"><vh>getDisks</vh></v>
<v t="aum.20060603155642"><vh>delDisk</vh></v>
<v t="aum.20060603125405"><vh>__getattr__</vh></v>
<v t="aum.20060603125405.1"><vh>__setattr__</vh></v>
</v>
<v t="aum.20060529164147"><vh>usage</vh></v>
<v t="aum.20060529164147.1"><vh>help</vh></v>
<v t="aum.20060530160322"><vh>removeDirAndContents</vh></v>
<v t="aum.20060531160838"><vh>status</vh></v>
<v t="aum.20060603100604"><vh>encrypt</vh></v>
<v t="aum.20060603100604.1"><vh>decrypt</vh></v>
<v t="aum.20060603100604.2"><vh>getpasswd</vh></v>
<v t="aum.20060603125812"><vh>ipython</vh></v>
<v t="aum.20060603132247"><vh>getyesno</vh></v>
<v t="aum.20060529163723.2" a="E"><vh>main</vh>
<v t="aum.20060530142805.1"><vh>&lt;&lt;set defaults&gt;&gt;</vh></v>
<v t="aum.20060530143459"><vh>&lt;&lt;process args&gt;&gt;</vh></v>
<v t="aum.20060604200719"><vh>&lt;&lt;execute command&gt;&gt;</vh></v>
</v>
<v t="aum.20060529163723.4"><vh>mainline</vh></v>
</v>
</v>
<v t="aum.20060530170840.1" tnodeList="aum.20060530170840.1,aum.20060529123536.1,aum.20060529163723,aum.20060529163723.1,aum.20060603114446,aum.20060604194409,aum.20060604194834,aum.20060603114247,aum.20060530143459.3,aum.20060607092808,aum.20060530143459.4,aum.20060530143459.5,aum.20060530143459.6,aum.20060530143459.7,aum.20060530143459.8,aum.20060530143459.9,aum.20060603164555,aum.20060604144241,aum.20060604143852,aum.20060603121718,aum.20060603125105,aum.20060603121718.1,aum.20060603121848,aum.20060603122324,aum.20060603125848,aum.20060603132557,aum.20060603131227,aum.20060603154804,aum.20060603155318,aum.20060603162815,aum.20060603155642,aum.20060603125405,aum.20060603125405.1,aum.20060529164147,aum.20060529164147.1,aum.20060530160322,aum.20060531160838,aum.20060603100604,aum.20060603100604.1,aum.20060603100604.2,aum.20060603125812,aum.20060603132247,aum.20060529163723.2,aum.20060530142805.1,aum.20060530143459,aum.20060604200719,aum.20060529163723.4"><vh>@file freedisk</vh>
<v t="aum.20060529123536.1" a="E"><vh>freedisk app</vh>
<v t="aum.20060529163723"><vh>imports</vh></v>
<v t="aum.20060529163723.1"><vh>globals</vh></v>
<v t="aum.20060603114446" a="E"><vh>class FreediskMgr</vh>
<v t="aum.20060604194409"><vh>__init__</vh></v>
<v t="aum.20060604194834"><vh>run</vh></v>
<v t="aum.20060603114247"><vh>cmd_init</vh></v>
<v t="aum.20060530143459.3"><vh>cmd_start</vh></v>
<v t="aum.20060607092808"><vh>cmd_run</vh></v>
<v t="aum.20060530143459.4"><vh>cmd_stop</vh></v>
<v t="aum.20060530143459.5"><vh>cmd_new</vh></v>
<v t="aum.20060530143459.6"><vh>cmd_add</vh></v>
<v t="aum.20060530143459.7"><vh>cmd_del</vh></v>
<v t="aum.20060530143459.8"><vh>cmd_update</vh></v>
<v t="aum.20060530143459.9"><vh>cmd_commit</vh></v>
<v t="aum.20060603164555"><vh>cmd_list</vh></v>
<v t="aum.20060604144241"><vh>cmd_cmd</vh></v>
<v t="aum.20060604143852"><vh>doFsCommand</vh></v>
</v>
<v t="aum.20060603121718" a="E"><vh>class FreediskConfig</vh>
<v t="aum.20060603125105"><vh>attribs</vh></v>
<v t="aum.20060603121718.1"><vh>__init__</vh></v>
<v t="aum.20060603121848"><vh>load</vh></v>
<v t="aum.20060603122324"><vh>create</vh></v>
<v t="aum.20060603125848"><vh>save</vh></v>
<v t="aum.20060603132557"><vh>abort</vh></v>
<v t="aum.20060603131227"><vh>setPassword</vh></v>
<v t="aum.20060603154804"><vh>addDisk</vh></v>
<v t="aum.20060603155318"><vh>getDisk</vh></v>
<v t="aum.20060603162815"><vh>getDisks</vh></v>
<v t="aum.20060603155642"><vh>delDisk</vh></v>
<v t="aum.20060603125405"><vh>__getattr__</vh></v>
<v t="aum.20060603125405.1"><vh>__setattr__</vh></v>
</v>
<v t="aum.20060529164147"><vh>usage</vh></v>
<v t="aum.20060529164147.1"><vh>help</vh></v>
<v t="aum.20060530160322"><vh>removeDirAndContents</vh></v>
<v t="aum.20060531160838"><vh>status</vh></v>
<v t="aum.20060603100604"><vh>encrypt</vh></v>
<v t="aum.20060603100604.1"><vh>decrypt</vh></v>
<v t="aum.20060603100604.2"><vh>getpasswd</vh></v>
<v t="aum.20060603125812"><vh>ipython</vh></v>
<v t="aum.20060603132247"><vh>getyesno</vh></v>
<v t="aum.20060529163723.2" a="E"><vh>main</vh>
<v t="aum.20060530142805.1"><vh>&lt;&lt;set defaults&gt;&gt;</vh></v>
<v t="aum.20060530143459"><vh>&lt;&lt;process args&gt;&gt;</vh></v>
<v t="aum.20060604200719"><vh>&lt;&lt;execute command&gt;&gt;</vh></v>
</v>
<v t="aum.20060529163723.4"><vh>mainline</vh></v>
</v>
</v>
</v>
<v t="aum.20060602094531.1" a="E"><vh>test</vh>
<v t="aum.20060602094531.2" tnodeList="aum.20060602094531.2"><vh>@file fdtest.py</vh></v>
</v>
</v>
</v>
<v t="aum.20060513073239.5" a="E"><vh>Test files</vh>
<v t="aum.20060526123909" tnodeList="aum.20060526123909"><vh>@file fstest.c</vh></v>
<v t="aum.20060511003500" tnodeList="aum.20060511003500"><vh>@file test.py</vh></v>
<v t="aum.20060512152233" tnodeList="aum.20060512152233"><vh>@file genkey.py</vh></v>
</v>
<v t="aum.20060513073239.6"><vh>Old stuff</vh>
<v t="aum.20060509223528" a="E"><vh>file freenet_old.py</vh>
<v t="aum.20060509223528.1"><vh>imports</vh></v>
<v t="aum.20060509223528.2"><vh>constants</vh></v>
<v t="aum.20060509223528.3"><vh>class node</vh></v>
<v t="aum.20060509223528.4"><vh>__init__</vh></v>
<v t="aum.20060509223528.5"><vh>get</vh></v>
<v t="aum.20060509223528.6"><vh>put</vh></v>
<v t="aum.20060509223528.7"><vh>getseq</vh></v>
<v t="aum.20060509223528.8"><vh>putseq</vh></v>
<v t="aum.20060509223528.9"><vh>putraw</vh></v>
<v t="aum.20060509223528.10"><vh>genkeypair</vh></v>
<v t="aum.20060509223528.11"><vh>invertprivate</vh></v>
<v t="aum.20060509223528.12"><vh>genchk</vh></v>
<v t="aum.20060509223528.13"><vh>keyexists</vh></v>
<v t="aum.20060509223528.14"><vh>getsite</vh></v>
<v t="aum.20060509223528.15"><vh>putsite</vh></v>
<v t="aum.20060509223528.16"><vh>_connect</vh></v>
<v t="aum.20060509223528.17"><vh>_disconnect</vh></v>
<v t="aum.20060509223528.18"><vh>_rawtransaction</vh></v>
<v t="aum.20060509223528.19"><vh>_handshake</vh></v>
<v t="aum.20060509223528.20"><vh>_getsmart</vh></v>
<v t="aum.20060509223528.21"><vh>_getraw</vh></v>
<v t="aum.20060509223528.22"><vh>_put</vh></v>
<v t="aum.20060509223528.23"><vh>_send</vh></v>
<v t="aum.20060509223528.24"><vh>_sendline</vh></v>
<v t="aum.20060509223528.25"><vh>_sendhdr</vh></v>
<v t="aum.20060509223528.26"><vh>_recv</vh></v>
<v t="aum.20060509223528.27"><vh>_recvline</vh></v>
<v t="aum.20060509223528.28"><vh>_recvkeydata</vh></v>
<v t="aum.20060509223528.29"><vh>_recvchunk</vh></v>
<v t="aum.20060509223528.30"><vh>_genchk</vh></v>
<v t="aum.20060509223528.31"><vh>_fecput</vh></v>
<v t="aum.20060509223528.32"><vh>_fecputfile</vh></v>
<v t="aum.20060509223528.33"><vh>_fecputfileex</vh></v>
<v t="aum.20060509223528.34"><vh>_fec_InsFecSplitPart</vh></v>
<v t="aum.20060509223528.35"><vh>_fec_retryInsert</vh></v>
<v t="aum.20060509223528.36"><vh>_fec_retryInsertFancy</vh></v>
<v t="aum.20060509223528.37"><vh>_fec_createManifest</vh></v>
<v t="aum.20060509223528.38"><vh>class _fec_threadData</vh></v>
<v t="aum.20060509223528.39"><vh>_fec_getMimetype</vh></v>
<v t="aum.20060509223528.40"><vh>_fec_makeSimpleMetadata</vh></v>
<v t="aum.20060509223528.41"><vh>_fec_makeDbr</vh></v>
<v t="aum.20060509223528.42"><vh>_fec_makeRedirect</vh></v>
<v t="aum.20060509223528.43"><vh>_fec_rebuildHdr</vh></v>
<v t="aum.20060509223528.44"><vh>_fec_makeMetadata</vh></v>
<v t="aum.20060509223528.45"><vh>_fec_segmentFile</vh></v>
<v t="aum.20060509223528.46"><vh>_fec_largeSend</vh></v>
<v t="aum.20060509223528.47"><vh>_fec_getNodeLoad</vh></v>
<v t="aum.20060509223528.48"><vh>_fec_openPort</vh></v>
<v t="aum.20060509223528.49"><vh>_fec_readMsg</vh></v>
<v t="aum.20060509223528.50"><vh>_fec_getFile</vh></v>
<v t="aum.20060509223528.51"><vh>_fec_removeTmpFiles</vh></v>
<v t="aum.20060509223528.52"><vh>_fec_clientGet</vh></v>
<v t="aum.20060509223528.53"><vh>_fec_segmentSplitFile</vh></v>
<v t="aum.20060509223528.54"><vh>_fec_decodeSegment</vh></v>
<v t="aum.20060509223528.55"><vh>_fec_getKey</vh></v>
<v t="aum.20060509223528.56"><vh>_fec_hexIndexList</vh></v>
<v t="aum.20060509223528.57"><vh>_fec_openSocket</vh></v>
<v t="aum.20060509223528.58"><vh>_fec_makeFakeMsg</vh></v>
<v t="aum.20060509223528.59"><vh>_fec_copyBinary</vh></v>
<v t="aum.20060509223528.60"><vh>_fec_zeroPad</vh></v>
<v t="aum.20060509223528.61"><vh>_fec_sameLength</vh></v>
<v t="aum.20060509223528.62"><vh>_fec_diffBinary</vh></v>
<v t="aum.20060509223528.63"><vh>_fec_concatFiles</vh></v>
<v t="aum.20060509223528.64"><vh>_fec_makeFilenames</vh></v>
<v t="aum.20060509223528.65"><vh>_fec_makeIndexList</vh></v>
<v t="aum.20060509223528.66"><vh>_fec_makeRebuiltFileList</vh></v>
<v t="aum.20060509223528.67"><vh>_fec_findMissingIndices</vh></v>
<v t="aum.20060509223528.68" a="E"><vh>class site</vh>
<v t="aum.20060509223528.69"><vh>__init__</vh></v>
<v t="aum.20060509223528.70"><vh>chkArgs</vh></v>
<v t="aum.20060509223528.71"><vh>put</vh></v>
<v t="aum.20060509223528.72"><vh>get</vh></v>
<v t="aum.20060509223528.73"><vh>readdir</vh></v>
<v t="aum.20060509223528.74"><vh>__get</vh></v>
<v t="aum.20060509223528.75"><vh>opendocfile</vh></v>
</v>
<v t="aum.20060509223528.76"><vh>class key</vh></v>
<v t="aum.20060509223528.77"><vh>__init__</vh></v>
<v t="aum.20060509223528.78"><vh>get</vh></v>
<v t="aum.20060509223528.79"><vh>put</vh></v>
<v t="aum.20060509223528.80"><vh>class uri</vh></v>
<v t="aum.20060509223528.81"><vh>__init__</vh></v>
<v t="aum.20060509223528.82"><vh>render</vh></v>
<v t="aum.20060509223528.83"><vh>dbr</vh></v>
<v t="aum.20060509223528.84"><vh>__repr__</vh></v>
<v t="aum.20060509223528.85"><vh>__str__</vh></v>
<v t="aum.20060509223528.86"><vh>class metadata</vh></v>
<v t="aum.20060509223528.87"><vh>attribs</vh></v>
<v t="aum.20060509223528.88"><vh>__init__</vh></v>
<v t="aum.20060509223528.89"><vh>add</vh></v>
<v t="aum.20060509223528.90"><vh>set</vh></v>
<v t="aum.20060509223528.91"><vh>targeturi</vh></v>
<v t="aum.20060509223528.92"><vh>documents</vh></v>
<v t="aum.20060509223528.93"><vh>parseRaw</vh></v>
<v t="aum.20060509223528.94"><vh>__repr__</vh></v>
<v t="aum.20060509223528.95"><vh>__str__</vh></v>
<v t="aum.20060509223528.96"><vh>parseRawLine</vh></v>
<v t="aum.20060509223528.97"><vh>render</vh></v>
<v t="aum.20060509223528.98" a="E"><vh>class Dispatcher</vh></v>
<v t="aum.20060509223528.99"><vh>connect</vh></v>
<v t="aum.20060509223528.100"><vh>initfec</vh></v>
<v t="aum.20060509223528.101"><vh>verbosity</vh></v>
<v t="aum.20060509223528.102"><vh>tempFilename</vh></v>
<v t="aum.20060509223528.103"><vh>_transferArgs</vh></v>
<v t="aum.20060509223528.104"><vh>guessMimetype</vh></v>
<v t="aum.20060509223528.105"><vh>dbr</vh></v>
<v t="aum.20060509223528.106"><vh>setLogCallback</vh></v>
<v t="aum.20060509223528.107" a="E"><vh>base64 stuff</vh>
<v t="aum.20060509223528.108"><vh>str2b64</vh></v>
<v t="aum.20060509223528.109"><vh>b642str</vh></v>
</v>
<v t="aum.20060509223528.110"><vh>num2bits</vh></v>
<v t="aum.20060509223528.111"><vh>str2bits</vh></v>
<v t="aum.20060509223528.112"><vh>bits2str</vh></v>
<v t="aum.20060509223528.113"><vh>bits2num</vh></v>
<v t="aum.20060509223528.114"><vh>base64encodeEntropy</vh></v>
<v t="aum.20060509223528.115"><vh>ssk2bits</vh></v>
<v t="aum.20060509223528.116"><vh>bits2ssk</vh></v>
<v t="aum.20060509223528.117"><vh>str2num</vh></v>
<v t="aum.20060509223528.118"><vh>num2str</vh></v>
<v t="aum.20060509223528.119"><vh>exceptions</vh></v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="aum.20060506215300">@nocolor

A hacked up implementation of a library for Freenet FCP v2

</t>
<t tx="aum.20060506215707">@first #!/usr/bin/env python
"""
An implementation of a freenet client library for
FCP v2, offering considerable flexibility.

Clients should instantiate FCPNode, then execute
its methods to perform tasks with FCP.

This module was written by aum, May 2006, released under the GNU Lesser General
Public License.

No warranty, yada yada

"""

@others


</t>
<t tx="aum.20060506215707.1">import sys, os, socket, time, thread
import threading, mimetypes, sha, Queue
import select, traceback, base64

</t>
<t tx="aum.20060506215707.2"># where we can find the freenet node FCP port
defaultFCPHost = "127.0.0.1"
defaultFCPPort = 9481

# may set environment vars for FCP host/port
if os.environ.has_key("FCP_HOST"):
    defaultFCPHost = os.environ["FCP_HOST"].strip()
if os.environ.has_key("FCP_PORT"):
    defaultFCPPort = int(os.environ["FCP_PORT"].strip())

# poll timeout period for manager thread
pollTimeout = 0.1
#pollTimeout = 3

# list of keywords sent from node to client, which have
# int values
intKeys = [
    'DataLength', 'Code',
    ]

# for the FCP 'ClientHello' handshake
expectedVersion="2.0"

# logger verbosity levels
SILENT = 0
FATAL = 1
CRITICAL = 2
ERROR = 3
INFO = 4
DETAIL = 5
DEBUG = 6

defaultVerbosity = ERROR

</t>
<t tx="aum.20060506215707.3">class FCPNode:
    """
    Represents an interface to a freenet node via its FCP port,
    and exposes primitives for the basic genkey, get, put and putdir
    operations.
    
    Only one instance of FCPNode is needed across an entire
    running client application, because its methods are quite thread-safe.
    Creating 2 or more instances is a waste of resources.

    Clients, when invoking methods, have several options regarding flow
    control and event notification:

        - synchronous call (the default). Here, no pending status messages
          will ever be seen, and the call will only control when it has
          completed (successfully, or otherwise)
        
        - asynchronous call - this is invoked by passing the keyword argument
          'async=True' to any of the main primitives. When a primitive is invoked
          asynchronously, it will return a 'job ticket object' immediately. This
          job ticket has methods for polling for job completion, or blocking
          awaiting completion
        
        - setting a callback. You can pass to any of the primitives a
          'callback=somefunc' keyword arg, where 'somefunc' is a callable object
          conforming to 'def somefunc(status, value)'
          
          The callback function will be invoked when a primitive succeeds or fails,
          as well as when a pending message is received from the node.
          
          The 'status' argument passed will be one of:
              - 'successful' - the primitive succeeded, and 'value' will contain
                the result of the primitive
              - 'pending' - the primitive is still executing, and 'value' will
                contain the raw pending message sent back from the node, as a
                dict
              - 'failed' - the primitive failed, and as with 'pending', the
                argument 'value' contains a dict containing the message fields
                sent back from the node

          Note that callbacks can be set in both synchronous and asynchronous
          calling modes.

    """
    @others

</t>
<t tx="aum.20060506220237">class ConnectionRefused(Exception):
    """
    cannot connect to given host/port
    """

class FCPException(Exception):

    def __init__(self, info=None):
        #print "Creating fcp exception"
        if not info:
            info = {}
        self.info = info
        #print "fcp exception created"
        Exception.__init__(self, str(info))

    def __str__(self):
        
        parts = []
        for k in ['header', 'ShortCodeDescription', 'CodeDescription']:
            if self.info.has_key(k):
                parts.append(str(self.info[k]))
        return ";".join(parts) or "??"

class FCPGetFailed(FCPException):
    pass

class FCPPutFailed(FCPException):
    pass

class FCPProtocolError(FCPException):
    pass

</t>
<t tx="aum.20060506220237.1">def __init__(self, **kw):
    """
    Create a connection object
    
    Keyword Arguments:
        - name - name of client to use with reqs, defaults to random. This
          is crucial if you plan on making persistent requests
        - host - hostname, defaults to environment variable FCP_HOST, and
          if this doesn't exist, then defaultFCPHost
        - port - port number, defaults to environment variable FCP_PORT, and
          if this doesn't exist, then defaultFCPPort
        - logfile - a pathname or writable file object, to which log messages
          should be written, defaults to stdout
        - verbosity - how detailed the log messages should be, defaults to 0
          (silence)

    Attributes of interest:
        - jobs - a dict of currently running jobs (persistent and nonpersistent).
          keys are job ids and values are JobTicket objects

    Notes:
        - when the connection is created, a 'hello' handshake takes place.
          After that handshake, the node sends back a list of outstanding persistent
          requests left over from the last connection (based on the value of
          the 'name' keyword passed into this constructor).
          
          This object then wraps all this info into JobTicket instances and stores
          them in the self.persistentJobs dict
                                                       
    """
    # grab and save parms
    env = os.environ
    self.name = kw.get('clientName', self._getUniqueId())
    self.host = kw.get('host', env.get("FCP_HOST", defaultFCPHost))
    self.port = kw.get('port', env.get("FCP_PORT", defaultFCPPort))
    self.port = int(self.port)

    # set up the logger
    logfile = kw.get('logfile', None) or sys.stdout
    if not hasattr(logfile, 'write'):
        # might be a pathname
        if not isinstance(logfile, str):
            raise Exception("Bad logfile '%s', must be pathname or file object" % logfile)
        logfile = file(logfile, "a")
    self.logfile = logfile
    self.verbosity = kw.get('verbosity', defaultVerbosity)

    # try to connect to node
    self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    try:
        self.socket.connect((self.host, self.port))
    except Exception, e:
        raise Exception("Failed to connect to %s:%s - %s" % (self.host,
                                                                self.port,
                                                                e))

    # now do the hello
    self._hello()

    # the pending job tickets
    self.jobs = {} # keyed by request ID

    # queue for incoming client requests
    self.clientReqQueue = Queue.Queue()

    # launch receiver thread
    self.running = True
    thread.start_new_thread(self._mgrThread, ())

</t>
<t tx="aum.20060506220237.2">def __del__(self):
    """
    object is getting cleaned up, so disconnect
    """
    # terminate the node
    try:
        self.shutdown()
    except:
        traceback.print_exc()
        pass

</t>
<t tx="aum.20060506220856">def _txMsg(self, msgType, **kw):
    """
    low level message send
    
    Arguments:
        - msgType - one of the FCP message headers, such as 'ClientHello'
        - args - zero or more (keyword, value) tuples
    Keywords:
        - rawcmd - if given, this is the raw buffer to send
        - other keywords depend on the value of msgType
    """
    log = self._log

    # just send the raw command, if given    
    rawcmd = kw.get('rawcmd', None)
    if rawcmd:
        self.socket.send(rawcmd)
        log(DETAIL, "CLIENT: %s" % rawcmd)
        return

    if kw.has_key("Data"):
        data = kw.pop("Data")
        sendEndMessage = False
    else:
        data = None
        sendEndMessage = True

    items = [msgType + "\n"]
    log(DETAIL, "CLIENT: %s" % msgType)

    #print "CLIENT: %s" % msgType
    for k, v in kw.items():
        #print "CLIENT: %s=%s" % (k,v)
        line = k + "=" + str(v)
        items.append(line + "\n")
        log(DETAIL, "CLIENT: %s" % line)

    if data != None:
        items.append("DataLength=%d\n" % len(data))
        log(DETAIL, "CLIENT: DataLength=%d" % len(data))
        items.append("Data\n")
        log(DETAIL, "CLIENT: ...data...")
        items.append(data)

    #print "sendEndMessage=%s" % sendEndMessage

    if sendEndMessage:
        items.append("EndMessage\n")
        log(DETAIL, "CLIENT: EndMessage")
    raw = "".join(items)

    self.socket.send(raw)

</t>
<t tx="aum.20060506222005">def _rxMsg(self):
    """
    Receives and returns a message as a dict
    
    The header keyword is included as key 'header'
    """
    log = self._log

    log(DETAIL, "NODE: ----------------------------")

    # shorthand, for reading n bytes
    def read(n):
        if n &gt; 1:
            log(DEBUG, "read: want %d bytes" % n)
        chunks = []
        remaining = n
        while remaining &gt; 0:
            chunk = self.socket.recv(remaining)
            chunklen = len(chunk)
            if chunk:
                chunks.append(chunk)
            remaining -= chunklen
            if remaining &gt; 0:
                if n &gt; 1:
                    log(DEBUG,
                        "wanted %s, got %s still need %s bytes" % (n, chunklen, remaining)
                        )
                pass
        buf = "".join(chunks)
        return buf

    # read a line
    def readln():
        buf = []
        while True:
            c = read(1)
            buf.append(c)
            if c == '\n':
                break
        ln = "".join(buf)
        log(DETAIL, "NODE: " + ln[:-1])
        return ln

    items = {}

    # read the header line
    while True:
        line = readln().strip()
        if line:
            items['header'] = line
            break

    # read the body
    while True:
        line = readln().strip()
        if line in ['End', 'EndMessage']:
            break

        if line == 'Data':
            # read the following data
            buf = read(items['DataLength'])
            items['Data'] = buf
            log(DETAIL, "NODE: ...&lt;%d bytes of data&gt;" % len(buf))
            break
        else:
            # it's a normal 'key=val' pair
            try:
                k, v = line.split("=")
            except:
                log(ERROR, "_rxMsg: barfed splitting %s" % repr(line))
                raise

            # attempt int conversion
            try:
                v = int(v)
            except:
                pass

            items[k] = v

    # all done
    return items

</t>
<t tx="aum.20060506223545"># low level noce comms methods

@others
</t>
<t tx="aum.20060506224238"># high level client methods

@others



</t>
<t tx="aum.20060506224238.1">def _hello(self):
    """
    perform the initial FCP protocol handshake
    """
    self._txMsg("ClientHello", 
                     Name=self.name,
                     ExpectedVersion=expectedVersion)
    
    resp = self._rxMsg()
    return resp

</t>
<t tx="aum.20060506224545">if __name__ == '__main__':
    
    main()

</t>
<t tx="aum.20060506231352">def get(self, uri, **kw):
    """
    Does a direct get of a key

    Keywords:
        - async - whether to return immediately with a job ticket object, default
          False (wait for completion)
        - persistence - default 'connection' - the kind of persistence for
          this request. If 'reboot' or 'forever', this job will be able to
          be recalled in subsequent FCP sessions. Other valid values are
          'reboot' and 'forever', as per FCP spec
        - Global - default false - if evaluates to true, puts this request
          on the global queue. Note the capital G in Global. If you set this,
          persistence must be 'reboot' or 'forever'
        - verbosity - default 0 - sets the Verbosity mask passed in the
          FCP message

        - dsnly - whether to only check local datastore
        - ignoreds - don't check local datastore
        - file - if given, this is a pathname to which to store the retrieved key
        - nodata - if true, no data will be returned. This can be a useful
          test of whether a key is retrievable, without having to consume resources
          by retrieving it

    Returns a 2-tuple, depending on keyword args:
        - if 'file' is given, returns (mimetype, pathname) if key is returned
        - if 'file' is not given, returns (mimetype, data) if key is returned
        - if 'dontReturnData' is true, returns (mimetype, 1) if key is returned
    If key is not found, raises an exception
    """
    self._log(INFO, "get: uri=%s" % uri)

    # ---------------------------------
    # format the request
    opts = {}

    id = kw.pop("id", None)
    if not id:
        id = self._getUniqueId()

    opts['async'] = kw.pop('async', False)
    if kw.has_key('callback'):
        opts['callback'] = kw['callback']

    opts['Persistence'] = kw.pop('persistence', 'connection')
    if kw.get('Global', False):
        print "global get"
        opts['Global'] = "true"
    else:
        opts['Global'] = "false"

    opts['Verbosity'] = kw.get('verbosity', 0)

    if opts['Global'] == 'true' and opts['Persistence'] == 'connection':
        raise Exception("Global requests must be persistent")

    file = kw.pop("file", None)
    if file:
        opts['ReturnType'] = "disk"
        #opts['File'] = file
        opts['Filename'] = file

    elif opts.get('nodata', False):
        nodata = True
        opts['ReturnType'] = "none"
    else:
        nodata = False
        opts['ReturnType'] = "direct"
    
    opts['Identifier'] = id
    
    if kw.get("ignoreds", False):
        opts["IgnoreDS"] = "true"
    else:
        opts["IgnoreDS"] = "false"
    
    if kw.get("dsonly", False):
        opts["DSOnly"] = "true"
    else:
        opts["DSOnly"] = "false"
    
#    if uri.startswith("freenet:CHK@") or uri.startswith("CHK@"):
#        uri = os.path.splitext(uri)[0]
    opts['URI'] = uri

    opts['MaxRetries'] = kw.get("maxretries", 3)
    opts['MaxSize'] = kw.get("maxsize", "1000000000000")
    opts['PriorityClass'] = int(kw.get("priority", 1))

    # ---------------------------------
    # now enqueue the request
    return self._submitCmd(id, "ClientGet", **opts)

</t>
<t tx="aum.20060506231352.1">def genkey(self, **kw):
    """
    Generates and returns an SSK keypair
    
    Keywords:
        - async - whether to do this call asynchronously, and
          return a JobTicket object
        - callback - if given, this should be a callable which accepts 2
          arguments:
              - status - will be one of 'successful', 'failed' or 'pending'
              - value - depends on status:
                  - if status is 'successful', this will contain the value
                    returned from the command
                  - if status is 'failed' or 'pending', this will contain
                    a dict containing the response from node
        - usk - default False - if True, returns USK uris
        - name - the path to put at end, optional
    """
    id = kw.pop("id", None)
    if not id:
        id = self._getUniqueId()
    
    pub, priv = self._submitCmd(id, "GenerateSSK", Identifier=id, **kw)

    name = kw.get("name", None)
    if name:
        pub = pub + name
        priv = priv + name

        if kw.get("usk", False):
            pub = pub.replace("SSK@", "USK@")+"/0"
            priv = priv.replace("SSK@", "USK@")+"/0"

    return pub, priv

</t>
<t tx="aum.20060506231352.2">def _getUniqueId(self):
    """
    Allocate a unique ID for a request
    """
    return "id" + str(int(time.time() * 1000000))

</t>
<t tx="aum.20060506232639"># methods for manager thread

@others

</t>
<t tx="aum.20060506232639.1">def _mgrThread(self):
    """
    This thread is the nucleus of pyfcp, and coordinates incoming
    client commands and incoming node responses
    """
    log = self._log

    log(DETAIL, "FCPNode: manager thread starting")
    try:
        while self.running:

            log(DEBUG, "Top of manager thread")

            # try for incoming messages from node
            log(DEBUG, "Testing for incoming message")
            if self._msgIncoming():
                log(DEBUG, "Retrieving incoming message")
                msg = self._rxMsg()
                log(DEBUG, "Got incoming message, dispatching")
                self._on_rxMsg(msg)
                log(DEBUG, "back from on_rxMsg")
            else:
                log(DEBUG, "No incoming message from node")
    
            # try for incoming requests from clients
            log(DEBUG, "Testing for client req")
            try:
                req = self.clientReqQueue.get(True, pollTimeout)
                log(DEBUG, "Got client req, dispatching")
                self._on_clientReq(req)
                log(DEBUG, "Back from on_clientReq")
            except Queue.Empty:
                log(DEBUG, "No incoming client req")
                pass

        self._log(INFO, "Manager thread terminated normally")
        return

    except:
        traceback.print_exc()
        self._log(CRITICAL, "manager thread crashed")

</t>
<t tx="aum.20060507003931">def put(self, uri="CHK@", **kw):
    """
    Inserts a key
    
    Arguments:
        - uri - uri under which to insert the key
    
    Keywords - you must specify one of the following to choose an insert mode:
        - file - path of file from which to read the key data
        - data - the raw data of the key as string
        - dir - the directory to insert, for freesite insertion
        - redirect - the target URI to redirect to

    Keywords for 'dir' mode:
        - name - name of the freesite, the 'sitename' in SSK@privkey/sitename'
        - usk - whether to insert as a USK (USK@privkey/sitename/version/), default False
        - version - valid if usk is true, default 0

    Keywords for 'file' and 'data' modes:
        - chkonly - only generate CHK, don't insert - default false
        - dontcompress - do not compress on insert - default false

    Keywords for 'file', 'data' and 'redirect' modes:
        - mimetype - the mime type, default text/plain

    Keywords valid for all modes:
        - async - whether to do the job asynchronously, returning a job ticket
          object (default False)
        - persistence - default 'connection' - the kind of persistence for
          this request. If 'reboot' or 'forever', this job will be able to
          be recalled in subsequent FCP sessions. Other valid values are
          'reboot' and 'forever', as per FCP spec
        - Global - default false - if evaluates to true, puts this request
          on the global queue. Note the capital G in Global. If you set this,
          persistence must be 'reboot' or 'forever'
        - verbosity - default 0 - sets the Verbosity mask passed in the
          FCP message

        - maxretries - maximum number of retries, default 3
        - priority - default 1

    Notes:
        - exactly one of 'file', 'data' or 'dir' keyword arguments must be present
    """
    self._log(INFO, "put: uri=%s" % uri)

    # divert to putdir if dir keyword present
    if kw.has_key('dir'):
        return self.putdir(uri, **kw)

    # ---------------------------------
    # format the request
    opts = {}

    opts['async'] = kw.get('async', False)
    if kw.has_key('callback'):
        opts['callback'] = kw['callback']

    opts['Persistence'] = kw.pop('persistence', 'connection')
    if kw.get('Global', False):
        opts['Global'] = "true"
    else:
        opts['Global'] = "false"

    if opts['Global'] == 'true' and opts['Persistence'] == 'connection':
        raise Exception("Global requests must be persistent")

    opts['URI'] = uri
    
    # determine a mimetype
    mimetype = kw.get("mimetype", None)
    if kw.has_key('mimetype'):
        # got an explicit mimetype - use it
        mimetype = kw['mimetype']
    else:
        # not explicitly given - figure one out
        ext = os.path.splitext(uri)[1]
        if not ext:
            # no CHK@ file extension, try for filename
            if kw.has_key('file'):
                # try to grab a file extension from inserted file
                ext = os.path.splitext(kw['file'])[1]
            if not ext:
                # last resort fallback
                ext = ".txt"

        # got some kind of 'file extension', convert to mimetype
        try:
            mimetype = mimetypes.guess_type(ext)[0] or "text/plain"
        except:
            mimetype = "text/plain"

    # now can specify the mimetype
    opts['Metadata.ContentType'] = mimetype

    id = kw.pop("id", None)
    if not id:
        id = self._getUniqueId()
    opts['Identifier'] = id

    chkOnly = toBool(kw.get("chkonly", "false"))

    opts['Verbosity'] = kw.get('verbosity', 0)
    opts['MaxRetries'] = kw.get("maxretries", 3)
    opts['PriorityClass'] = kw.get("priority", 1)
    opts['GetCHKOnly'] = chkOnly
    opts['DontCompress'] = toBool(kw.get("nocompress", "false"))

    if kw.has_key("file"):
        opts['UploadFrom'] = "disk"
        opts['Filename'] = kw['file']
        if not kw.has_key("mimetype"):
            opts['Metadata.ContentType'] = mimetypes.guess_type(kw['file'])[0] or "text/plain"

    elif kw.has_key("data"):
        opts["UploadFrom"] = "direct"
        opts["Data"] = kw['data']

    elif kw.has_key("redirect"):
        opts["UploadFrom"] = "redirect"
        opts["TargetURI"] = kw['redirect']
    elif chkOnly != "true":
        raise Exception("Must specify file, data or redirect keywords")

    #print "sendEnd=%s" % sendEnd

    # ---------------------------------
    # now dispatch the job
    return self._submitCmd(id, "ClientPut", **opts)

</t>
<t tx="aum.20060507124316">def _log(self, level, msg):
    """
    Logs a message. If level &gt; verbosity, don't output it
    """
    if level &gt; self.verbosity:
        return

    if not msg.endswith("\n"): msg += "\n"

    self.logfile.write(msg)
    self.logfile.flush()

</t>
<t tx="aum.20060507154638">def runServer(**kw):
    """
    Creates and runs a basic XML-RPC server for FCP access
    
    For keyword parameters, refer FCPXMLRPCServer constructor
    """
    FCPXMLRPCServer(**kw).run()

</t>
<t tx="aum.20060507155016">class FreenetXMLRPCRequestHandler:
    """
    Simple class which exposes basic primitives
    for freenet xmlrpc server
    """
    @others

</t>
<t tx="aum.20060507162314">def __init__(self, fcpnode):

    self.node = fcpnode


</t>
<t tx="aum.20060507162314.2">def get(self, uri, options=None):
    """
    Performs a fetch of a key

    Arguments:
        - uri - the URI to retrieve
        - options - a mapping (dict) object containing various
          options - refer to FCPNode.get documentation
    """
    if options==None:
        options = {}
    
    if options.has_key('file'):
        raise Exception("file option not available over XML-RPC")
    if options.has_key('dir'):
        raise Exception("dir option not available over XML-RPC")

    return self.node.get(uri, **options)

</t>
<t tx="aum.20060507162314.3">def put(self, uri, options=None):
    """
    Inserts data to node

    Arguments:
        - uri - the URI to insert under
        - options - a mapping (dict) object containing various options,
          refer to FCPNode.get documentation
    """
    if options==None:
        options = {}

    if options.has_key('file'):
        raise Exception("file option not available over XML-RPC")
    if options.has_key('dir'):
        raise Exception("dir option not available over XML-RPC")

    return self.node.put(uri, data=data, **options)

</t>
<t tx="aum.20060507162543.1">def genkey(self):
    
    return self.node.genkey()

</t>
<t tx="aum.20060507163143">def testServer():
    
    runServer(host="", fcpHost="10.0.0.1", verbosity=DETAIL)

</t>
<t tx="aum.20060507195029">def usage(msg="", ret=1):

    if msg:
        sys.stderr.write(msg+"\n")

    print "\n".join([
        "Freenet XML-RPC Server",
        "Usage: %s [options]" % sys.argv[0],
        "Options:",
        "  -h, --help",
        "       show this usage message",
        "  -v, --verbosity=",
        "       set verbosity level, values are:",
        "         0 (SILENT) show only 1 line for incoming hits",
        "         1 (FATAL) show only fatal messages",
        "         2 (CRITICAL) show only major failures",
        "         3 (ERROR) show significant errors",
        "         4 (INFO) show basic request details",
        "         5 (DETAIL) show FCP dialogue",
        "         6 (DEBUG) show ridiculous amounts of debug info",
        "  --host=",
        "       listen hostname for xml-rpc requests, default %s" % xmlrpcHost,
        "  --port=",
        "       listen port number for xml-rpc requests, default %s" % xmlrpcPort,
        "  --fcphost=",
        "       set hostname of freenet FCP interface, default %s" \
             % node.defaultFCPHost,
        "  --fcpport=",
        "       set port number of freenet FCP interface, default %s" \
             % node.defaultFCPPort,
        ])

    sys.exit(ret)

</t>
<t tx="aum.20060507195029.1">def main():
    """
    When this script is executed, it runs the XML-RPC server
    """
    import getopt

    opts = {'verbosity': node.INFO,
            'host':xmlrpcHost,
            'port':xmlrpcPort,
            'fcpHost':node.defaultFCPHost,
            'fcpPort':node.defaultFCPPort,
            }

    try:
        cmdopts, args = getopt.getopt(sys.argv[1:],
                                   "?hv:",
                                   ["help", "verbosity=", "host=", "port=",
                                    "fcphost=", "fcpport="])
    except getopt.GetoptError:
        # print help information and exit:
        usage()
        sys.exit(2)
    output = None
    verbose = False
    #print cmdopts
    for o, a in cmdopts:
        if o in ("-h", "--help"):
            usage(ret=0)
        elif o == "--host":
            opts['host'] = a
        elif o == "--port":
            try:
                opts['port'] = int(a)
            except:
                usage("Invalid port number '%s'" % a)
        elif o == "--fcphost":
            opts['fcpHost'] = a
        elif o == "--fcpport":
            opts['fcpPort'] = a
        elif o in ['-v', '--verbosity']:
            print "setting verbosity"
            try:
                opts['verbosity'] = int(a)
                #print "verbosity=%s" % opts['verbosity']
            except:
                usage("Invalid verbosity '%s'" % a)

    #print "Verbosity=%s" % opts['verbosity']

    if opts['verbosity'] &gt;= node.INFO:
        print "Launching Freenet XML-RPC server"
        print "Listening on %s:%s" % (opts['host'], opts['port'])
        print "Talking to Freenet FCP at %s:%s" % (opts['fcpHost'], opts['fcpPort'])

    try:
        runServer(**opts)
    except KeyboardInterrupt:
        print "Freenet XML-RPC server terminated by user"



</t>
<t tx="aum.20060509184020.1">@others

</t>
<t tx="aum.20060509184020.2">def toBool(arg):
    try:
        arg = int(arg)
        if arg:
            return "true"
    except:
        pass
    
    if isinstance(arg, str):
        if arg.strip().lower()[0] == 't':
            return "true"
        else:
            return "false"
    
    if arg:
        return True
    else:
        return False

</t>
<t tx="aum.20060509223528">@language python
# ***********************************************************************
#
# IMPORTANT NOTE!
#
# This code is best viewed and edited with the Leo meta-structural editor.
#
# If you look at this file raw with a regular text editor like
# emacs or vim, it will look like 4500 lines of spaghetti and
# will annoy you to no end.
#
# But if you open it with Leo, it will reveal itself as a clean and
# easily-understandable tree of classes and methods.
#
# Leo runs on *nix and Windoze systems, and is one amazing editor
# that leverages your effort by giving you easy multi-dimensional
# views of code. Also, it can integrate seamlessly with Emacs.
#
# You can get Leo from http://leo.sourceforge.net
#
# **********************************************************************

"""
Module freenet


Provides a high-level Python interface to the Freenet network,
fcptools backend has been replaced with totally Python socket access.

Portions of code, particularly relating to splitfiles and FEC, lifted
from GJ and fish - hearty thanks to you both for saving me from
painful duplicated effort.

This module and its component files (except GJ's and Fish's stuff)
written By David McNab &lt;david@rebirthing.co.nz&gt;
Copyright (c) 2003, all rights reserved.

Released under the GNU General Public License, www.gnu.org

This softare comes with absolutely no warranty. Use only at your
own risk. If it fries your hard disk, destroys your files, lands
you in jail, causes your liver to shut down etc - don't blame me.

"""

@others
</t>
<t tx="aum.20060509223528.1">import fnmatch, glob, md5, mimetypes, os, os.path, pickle
import random, re, socket, string, sys, tempfile
import thread, threading, Queue, time, types, warnings
import traceback, struct, base64

from UserString import MutableString
from pdb import set_trace

</t>
<t tx="aum.20060509223528.2">version = "0.2.5"

fcpRoundRobin=1
fcpRandom=2
fcpLoad=3


############################################################
# FCP Server dependant constants
FCP_HEADER_BYTES="\x00\x00\x00\x02"

# UNDOCUMENTED
# Causes _fec_clientGet and FCP_ClientPut
# to delete the local copy of the key from
# the node's data store before executing.
# see freenet.message.client.ClientRequest
FLAG_DELETELOCAL = 0x01

# MetadataHint kind constants
# defined in freenet.message.client.MetadataHint
MDH_DATA = 1
MDH_REDIRECT = 2
MDH_DATEREDIRECT = 3
MDH_SPLITFILE = 4
MDH_TOODUMB = 5
MDH_ERROR = 6

# Maximum size for non-CHK keys
MAX_SVK_SIZE = 32768

# flag to indicate if we've connected to an FCP host
#connected = False

logLevel = 2

defaultHost = "127.0.0.1"
defaultPort = 8481
defaultHtl = 15

defaultMaxSiteThreads = 8

defaultAllowSplitfiles = 1

# vars for FEC

</t>
<t tx="aum.20060509223528.3">class node:
    """
    'node' is the main class for working with Freenet.
    
    It contains methods for inserting and retrieving files and even
    entire freesites, plus a whole raft of lower level methods.
    """
    @others
</t>
<t tx="aum.20060509223528.4">def __init__(self, host=None, port=None, htl=20, **kw):
    """
    Constructs the freenet.node object
    
    Arguments:
     - host - hostname of freenet FCP interface, defaults to
       the global module variable 'defaultHost'
     - port - port of freenet FCP interface, defaults to
       the global module variable 'defaultPort'
     - htl - hops-to-live for insert/retrieve operations, defaults
       to 20
    
    Keywords:
     - future - for putsite operations, sets the default number of days
       in the future for which to insert freesites, defaults to 0
    """
    global defaultHost
    global defaultPort
    if host == None:
        self._host = defaultHost
    else:
        self._host = host
    if port == None:
        self._port = defaultPort
    else:
        self._port = port
    self._htl = htl
    self._recvbuf = ''
    self._recvbuflen = 0
    self._sskSuffix = "PAgM"
    self._isEntropy = 0
    self._handshake()

    # accept some keywords
    self._future = kw.get("future", 0)
    self._allowSplitfiles = kw.get("allowSplitfiles", 1)

    self._siteType = kw.get('siteType', 'dbr')
    self._edition = kw.get('edition', 0)
    self._editionMaxTries = kw.get('editionMaxTries', 0)
    
    self.metadataHeader = "Version\nRevision=1\nEndPart\n"

</t>
<t tx="aum.20060509223528.5">def get(self, keyuri, htl=None, raw=False, past=0, numtries=1):
    """
    retrieves a key from Freenet

    Arguments:
     - uri - uri of key to request
     - htl - hops to live - default 20
     - raw - whether to fetch the raw key, and not interpret metadata (false)
     - past - number of periods in the past to regress (dbr keys only)

    Returns:
     - a freenet.key object containing the retrieved key

    Exceptions:
     - FreenetFcpError - details in error value
    """

    if htl == None:
        htl = self._htl

    # Fetch and return a key object
    if raw:
        # easy case
        return self._getraw(keyuri, htl, numtries=numtries)
    else:
        return self._getsmart(keyuri, htl, 'text/plain',
                              past=past, numtries=numtries)

</t>
<t tx="aum.20060509223528.6">def put(self,
        keydata=None, keymeta=None,
        keyuri='CHK@',
        htl=None, allowSplitfiles=defaultAllowSplitfiles,
        **args):

    """
    Smarter key insertion routine that inserts via splitfiles
    and FEC if needed

    Arguments:
     - keydata - string of data to insert. Defaults to ''
     - keymeta - string of metadata to insert. Defaults to a minimal
       metadata file
     - keyuri - uri object or URI string to insert as. If None or '',
       inserts the key as a CHK
     - htl - hops-to-live, default 20 (I think)
    Keywords:
     - mimetype - if keymeta is None or '', a metadata block is created
       which declares the default doc to have this mimetype.
     - host - lets you override host setting
     - port - lets you override port setting
    Returns:
     - IF called statically, returns a complete key object containing
       the key, its data, metadata and uri

    NOTE!!! You no longer have to worry about the 32k size limit for KSK, SVK and SSK
    keys. If you try to insert something bigger than 32k, this method will transparently
    insert it as a CHK, then insert a redirector at your original URI. So feel free to
    insert any size key under KSK, SVK and SSK - the get() method can get it back
    transparently.
    """

    # Set defaults
    if keydata == None:
        keydata = ''
    if keymeta == None or (type(keymeta) == type("") and keymeta == ''):
        keymeta = metadata()
        mimetype = args.get('mimetype', None)
        if mimetype:
            keymeta.add("", mimetype=mimetype)
    if not isinstance(keyuri, uri):
        if keyuri == None or (type(keyuri) == type("") and keyuri == ''):
            keyuri = uri('CHK@')
    if htl == None:
        htl = getattr(self, '_htl', defaultHtl)

    if allowSplitfiles and self._isEntropy:
        allowSplitfiles = 0

    # if KSK, SVK or SSK, and &gt;32k, insert a CHK redirect
    uriTxt = str(keyuri)
    if uriTxt[0:4] in ['SSK@', 'SVK@', 'KSK@'] and len(keydata) &gt;= 32768:

        LOGMSG(3, "key '%s' is too big - redirecting to CHK" % uriTxt)

        # insert as a CHK
        kChk = self.put(keydata, keymeta, 'CHK@', htl, allowSplitfiles, **args)
        uriChk = str(kChk.uri)

        # create redirection metadata
        metaRedir = metadata()
        metaRedir.add('', 'Redirect', target=uriChk)

        # insert the redirector at original requested URI
        k = self.put('', metaRedir, uriTxt, htl, 0, **args)

        #if not k:
        #    LOGMSG(3, "************ put() returned nothing?!?!?")

        # all done
        return k
    
    # If key is large, insert via fish
    if len(keydata) &lt;= 1024*1024 or not allowSplitfiles:
        k = self.putraw(keydata, keymeta, keyuri, htl)
        #if not k:
        #    LOGMSG(3, "************ putraw() returned nothing?!?!?")
        return k
    else:
        LOGMSG(3, "Inserting data via FEC")

        # Big bugger - insert with fish's FCP FEC magic
        newuri = self._fecput(str(keyuri), keydata, htl)

        # fetch it back - raw - and return as key object
        k = self.get(newuri, htl, True)

        return key(keydata, k.metadata, newuri, host=self._host, port=self._port)



</t>
<t tx="aum.20060509223528.7">def getseq(self, keyprefix, startnum=0, numtries=5, htl=None, raw=False):
    """
    Retrieves a sequenced key.
    
    Sequenced keys allow for implementation of in-Freenet 'queues',
    to/from which different parties can insert/retrieve messages.
    
    Example:
      - KSK@somequeuename-1, KSK@somequeuename-2, ...
    
    This function attempts to retrieve the key URI &lt;keyprefix&gt;&lt;startnum&gt;.
    If this fails, then tries to get &lt;keyprefix&gt;&lt;startnum+1&gt; right up to
    &lt;keyprefix&gt;&lt;startnum+numtries-1&gt;
    
    If a key is successfully retrieved, it is returned.
    Otherwise, the FreenetKeySequenceFail exception occurs
    
    Arguments:
     - keyprefix - the prefix of the URI queue. For instance, if you
       are fetching keys 'KSK@myqueue-1', 'KSK@myqueue-2'..., then
       this argument should be 'KSK@myqueue-'. Note the trailing
       hyphen - otherwise this method would try 'KSK@myqueue1', 'KSK@myqueue2'...
     
     - startnum - the starting sequence number of the key. For instance,
       if keyprefix is 'KSK@myqueue-', and startnum is 15, then this
       method will try 'KSK@myqueue-15', 'KSK@myqueue-16', ...
       Defaults to 0
     
     - numtries - sets a limit on how far to look ahead in the queue.
       For instance, with keyprefix = 'KSK@myqueue-', and startnum = 15,
       and numtries = 7, this method will try 'KSK@myqueue-15',
       'KSK@myqueue-16', ..., 'KSK@myqueue-21' inclusive.
       Defaults to 5
     
     - htl - determines the HTL value to use in the key fetches.
       Defaults to the node object's HTL setting.
    
     - raw - if set, prevents smart key handling (such as DateRedirects,
       Redirects, SplitFiles etc. Defaults to False.
    """
    keyprefix = str(keyprefix)
    startnum = int(startnum)
    numtries = int(numtries)
    
    trynum = 0
    
    while trynum &lt; numtries:
        tryuri = keyprefix + str(startnum+trynum)
        try:
            return self.get(tryuri, htl, raw)
        except FreenetDataNotFound, FreenetRouteNotFound:
            pass
        except:
            raise
        trynum = trynum + 1
    raise FreenetDataNotFound("%s[%d-%d]" % (keyprefix, startnum, startnum+numtries-1))
</t>
<t tx="aum.20060509223528.8">def putseq(self, keyprefix, startnum=0, numtries=5, keydata='', keymeta=None, htl=None, **kw):
    """
    Inserts a sequenced key.
    
    Sequenced keys allow for implementation of in-Freenet 'queues',
    to/from which different parties can insert/retrieve messages.
    
    Example:
      - KSK@somequeuename/1, KSK@somequeuename/2, ...
    
    This function attempts to insert the key URI &lt;keyprefix&gt;&lt;startnum&gt;.
    If this fails, then tries to insert &lt;keyprefix&gt;&lt;startnum+1&gt; right up to
    &lt;keyprefix&gt;&lt;startnum+numtries-1&gt;
    
    If a key is successfully inserted without collisions, it is returned.
    Otherwise, the FreenetKeySequenceFail exception occurs
    
    Arguments:
     - keyprefix - the prefix of the URI queue. For instance, if you
       are inserting keys 'KSK@myqueue-1', 'KSK@myqueue-2'..., then
       this argument should be 'KSK@myqueue-'. Note the trailing
       hyphen - otherwise this method would try 'KSK@myqueue1', 'KSK@myqueue2'...
     
     - startnum - the starting sequence number of the key. For instance,
       if keyprefix is 'KSK@myqueue-', and startnum is 15, then this
       method will try 'KSK@myqueue-15', 'KSK@myqueue-16',
       Defaults to 0
     
     - numtries - sets a limit on how far to look ahead in the queue.
       For instance, with keyprefix = 'KSK@myqueue-', and startnum = 15,
       and numtries = 7, this method will try 'KSK@myqueue-15',
       'KSK@myqueue-16', ..., 'KSK@myqueue-21' inclusive.
       Defaults to 5.
       Set to -1 to try endlessly
     
     - keydata - data of key to insert
     
     - keymeta - metadata string

     - htl - determines the HTL value to use in the key inserts
       Defaults to the node object's HTL setting.
    """
    keyprefix = str(keyprefix)
    startnum = int(startnum)
    numtries = int(numtries)

    allowSplitfiles = kw.get('allowSplitfiles', 1)

    # if KSK, SVK or SSK, and &gt;32k, insert a CHK redirect
    uriTxt = str(keyprefix)
    #if uriTxt[0:4] in ['SSK@', 'SVK@', 'KSK@'] and len(keydata) &gt;= 32768:
    if len(keydata) &gt;= 32768:

        LOGMSG(3, "key '%s' is too big - redirecting to CHK" % uriTxt)

        # insert as a CHK
        kChk = self.put(keydata, keymeta, 'CHK@', htl, allowSplitfiles, **kw)
        uriChk = str(kChk.uri)

        # create redirection metadata
        metaRedir = metadata()
        metaRedir.add('', 'Redirect', target=uriChk)

        # frig - set up to insert the pointer key's data/metadata
        keydata = ''
        keymeta = metaRedir
        
        # insert the redirector at original requested URI
        #k = self.put('', metaRedir, uriTxt, htl, 0, **args)

        #if not k:
        #    LOGMSG(3, "************ put() returned nothing?!?!?")

        # all done
        #return kChk
    
    
    trynum = 0
    while numtries &lt; 0 or trynum &lt; numtries:
        tryuri = keyprefix + str(startnum+trynum)
        try:
            k = self.put(keydata, keymeta, tryuri, htl=None)
            #if not k:
            #    LOGMSG(3, "************ put() returned nothing?!?!?")
            k.seq = startnum + trynum
            return k

        except FreenetKeyCollision, FreenetRouteNotFound:
            pass
        except:
            raise
        trynum = trynum + 1
    raise FreenetKeyInsertFail("%s[%d-%d]" % (keyprefix, startnum, startnum+numtries-1))


</t>
<t tx="aum.20060509223528.9">def putraw(self, *args, **kwds):
    """
    Inserts a key into freenet - raw, without any splitfiles or FEC rubbish

    Calling options:
     1. Insert a URI object:
        - Arguments:
           - key - uri object of key to insert
           - uri - if None, uses key's uri attrib. IF this attrib is none,
             inserts the key as a CHK and stores that CHK into the key object
           - htl - Hops To Live, defaults to 20
        - Returns:
           - uri object that key is inserted under
     2. Insert raw data and metadata:
        - Arguments:
           - keydata - string of data to insert
           - meta - string of key metadata (or a metadata object)
           - uri - uri object or string to insert under. If not provided,
             the key is inserted as a CHK
           - htl - Hops to Live for insert, default 20
        - Returns:
           - key object for inserted key

    Exceptions:
      - FreenetFcpError - details in exception's 'value' attribute
    """

    # First validation
    #set_trace()
    lenargs = len(args)
    if lenargs == 0:
        raise FreenetFcpError("fcp._put: must give key data, uri, [htl]")

    # Action depends on arg type
    keydata = args[0]
    if isinstance(keydata, key):
        # got a key object - insert it
        if lenargs &gt; 1:
            keyuri = args[1]
            if keyuri == None:
                keyuri = keydata.uri
            if keyuri == None:
                keyuri = ''
            if lenargs &gt; 2:
                htl = args[2]
            else:
                htl = None
        else:
            keyuri = keydata.uri
            if keyuri == None:
                keyuri = ''
            if str(keyuri) == '':
                keyuri = 'CHK@'
            htl = self.htl

        # allow keywords args
        htl = kwds.get('htl', htl)
        
        meta = str(keydata.metadata)
        inserteduri = self._put(str(keydata), str(meta), str(keyuri), htl)
        keydata.uri = inserteduri

        #if not inserteduri:
        #    LOGMSG(3, "************ _put() returned nothing?!?!?")

        return inserteduri
    else:
        # just raw data - insert it and make up a key object
        if lenargs &gt; 1:
            meta = metadata(args[1])
            if lenargs &gt; 2:
                keyuri = args[2]
                if keyuri == None:
                    keyuri = ''
                if str(keyuri) == '':
                    keyuri = 'CHK@'
                keyuri = uri(keyuri, pub=self._sskSuffix)
                if lenargs &gt; 3:
                    htl = args[3]
                else:
                    htl = None
            else:
                keyuri = 'CHK@'
                htl = None
        else:
            meta = ''
            keyuri = 'CHK@'
            htl = None
        
        # allow keywords args
        htl = kwds.get('htl', htl)

        inserteduri = self._put(str(keydata), str(meta), str(keyuri), htl)

        #if not inserteduri:
        #    LOGMSG(3, "*********!!! _put() returned nothing?!?!?")

        #set_trace()
        keyobj = key(keydata, meta, inserteduri, host=self._host, port=self._port)
        return keyobj

</t>
<t tx="aum.20060509223528.10">def genkeypair(self):
    """
    Generates an SVK keypair, needed for inserting SSK freesites

    Arguments:
     - none
    Returns:
     - Keypair as (public, private) tuple
    Exceptions:
     - FreenetFcpError - details in error value
    """

    self._connect()
    self._sendline("GenerateSVKPair")
    self._sendline("EndMessage")

    # We should get back some keys
    pubkey = None
    privkey = None
    resp = self._recvline()
    if resp != "Success":
        raise FreenetFcpError("makekeypair: expecting 'Success', got '%s'" % resp)
    while 1:
        resp = self._recvline()
        if resp == 'EndMessage':
            break
        fld, val = resp.split("=", 1)
        if fld == 'PublicKey':
            pubkey = val
        elif fld == 'PrivateKey':
            privkey = val
        else:
            #print "makekeypair: strange node response '%s'" % resp
            continue
            raise FreenetFcpError("makekeypair: strange node response '%s'" % resp)

    if pubkey == None:
        raise FreenetFcpError("makekeypair: node sent no public key")
    if privkey == None:
        raise FreenetFcpError("makekeypair: node sent no private key")

    return pubkey, privkey
</t>
<t tx="aum.20060509223528.11">def invertprivate(self, priv):
    """
    Converts an SSK private key into its corresponding pubkey

    Arguments:
     - privkey - SSK private key string
    Returns:
     - public key
    Exceptions:
     - FreenetFcpError - details in error value
    """

    self._connect()
    self._sendline("InvertPrivateKey")
    self._sendline("Private=%s" % priv)
    self._sendline("EndMessage")

    # We should get back some keys
    pubkey = None
    resp = self._recvline()
    if resp != "Success":
        raise FreenetFcpError("makekeypair: expecting 'Success', got '%s'" % resp)
    while 1:
        resp = self._recvline()
        if resp == 'EndMessage':
            break
        fld, val = resp.split("=", 1)
        if fld in ['Public', 'PublicKey']:
            pubkey = val
        else:
            #print "makekeypair: strange node response '%s'" % resp
            continue
            raise FreenetFcpError("makekeypair: strange node response '%s'" % resp)

    if pubkey == None:
        raise FreenetFcpError("makekeypair: node sent no public key")

    return pubkey
</t>
<t tx="aum.20060509223528.12">def genchk(self, keydata, meta=None):
    """
    Calculates the CHK for a block of data and metadata,
    
    genchk(data, metadata)

    Useful if you need to know a key's CHK before you insert it.

    Option 1 - pass in key object, CHK uri gets added to object:
     - Arguments:
       - keyobj - a freenet.key instance
     - Returns:
       - generated URI object
     - Note:
       - The key object is updated by having the CHK uri added to it

    Option 2 - pass in raw data and metadata strings, get back a URI object
     - Arguments:
       - data - string of raw data
       - metadata - string of raw metadata (default '')
     - Returns:
       - a uri object, being the CHK key uri

    Exceptions:
     - FreenetFcpError - details in exception's value attrib
    """

    if isinstance(keydata, key):
        if meta != None:
            raise FreenetFcpError("genchk: invalid arguments - RTFD")
        rawdata = str(keydata)
        rawmeta = str(keydata.metadata)
        chk = self._genchk(rawdata, rawmeta)
        keydata.uri = chk
        return chk
    else:
        rawdata = str(keydata)
        if meta == None:
            rawmeta = ''
        else:
            rawmeta = str(meta)
        chk = self._genchk(rawdata, rawmeta)
        return chk
</t>
<t tx="aum.20060509223528.13">def keyexists(self, keyuri, htl=None):
    """
    Attempts to fetch key from freenet.

    Arguments:
     - keyuri - uri object or URI string of key
     - htl - hops-to-live
    Returns:
     - True if key exists, or False if it couldn't be retrieved
    """

    #if not isinstance(self, node):
    #    inst = node()
    #    return inst.keyexists(keyuri, htl)

    if htl == None: htl = self._htl
    self._connect()
    try:
        self._sendline("ClientGet")
        self._sendline("URI=%s" % str(keyuri))
        self._sendline("HopsToLive=%d" % htl)
        self._sendline("EndMessage")
    
        # wait for response
        while 1:
            resp = self._recvline()
            if resp == 'Restarted':
                continue
            elif resp == 'DataFound':
                self._disconnect()
                return True
            else:
                break
    except:
        pass
    self._disconnect()
    return False
</t>
<t tx="aum.20060509223528.14">def getsite(self, siteuri=None, todir=None, docname=None, **args):
    """
    Retrieves a freesite, lock, stock'n'barrel.

    Arguments (not required if instance vars present):
     - siteuri - full URI of site to retrieve
     - todir - directory to store the retrieved site
       Note - this direcctory must already exist.
    Keywords:
     - past - number of time intervals (default 0) to regress
       when retrieving the site. Note that most DBR sites work
       at offset 0, increment 86400 (1 day)
     - htl - hops to live - how deeply to delve within the Freenet
       for retrieving this site
     - docname - only used during recursive calls - ignore this
     - host - FCP host to use, defaults to constructor arg
     - port - FCP port to use - defaults to constructor arg
    Returns:
     - True if retrieval succeeded, False if failed
    Note:
     - Site's files will be written *into* directory 'todir'
       So if you're fetching 'SSK@blahblah/somesite', you should
       perhaps create a directory called 'somesite' somewhere first.
    """
    if not args.has_key('host'):
        args['host'] = self._host
    if not args.has_key('port'):
        args['port'] = self._port
    if not args.has_key('sskSuffix'):
        args['sskSuffix'] = self._sskSuffix

    siteobj = site(**args)
    return siteobj.get(siteuri, todir, docname)
</t>
<t tx="aum.20060509223528.15">def putsite(self, fromdir=None, **args):
    """
    Insert this site object into freenet as a complete freesite
    Arguments:
     - fromdir - directory to insert form. If not given, attempts to
       take this from instance variables
    Keywords:
     - host - FCP host to use, defaults to constructor arg
     - port - FCP port to use - defaults to constructor arg
     - name (optional, defaults to 'site'
       called, otherwise taken from instance var
     - htl - optional, default 20
     - pub - ssk public key
     - priv - ssk private key
     - future - optional, defaultx to the 'future' constructor keyword 
     - default - file to use as site default, default 'index.html'
     - splitsize - size of splitfile chunks, default 262144
     - offset - dbr offset, default 0
     - increment - dbr increment, default 86400
     - maxthreads - maximum number of parallel insert threads
     - allowSplitfiles - default 1, allow large files to be split
     - files - dict of files to insert into the freesite.

       You may only specify this keyword if you don't pass a 'fromdir' arg.
       
       The keys of the dict are
       relative paths (as they appear, for example:
         - the 'path/to/file.txt' in 'SSK@BblahblahPAgM/fred//path/to/file.txt'.
       The value is a dict containing the keys:
         - mimetype - a standard mimetype string, AND one of:
             - raw - a raw string comprising the file's content, OR
             - fullpath - an absolute path on the host filesystem
       Example::

         { 'index.html' ;     {'mimetype' : 'text/html',
                               'raw' : '&lt;html&gt;&lt;body&gt;Here is index.html&lt;/body&gt;&lt;/html&gt;'
                               },
           '/fred/mary.txt' : {'mimetype' : 'text/plain',
                               'raw' : 'This is fred/mary.txt'
                               },
           }

    Returns:
     - a uri object for the inserted site

    After any insertion attempt, the pub/priv keypair, htl, splitsize, offset
    and increment get stored in a pickle in file /.freesiterc in the site's
    directory - but only if the caller did not pass a fileset
    """
    if not args.has_key('host'):
        args['host'] = self._host
    if not args.has_key('port'):
        args['port'] = self._port
    if not args.has_key('htl'):
        args['htl'] = self._htl
    if not args.has_key('future'):
        args['future'] = self._future
    if not args.has_key('allowSplitfiles'):
        args['allowSplitfiles'] = self._allowSplitfiles

    if not args.has_key('siteType'):
        args['siteType'] = self._siteType
    if not args.has_key('edition'):
        args['edition'] = self._edition
    if not args.has_key('editionMaxTries'):
        args['editionMaxTries'] = self._editionMaxTries
    if not args.has_key('maxthreads'):
        args['maxthreads'] = defaultMaxSiteThreads

    if args.has_key('files'):
        files = args['files']
        del args['files']
    else:
        files = None

    if not args.has_key('sskSuffix'):
        args['sskSuffix'] = self._sskSuffix

    siteobj = site(**args)
    
    if files:
        return siteobj.put(fromdir, files=files)
    else:
        return siteobj.put(fromdir)

</t>
<t tx="aum.20060509223528.16">def _connect(self):
    try:
        self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self._sock.connect((self._host, self._port))
        self._sendhdr()
    except:
        raise FreenetFcpConnectError("Failed to connect to '%s:%d'" % (self._host, self._port))

    self._recvbuf = ''
    self._recvbuflen = 0

</t>
<t tx="aum.20060509223528.17">def _disconnect(self):
    self._sock.close()
    self._recvbuf = ''
    self._recvbuflen = 0

</t>
<t tx="aum.20060509223528.18">def _rawtransaction(self, txdata):
    """
    Sends a raw block of data to node, and returns raw response.
    """
    self._send(txdata)
    rx = self._recv(32768)
    self._disconnect()
    return rx
</t>
<t tx="aum.20060509223528.19">def _handshake(self):
    self._connect()
    self._sendline("ClientHello")
    self._sendline("EndMessage")

    line = self._recvline()
    if line != 'NodeHello':
        LOGMSG(2, "Bad resp: '%s'" % line)
        raise FreenetFcpError(
            "I'm not sure that '%s:%s' is a real Freenet or Entropy FCP Port" % (self._host, self._port))
    while 1:
        line = self._recvline()
        if line == 'EndMessage':
            self._disconnect()
            return None
        try:
            kwd, val = line.split("=", 1)
        except:
            raise FreenetInvalidHelloResponse(line)

        LOGMSG(5, "line=%s" % line)
        
        # store node parameters
        if kwd == 'MaxFileSize':
            self.maxFileSize = int(val, 16)
            LOGMSG(5, "maxFileSize=%x" % self.maxFileSize)
        elif kwd == 'Node':
            self.nodeType, self.nodeVers = val.split(",", 1)
            if self.nodeType.lower() == 'entropy':
                self._sskSuffix = "BCMA"
                self._isEntropy = 1
            else:
                self._sskSuffix = "PAgM"
            LOGMSG(5, "nodeType=%s" % self.nodeType)
            LOGMSG(5, "nodeVers=%s" % self.nodeVers)
            LOGMSG(5, "sskSuffix=%s" % self._sskSuffix)
        elif kwd == 'Protocol':
            self.nodeProtocol = val
            LOGMSG(5, "nodeProtocol=%s" % self.nodeProtocol)
            
    return None

    resp = ''
    flds = {}
    while 1:
        x = self._recvline()
        if x == 'EndMessage':
            self._disconnect()
            self.nodeinfo = flds
            return
        fld, val = x.split("=", 1)
        flds[fld] = val
    pass</t>
<t tx="aum.20060509223528.20">def _getsmart(self, keyuri, htl=20, mimetype='text/plain', **kw):
    """
    Recursive method which follows redirects and msk chains,
    reassembles splitfiles, till the target doc is retrieved
    
    Arguments:
        - keyuri - the URI to fetch
        - htl - default 20
        - mimetype - the default mimetype to assign to the data
    
    Keywords:
        - past - only applies to DBR - number of periods in the past to regress, default 0
    """

    past = kw.get('past', 0)
    numtries = kw.get('numtries', 1)

    if not isinstance(keyuri, uri):
        keyuri = uri(keyuri, pub=self._sskSuffix)

    rawuri = str(keyuri).split("//", 1)[0]

    k = self._getraw(rawuri, htl, numtries=numtries)
    doc = keyuri.mskpath.split('//')[0] # first part of MSK path

    if k.metadata:
        tgt = k.metadata.targeturi(doc, -past)
        # grab a mimetype if one given

        if k.metadata.map.has_key(doc):
            if k.metadata.map[doc].has_key('mimetype'):
                mimetype = k.metadata.map[doc]['mimetype']
    else:
        k.mimetype = mimetype
        return k

    if tgt == None:
        k.mimetype = mimetype
        return k # we're at final destination with this key

    elif isinstance(tgt, uri):
        # re-fucking-cursion
        return self._getsmart(tgt, htl, mimetype, **kw)

    elif type(tgt) is types.ListType:
        # We've got a splitfile - dive off into GJ-land for now
        f = tempFilename()
        for trynum in range(0, numtries):
            if self._fec_getFile(str(keyuri), f, self._host, self._port, htl, numtries=numtries):
                fd = open(f)
                data = fd.read()
                fd.close()
                os.unlink(f)
    
                #set_trace()
                m = metadata()
                m.add('')
                km = k.metadata.map['']
                m.set('', 'Info.Format', km.get('Info.Format', 'text/plain'))
                if km.has_key('Info.Description'):
                    m.set('', 'Info.Description', km['Info.Description'])
                k = key(data, m, keyuri, host=self._host, port=self._port)
                k.mimetype = km.get('Info.Format', mimetype)
                return k
        raise FreenetFcpError("getsmart: FEC error: %s" % keyuri)
    else:
        raise FreenetFcpError("getsmart: strange uri target on %s" % keyuri)
</t>
<t tx="aum.20060509223528.21">def _getraw(self, keyuri, htl=None, numtries=1):
    """
    retrieves a key from Freenet, with no interpretation of
    metadata
    
    Arguments:
     - uri - uri of key to request
     - htl - hops to live - default 20
     - numtries - maximum number of tries to get this key, default 1
    Returns:
     - tuple (key, metadata)
    Exceptions:
     - FreenetFcpError - details in error value
    """

    if htl == None:
        htl = self._htl
    data = ''
    meta = ''

    # 'normalise' the uri
    keyuri = uri(keyuri, pub=self._sskSuffix)

    # connect and send key request
    self._connect()
    self._state = 'wait' # 'wait', 'hdr', 'meta' or 'data'

    for trynum in range(0, numtries):
        try:
            self._sendline("ClientGet")
            self._sendline("URI=%s" % str(keyuri))
            self._sendline("HopsToLive=%x" % htl)
            self._sendline("EndMessage")
        
            # wait for response
            while 1:
                if self._state == 'wait':
                    resp = self._recvline()
                    if resp == 'URIError':
                        raise FreenetFcpError("Node dislikes URI '%s'" % keyuri)
                    elif resp == 'Restarted':
                        self._state = 'waitrestart'
                        continue
                    elif resp == 'DataNotFound':
                        raise FreenetDataNotFound("Key Not Found: '%s'" % keyuri)
                    elif resp == 'RouteNotFound':
                        raise FreenetRouteNotFound("Route Not Found: '%s'" % keyuri)
                    elif resp == 'DataFound':
                        self._state = 'hdr'
                        continue
                    else:
                        raise FreenetFcpError("Strange node response: '%s'" % resp)
    
                elif self._state == 'waitrestart':
                    resp = self._recvline()
                    if resp.startswith("Timeout="):
                        LOGMSG(4, "Got '%s'" % resp)
                        continue
                    elif resp == 'EndMessage':
                        self._state = 'wait'
                        continue
    
                elif self._state == 'hdr':
                    # receive data header
                    datalen = 0
                    metalen = 0
                    data = ''
                    while 1:
                        resp = self._recvline()
                        if resp == 'EndMessage':
                            break # move on and get data
                        fld, val = resp.split("=", 1)
                        if fld == 'DataLength':
                            datalen = int(val, 16)
                        elif fld == 'MetadataLength':
                            metalen = int(val, 16)
    
                    # IIRC, 'DataLength' includes metadata - need to adjust
                    datalen -= metalen
    
                    if metalen &gt; 0:
                        self._state = 'meta'
                    else:
                        self._state = 'data'
                    continue
    
                elif self._state == 'meta':
                    meta = self._recvkeydata(metalen)
                    if meta == None:
                        # whoops - restarted - back to start
                        self._state = 'wait'
                        continue
                    # got metadata just fine
                    self._state = 'data'
                    continue
    
                elif self._state == 'data':
                    #set_trace()
                    data = self._recvkeydata(datalen)
                    if data == None:
                        # whoops - restarted - back to start
                        self._state = 'wait'
                        self._recvbuf = ''
                        continue
    
                # everything has arrived just as we want it
                self._disconnect()
                return key(data, meta, keyuri, host=self._host, port=self._port)

        except FreenetDataNotFound, FreenetRouteNotFound:
            LOGMSG(3, "Failed to retrieve %s, try %d of %d" % (keyuri, trynum+1, numtries))
            trynum += 1
        except:
            self._disconnect()
            raise

</t>
<t tx="aum.20060509223528.22">def _put(self, rawdata, rawmeta, keyuri, htl=None):
    """
    Lower-level key insert routine.
    Arguments:
     - rawdata - raw key data to insert
     - rawmeta - metadata string or object
     - keyuri - uri string or object
     - htl - Hops to Live, defaults to self.htl, which defaults to 20
    Returns:
     - uri object for inserted key
    Exceptions:
     - FreenetFcpError - details in exception's 'value' attribute
    """

    if rawdata == None:
        rawdata = ''
    if rawmeta == None:
        rawmeta = ''
    if keyuri == None:
        keyuri = ''
    else:
        keyuri = str(keyuri)
    if rawdata == '' and rawmeta == '' and keyuri == '':
        raise FreenetFcpError("_put: no data, no metadata, no uri")

    # if no uri, default to inserting CHK
    if keyuri == '':
        keyuri = 'CHK@'

    if htl == None:
        htl = self._htl
    if htl == None:
        htl = 20

    collision = 0 # flag - indicates collision with different content

    metalen = len(rawmeta)
    datalen = len(rawdata) + metalen

    # send data and metadata to node
    self._connect()
    self._sendline("ClientPut")
    self._sendline("HopsToLive=%x" % htl)
    self._sendline("URI=%s" % str(keyuri))
    self._sendline("DataLength=%x" % datalen)
    if metalen &gt; 0:
        self._sendline("MetadataLength=%x" % metalen)
    self._sendline("Data")
    if metalen &gt; 0:
        self._send(rawmeta)
    self._send(rawdata)

    # Await confirmation
    while 1:
        resp = self._recvline()
        if resp == 'URIError':
            raise FreenetFcpError("fcp._put: Note dislikes uri '%s'" % keyuri)
        elif resp == 'Restarted':
            while 1:
                resp = self._recvline()
                if resp == 'EndMessage':
                    break
                else:
                    continue
            continue
        elif resp == 'RouteNotFound':
            raise FreenetRouteNotFound("Key '%s'" % keyuri)
        elif resp == 'SizeError':
            raise FreenetFcpError("Key '%s' limited to 32k of data" % keyuri)
        elif resp == 'Pending':
            # discard remainder of 'Pending' message
            while self._recvline() != 'EndMessage':
                pass
            continue
        elif resp != 'Success' and resp != 'KeyCollision':
            raise FreenetFcpError("fcp._put: expected 'Success', got '%s'" % resp)

        if resp == 'KeyCollision':
            collision = 1

        pubkey = None
        privkey = None
        while 1:
            resp = self._recvline()
            fld = resp.split("=")
            if fld[0] == 'URI':
                keyuri = uri(fld[1], pub=self._sskSuffix)
            elif fld[0] == 'PublicKey':
                pubkey = fld[1]
            elif fld[0] == 'PrivateKey':
                privkey = fld[1]
            elif resp == 'EndMessage':
                break
        break

    # got success or collision packet from node
    # TODO - incorporate better handling of KeyCollision
    if collision:
        # retrieve the key back and compare
        retrkey = self._getraw(keyuri, htl)
        if retrkey.data != rawdata or retrkey.metadata != rawmeta:
            # what we got back ain't what we stuck in - this is not good
            LOGMSG(2, "fcp._put: collision - existing data at key '%s' differs" % str(keyuri))
            raise FreenetKeyCollision("Key '%s' is already present with differing data" % str(keyuri))
        else:
            LOGMSG(3, "fcp._put: collision - existing data at key '%s' is identical - no problem" % str(keyuri))

    if pubkey != None:
        keyuri.sskpub = pubkey
    if privkey != None:
        keyuri.sskpriv = privkey
    return keyuri
</t>
<t tx="aum.20060509223528.23">def _send(self, buf):
    #set_trace()
    return self._sock.send(buf)
</t>
<t tx="aum.20060509223528.24">def _sendline(self, line):
    LOGMSG(4, "to host: '%s'" % line)
    self._send(line + "\n")
</t>
<t tx="aum.20060509223528.25">def _sendhdr(self):
    self._send('\x00\x00\x00\x02')
</t>
<t tx="aum.20060509223528.26">def _recv(self, max):

    #LOGMSG(4, "_recv: wanting %d bytes" % max)
    buf = self._sock.recv(max)
    #LOGMSG(4, "_recv: got %d bytes" % max)
    return buf

    chars = []
    rcvd = 0
    try:
        while rcvd &lt; max:
            c = self._sock.recv(1)
            chars.append(c)
            rcvd = rcvd + 1
    except:
        LOGMSG(4, "_recv: timed out")
    LOGMSG(4, "_recv: got %d bytes" % rcvd)
    buf = "".join(chars)
    return buf
</t>
<t tx="aum.20060509223528.27">def _recvline(self):
    line = ''
    while 1:
        ch = self._sock.recv(1)
        if ch == '\n':
            LOGMSG(4, "from host: '%s'" % line)
            return line
        line += ch
</t>
<t tx="aum.20060509223528.28">def _recvkeydata(self, len):
    """
    Receives incoming key data, guaranteeing the delivery of len bytes.
    This is used in key receive

    Arguments:
     - len - number of bytes to receive
    Returns:
     - received bytes, as a string, if received OK
     - None if a 'Restarted' message is received

    Note:
     - This routine is 'all or nothing', in that it guarantees either the full
       complement of requested data, or None if a restart occurs
     - Since a metadata-&gt;data transition is not guaranteed to occur at DataChunk
       boundaries (ie, can occur *within* a DataChunk), this routine needs to do
       buffering via self._recvbuf, and receive discrete chunks via
       self._recvchunk()
    """

    # loop around till we get everything, or a restart
    while len &gt; self._recvbuflen:

        # keep receiving chunks till our buffer is big enough to fulfil request
        #set_trace()
        buf, buflen = self._recvchunk()
        if buf == None:
            # got a restart - bail out here
            self._recvbuf = ''
            self._recvbuflen = 0
            return None

        # add this chunk to our buffer
        self._recvbuf += buf
        self._recvbuflen += buflen

    # got enough now
    buf = self._recvbuf[0:len]
    #del self._recvbuf[0:len]
    self._recvbuf = self._recvbuf[len:]
    self._recvbuflen -= len
    return buf
</t>
<t tx="aum.20060509223528.29">def _recvchunk(self):
    """
    Receive a discrete chunk of data from node.
    As per FCP spec, the node dictates the size of the chunk.

    Arguments:
     - None
    Returns:
     - tuple - (chunk, len), where 'chunk' is a string of raw data
       or (None, None) if we got a restart
    """

    #set_trace()

    # now receive a series of data chunks
    resp = self._recvline()
    if resp == 'Restarted':
        # dammit
        self._recvbuf = ''
        self._recvbuflen = 0
        return None
        
    if resp != 'DataChunk':
        raise FreenetFcpError("Expected 'DataChunk', got '%s'" % resp)

    # get length field
    resp = self._recvline()
    fld, val = resp.split("=")
    if fld != 'Length':
        raise FreenetFcpError("Expected 'Length=', got '%s'" % resp)

    chunklen = int(val, 16)
    needed = chunklen
    chunk = ''

    # Get 'Data' line, or complain
    resp = self._recvline()
    if resp != 'Data':
        raise FreenetFcpError("Expected 'Data', got '%s'" % resp)

    # now we can loop around and pull the raw data
    while (needed &gt; 0):
        slice = self._recv(needed)
        chunk += slice
        needed -= len(slice)
    
    # Got the chunk
    return chunk, chunklen
</t>
<t tx="aum.20060509223528.30">def _genchk(self, rawdata, rawmeta=''):
    """
    Lower-level CHK generation method.
    Takes raw data and metadata strings, and sends back a URI object
    being the CHK that would be generated on inserting this data,metadata

    Arguments:
     - rawdata - raw data that would be inserted
     - rawmeta - accompanying raw metadata (default '')
    Returns:
     - a uri object, being the CHK key uri
    Exceptions:
     - FreenetFcpError - details in exception's 'value' attribute
    """

    metalen = len(rawmeta)
    datalen = len(rawdata) + metalen
    self._connect()
    self._sendline("GenerateCHK")
    self._sendline("DataLength=%x" % datalen)
    if metalen &gt; 0:
        self._sendline("MetadataLength=%x" % metalen)
    self._sendline("Data")
    if metalen &gt; 0:
        self._send(rawmeta)
    self._send(rawdata)
    #self._sendline("EndMessage") # not sure if this is needed

    # Get node response
    resp = self._recvline()
    if resp != 'Success':
        raise FreenetFcpError("_genchk: expected 'Success', got '%s'" % resp)
    resp = self._recvline()
    fld, val = resp.split("=", 1)
    if fld != 'URI':
        raise FreenetFcpError("_genchk: expected 'URI=', got '%s'" % resp)
    keyuri = uri(val, pub=self._sskSuffix)
    resp = self._recvline()
    if resp != 'EndMessage':
        raise FreenetFcpError("_genchk: expected EndMessage, got '%s'" % resp)

    # success
    return keyuri
</t>
<t tx="aum.20060509223528.31">def _fecput(self, keyuri, data, htl, **kw):
    keyuri = uri(keyuri, pub=self._sskSuffix)

    threaded = kw.get('threaded', 1)

    # stuff data into temporary file
    nam = tempFilename()
    fd = open(nam, "wb")
    fd.write(data)
    fd.close()

    k = self._fecputfile(keyuri, nam, htl, threaded=threaded)
    os.unlink(nam)
    return k

</t>
<t tx="aum.20060509223528.32">def _fecputfile(self, keyuri, filename, htl, **kw):
    
    keyuri = uri(keyuri, pub=self._sskSuffix)

    # stuff data into temporary file
    threaded = kw.get('threaded', 1)
    k = self._fecputfileex("CHK@", filename, htl, False, False, "CHK@", threaded)
    return k

</t>
<t tx="aum.20060509223528.33">def _fecputfileex(self, location, file, htl, remoteInsert, verifySite, oldUri, threaded=True):

    """
    fish's fec insert front-end - sorry about renaming :)
    """

    LOGMSG(3, "threaded=%s" % threaded)

    # does this even work on win32?
    # (yes)
    length = os.stat(file)[6]
    self._fec_threadData.usedData += length
    #print location, oldUri

    # the following code was mostly shamlessly stolen from the fantastic incredible GJ
    LOGMSG(3, "insertFileKey: Inserting FEC version 1.2 using FCP\nthreaded=%s" % threaded)
    segmentHeaders = self._fec_segmentFile('OnionFEC_a_1_2', length)
    #print segmentHeaders
    maps = []
    headers = []
    for header in segmentHeaders:
        # lock bitch
        self._fec_threadData.fecLock.acquire()

        headers.append(header)
        numChecks = int(header[1]['CheckBlockCount'], 16)
        numBlocks = int(header[1]['BlockCount'], 16)
        blocksRequired = int(header[1]['BlocksRequired'], 16)
        segments = int(header[1]['Segments'], 16)
        segmentNum = int(header[1]['SegmentNum'], 16)
        offset = long(header[1]['Offset'], 16)
        blockSize = int(header[1]['BlockSize'], 16)
        checkSize = int(header[1]['CheckBlockSize'], 16)

        # duh, we've alrady got this one
        # length = long(header[1]['FileLength'], 16)

        # I was going to just call GJ's code here, but then it occoured to me that it
        # relied on paging files, and it was just easier to copy it inline
        # here, modifying it as I go ^_^.
        # need to move this into a seperate function later!
        headerString = "SegmentHeader\n"
        headerString += self._fec_rebuildHdr(header[1])
        headerString += "EndMessage\n"
                
        # segments are always padded to this length, non?
        # GJ's code gets a bit esoteric here :)
        segLength = numBlocks*blockSize
        # read data
        s = open(file, "rb")
        s.seek(offset)
        data = s.read(segLength)
        # zero pad
        data = data+("\0"*(segLength-len(data)))
        s.close()

        # ask freenet to actully encode it
        # FIXME: this should definantly be in a differnet function ^_^
        LOGMSG(4, "insertFileKey: %s %s" % (location, oldUri))
        dataString = "\x00\x00\x00\x02"
        dataString += "FECEncodeSegment\n"
        dataString += "DataLength=%lx\n" % (len(headerString)+len(data))
        dataString += "MetadataLength=%lx\n" % len(headerString)
        dataString += "Data\n"
        dataString += headerString
        dataString += data
            
        s = self._fec_openPort()
        if s == None:
            LOGMSG(1, "insertFileKey: Couldn't connect to FCP - dying now!")
            return None

        self._fec_largeSend(s, dataString)

        # wait for confirmation
        # FIXME: rewrite all of this to use socets directly, rather than files
        fakefile = s.makefile("rb")
        msg = self._fec_readMsg(fakefile)

        if msg==None:
            LOGMSG(1, "insertFileKey: FEC encoding failed for %s %d" % (file, length))
            return None

        if msg[0] != 'BlocksEncoded':
            LOGMSG(1, "insertFileKey: no expected BlocksEncoded message - dying now! %s %d" \
                    % (file,length))
            return None
                
        # how this works is a tad esoteric, but it does makes sense.
        blockNum = 0
        count = 0
        blockData = ""
        blocks = []
 
        #set_trace()

        msg = self._fec_readMsg(fakefile)
        while msg != None:
            #print "_fecputfileex: msg='%s'" % str(msg)
            if msg[0]=="DataChunk":
                length = int(msg[1]['Length'], 16)
                while length &gt; 0:
                    boundry = (blockNum + 1) * checkSize
                    if count &lt; boundry:
                        # Read into the current block
                        nBytes = boundry - count
                        if nBytes &gt; length:
                            nBytes = length

                        time.sleep(0.2)
                        myData = fakefile.read(nBytes)
                        
                        #print "_fecputfileex: trying to read the %d bytes" % nBytes
                        #myChunks = []
                        #nwanted = nBytes
                        #while nwanted &gt; 0:
                        #    thistime = min(nwanted, 256)
                        #    print "still need %d bytes, reading %d" % (nwanted, thistime)
                        #    chnk = fakefile.read(thistime)
                        #    myChunks.append(chnk)
                        #    nwanted = nwanted - len(chnk)
                        #myData = string.join(myChunks, "")
                        #print "_fecputfileex: got the %d bytes" % nBytes
                        if len(myData) &lt; nBytes:
                            LOGMSG(1,
                                   "insertFileKey: Didn't read enough data! (%d)" \
                                     % len(myData))
                            return None
                        count += len(myData)
                        length -= len(myData)
                        blockData += myData
                    else:
                        blocks.append(blockData)    
                        blockData = ""
                        blockNum += 1
                msg = self._fec_readMsg(fakefile)
            else:
                LOGMSG(1, "insertFileKey: Recieved an unknown message! %s" % msg)
        fakefile.close()
        s.close()
        # append last block
        if len(blockData) &gt; 0:
            blocks.append(blockData)    
            blockData = ""
            blockNum += 1

        # okay, now insert the file
        # the rest is all copied from the old v1.0 splitfile insert code
        LOGMSG(3, "insertFileKey: Encoded %d redundant blocks @ %d kb per block" \
                % (len(blocks), checkSize/1024))

        # unlock bitch
        self._fec_threadData.fecLock.release()
        # no, no, no, no, no, no, no
        # no, no, no, no, no, no, no, no
        # no.  fuck no.  I am a fucking
        # moron.
        #self._fec_threadData.currentThreads = self._fec_threadData.currentThreads-1

        splitfileKeys = []
        splitfileLock = thread.allocate_lock()
        splitCheckKeys = []
        splitCheckLock = thread.allocate_lock()
            
        # clear the block thingys
        for i in range(numBlocks):
            splitfileKeys.append(None)
            splitCheckKeys.append(None)

        # insert the main blocks
        for i in range(numBlocks):
            blockdata = data[blockSize*i:blockSize*(i+1)]
            #print len(blockdata)
            splitPos = i
            while self._fec_threadData.currentThreads &gt;= self._fec_threadData.maxThreads:
                time.sleep(0.5)
            if threaded:
                thread.start_new_thread(self._fec_InsFcpSplitPart,
                                        (blockdata, i, splitPos, htl, numBlocks+numChecks,
                                         splitfileLock, splitfileKeys, remoteInsert,
                                         verifySite, oldUri)
                                        )
            else:
                self._fec_InsFcpSplitPart(blockdata, i, splitPos, htl, numBlocks+numChecks,
                                        splitfileLock, splitfileKeys, remoteInsert,
                                        verifySite, oldUri)
            time.sleep(0.25)                

        for i in range(numChecks):
            blockdata = blocks[i]
            splitPos = i + numBlocks
            while self._fec_threadData.currentThreads &gt;= self._fec_threadData.maxThreads:
                time.sleep(0.5)
            if threaded:
                thread.start_new_thread(self._fec_InsFcpSplitPart,
                                        (blockdata, i, splitPos, htl, numBlocks+numChecks,
                                         splitCheckLock, splitCheckKeys, remoteInsert,
                                         verifySite, oldUri)
                                        )
            else:
                self._fec_InsFcpSplitPart(blockdata, i, splitPos, htl, numBlocks+numChecks,
                                        splitCheckLock, splitCheckKeys, remoteInsert,
                                        verifySite, oldUri)
            time.sleep(0.25)                

        map = ("BlockMap", {})
        for i in range(numBlocks):
            while splitfileKeys[i] == None:
                time.sleep(0.5)
            key = "Block.%lx" % i
            map[1][key] = splitfileKeys[i]
        
        for i in range(numChecks):
            while splitCheckKeys[i] == None:
                time.sleep(0.5)
            key = "Check.%lx" % i
            map[1][key] = splitCheckKeys[i]
        #print map
        #print "done"
        maps.append(map)

    # back to blatent gj copy mode ^_^
    LOGMSG(4, "insertFileKey: Making splitfile metadata")

    #set_trace()

    meta = self._fec_makeMetadata(headers, maps, self._fec_getMimetype(file))

    key = self._fec_retryInsertFancy("", meta, location, htl,
                                "splitfile metadata for "+file,
                                oldUri, verifySite, remoteInsert)
    return key




</t>
<t tx="aum.20060509223528.34">def _fec_InsFcpSplitPart(self, blockdata, i, splitPos, htl, n, lock,
                       splitfileKeys, remoteInsert, verifySite, oldUri):

    mynode = node(self._host, self._port, htl)
    self._fec_threadData.currentThreads += 1

    mou = oldUri

    if mou != None:
        # generate the CHK for this key to verify, if we're doing a refresh
        #mou = self.generateCHK(blockdata, "")
        mou = str(mynode._genchk(blockdata, ''))

    try:
        keyuri = self._fec_retryInsert(blockdata, "", "CHK@", htl,
                                  ("Part %s of %s threads: %s" % \
                                   (str(splitPos+1),
                                    str(n),
                                    str(self._fec_threadData.currentThreads))),
                                  mou, verifySite, remoteInsert)
    except:
        traceback.print_exc()

    lock.acquire()
    splitfileKeys[i] = keyuri
    lock.release()
    self._fec_threadData.currentThreads -= 1</t>
<t tx="aum.20060509223528.35"># we almost always want to remote insert
#
# but we don't want to preverify if we already know ahead of time that the file isn't in freenet
def _fec_retryInsert(self, data, meta, location, htl, data2print,
                preverify=None, postverify=True, remoteinsert=True):

    n = node(self._host, self._port, htl)

    #print "preverify: ",location, preverify, data2print
    if(preverify != None):
        LOGMSG(3, "_fec_retryInsert: attempting to preverify %s at %s" \
                % (data2print, preverify))
        #d=retrieveKey(preverify, 15, true) # disabled DDM
        if n.keyexists(preverify, htl):
            LOGMSG(3, "_fec_retryInsert: retrieved %s without inserting - skipping..." % data2print)
            self._fec_threadData.skipped += 1
            return preverify

    keyuri = None
    retry = 0
    while keyuri==None:
        retry += 1
        LOGMSG(3, "_fec_retryInsert: Inserting %s at %s, try %s" \
                % (data2print, location, str(retry)))
        #traceback.print_stack()
        #keyuri = insertKey(data, meta, location, htl, remoteinsert)
        try:
            k = n.putraw(data, meta, location, htl)
            keyuri = str(k.uri)
        except:
            keyuri = None
        if postverify and keyuri != None:
            LOGMSG(4, "_fec_retryInsert: Verifying %s at %s", (data2print, keyuri))
            # we always want this to be remote
            # we're sticking to HTL=15 for retrieval right now, since this
            # is what fproxy defaults to - make it settable later, tho
            #d=retrieveKey(key, 15, true) # disabled DDM
            if n.keyexists(keyuri, htl):
                LOGMSG(3, "_fec_retryInsert: Verification succeeded!")
            else:
                LOGMSG(3, "_fec_retryInsert: Verification failed!")
                keyuri=None
            
        if keyuri == None:
            time.sleep(5)

    self._fec_threadData.inserted += 1
    return keyuri


</t>
<t tx="aum.20060509223528.36">def _fec_retryInsertFancy(self, data, meta, location, htl,
                     data2print, preverify=None, postverify=True, remoteinsert=True):
    needRedirect = True;
    if location[:3] == "CHK":
        needRedirect=False

    if data == None:
        data = ''
    if meta == None:
        meta = ''

    # not 32768, we're playing it safe :-p
    if len(data + meta) &lt; 32000:
        needRedirect = False
    if needRedirect == True:
        # insert the key
        keyuri = self._fec_retryInsert(data, meta, "CHK@", htl, data2print,
                                  None, postverify, remoteinsert)
        # create the redirect
        meta = self._fec_makeRedirect(keyuri)
        keyuri = self._fec_retryInsert("", meta, location, htl, data2print+" redirect",
                             preverify, postverify, remoteinsert)
    else:
        keyuri = self._fec_retryInsert(data, meta, location, htl, data2print,
                                  preverify, postverify, remoteinsert)
    return keyuri

</t>
<t tx="aum.20060509223528.37">def _fec_createManifest(self, sourceList, keyList):

    meta = self.metadataHeader

    # find index.html first
    for i in range(len(sourceList)):
        if (sourceList[i] == "index.html"):
            meta += "Document\n"
            meta += "Redirect.Target=%s\n" % keyList[i]
            meta += "EndPart\n"

    # and everything else
    for i in range(len(sourceList)):
        meta += "Document\n"
        meta += "Name=%s\n" % sourceList[i].replace("\\", "/")
        meta += "Redirect.Target=%s\n" % keyList[i]
        meta += "EndPart\n"
        # Change last EndPart to End - thanks to wookie :)

    if meta[-5:-1] == "Part":
        meta = meta[:-5] + "\n"
    return meta

</t>
<t tx="aum.20060509223528.38">class _fec_threadData:
    
    currentThreads = 0
    maxThreads = 4
    fcpHost = []
    fcpPort = []
    seperator = "/"
    inserted = 0
    skipped = 0
    verbose = False
    edition = -1
    activeLink = None
    firstFeedback = 0
    feedbackNumber = 20
    sitename = None
    usedData = 0
    maxData = 0
    lastFcp = 0
    fecLock = thread.allocate_lock()
</t>
<t tx="aum.20060509223528.39">def _fec_getMimetype(self, file):
    return {'html':'text/html', 'mp3':'audio/mpeg', 'ogg':'audio/ogg', 'mid':'audio/midi',
            'jpg':'image/jpeg', 'jpeg':'image/jpeg', 'gif':'image/gif', 'png':'image/png',
            'avi':'video/avi', 'asf':'video/asf', 'avi':'video/avi', 'mpg':'video/mpeg',
            'mpeg':'video/mpeg', 'sid':'audio/psid', 'zip':'binary/zip-compressed',
            'iso':'binary/cdimage',
            'gz':'binary/gzip-compressed'}.get(file.split('.')[-1], "text/plain")

</t>
<t tx="aum.20060509223528.40">def _fec_makeSimpleMetadata(self, mimetype):
    data = self.metadataHeader
    data += "Document\n"
    data += "Info.Format=%s\n" % mimetype
    data += "End\n"
    return data

</t>
<t tx="aum.20060509223528.41">def _fec_makeDbr(self, keyuri, period=86400):

    meta = self.metadataHeader
    meta += "Document\n"
    meta += "DateRedirect.Target=" + keyuri +"\n"
    meta += "DateRedirect.Increment=%lx\n" % period
    meta += "End\n"

    return meta
</t>
<t tx="aum.20060509223528.42">def _fec_makeRedirect(self, target):

    meta = self.metadataHeader
    meta += "Document\n"
    meta += "Redirect.Target=" + target + "\n"
    meta += "End\n"

    return meta
</t>
<t tx="aum.20060509223528.43">def _fec_rebuildHdr(self, header):

    out=""
    for field in header.keys():
        out += field + "=" + header[field] + "\n"

    return out
</t>
<t tx="aum.20060509223528.44"># this function copied almost verbatum from GJ, and then cleaned up
def _fec_makeMetadata(self, headers, maps, mimeType):

    n = node(self._host, self._port, self._htl)

    description="Onion FEC v1.2 file inserted by FishTools - ph33r d4 ph15h!"
    listString = ""

    for index in range(len(headers)):
        header = headers[index]
        listString += "SegmentHeader\n"
        listString += self._fec_rebuildHdr(header[1])
        listString += "EndMessage\n"

        map=maps[index]
        listString += "BlockMap\n"
        listString += self._fec_rebuildHdr(map[1])
        listString += "EndMessage"

    dataString = "\x00\x00\x00\x02"
    dataString += "FECMakeMetadata\n"
    dataString += "Segments=%lx\n" % len(headers)
    dataString += "Description=%s\n" % description
    if(mimeType):
        dataString += "MimeType=%s\n" % mimeType
    dataString += "DataLength=%lx\n" % len(listString)
    dataString += "Data\n"
    dataString += listString
    #print dataString
    s = n._fec_openPort()
    n._fec_largeSend(s, dataString)

    # the file hack from before returns
    fakefile = s.makefile("rb")
    msg = n._fec_readMsg(fakefile)
    LOGMSG(4, "_fec_makeMetadata: %s" % str(msg))
    if msg[0] != "MadeMetadata":
        LOGMSG(4, "_fec_makeMetadata: Unknown message: %s" % str(msg))
        return None

    tlen = int(msg[1]['DataLength'], 16)
    count = 0
    msg = n._fec_readMsg(fakefile)
    odata = ""
    while msg!=None:
        if msg[0] == "DataChunk":
            length = int(msg[1]["Length"], 16)
            time.sleep(0.2)
            myData = fakefile.read(length)
            if len(myData) &lt; length:
                LOGMSG(4, "_fec_makeMetadata failed to read enough data!")
                return None
            count += len(myData)
            if count &gt; tlen:
                break
            odata += myData
            msg = n._fec_readMsg(fakefile)
        else:
            LOGMSG(4, "_fec_makeMetadata: Bad message: %s" % str(msg))
            msg = n._fec_readMsg(fakefile)
            return None
    fakefile.close()
    s.close()
    return odata


</t>
<t tx="aum.20060509223528.45"># this one is almost a direct cut/paste from GJ - why reinvent the wheel :)
def _fec_segmentFile(self, algorythm, length):

    n = node(self._host, self._port, self._htl)

    # Build the message.
    dataString = "\x00\x00\x00\x02"
    dataString += "FECSegmentFile\n"
    dataString += "AlgoName=%s\n" % algorythm
    dataString += "FileLength=%lx\n" % length
    dataString += "EndMessage\n"

    print "_fec_segmentFile: algo=%s, length=%s" % (algorythm, length)

    # open the socket
    s = self._fec_openPort()
    if s is None:
        LOGMSG(1, "FECSegmentFile: Couldn't connect to FCP port")
        return None

    n._fec_largeSend(s, dataString)

    # Get response.
    file = s.makefile("rb")
    headers = []
    msg = n._fec_readMsg(file)
    while msg != None:
        if msg[0] != 'SegmentHeader':
            print "Received an unexpected msg!"
            print msg
            headers = []
            headers.append(msg)
            break

        headers.append(msg)
        msg = n._fec_readMsg(file)
    file.close()
    s.close()

    return headers

</t>
<t tx="aum.20060509223528.46"># send data in chunks of 1meg at a time
def _fec_largeSend(self, sock, data):

    sd=0
    while sd &lt; len(data):
        ed = sd + (1024 * 1024)
        if(ed &gt; len(data)): 
            ed = len(data)
        newdata = data[sd:ed]
        sock.send(newdata)
        sd = sd + (1024 * 1024)

</t>
<t tx="aum.20060509223528.47">def _fec_getNodeLoad(self, host, port):

    dataString = "\x00\x00\x00\x02"
    dataString += "ClientInfo\n"
    dataString += "EndMessage\n"
    s = self.openSpecificFcpPort(host, port)
    if s==None:
        return 100

    self._fec_largeSend(s, dataString)
    dataBack='fish'
    cbuf=''
    while len(dataBack) &gt; 0:
        dataBack = s.recv(1024)
        cbuf += dataBack
        # we have a complete message - process it...
        if cbuf[-11:] == "EndMessage\n":
            lines = cbuf.split("\n")
            for j in lines:
                fields = j.split('=')
                if fields[0] == "EstimatedLoad":
                    return int(fields[1], 16)
    return 100
</t>
<t tx="aum.20060509223528.48">def _fec_openPort(self, host=None, port=None):

    if host == None:
        host = self._host
    if port == None:
        port = self._port

    # open the socket
    s = None
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        mytuple = (host, int(port))
        if self._fec_threadData.verbose and len(self._fec_threadData.fcpHost) &gt; 1:
            LOGMSG(4, "openSpecificFcpPort: %s" % str(mytuple))
        s.connect(mytuple)
    except:
        s = None

    # write to it
    if s is None:
        LOGMSG(1, "openSpecificFcpPort: Couldn't connect to %s:%s" % (str(host), str(port)))
        return None
    return s
</t>
<t tx="aum.20060509223528.49">def _fec_readMsg(self, file):
    """
    Reads an FCP message off of an open file.
    returns a (Msg Name, Fields Dictionary) tuple
    or None, if no message could be read.
    """

    msgName = None     
    fields = {}

    time.sleep(0.2)
    buffer = file.readline()
    while buffer != '':
        #print "_fec_readMsg buffer: ", buffer
        if buffer.find('=') != -1:
            values = buffer.split('=')
            fields[values[0]] = values[1].strip()
        else:
            buffer = buffer.strip()
            if msgName == None:
                msgName = buffer.strip()
            elif buffer == 'EndMessage' or buffer == 'Data':
                # Stop at the end of the message.
                break

        buffer = file.readline()

    if msgName == None:
        return None

    return (msgName, fields)

</t>
<t tx="aum.20060509223528.50"># url can't be redirected.
# for now htl must be 0

def _fec_getFile(self, url, fileName, host, port, htl, **kw):

    numtries = kw.get('numtries', 1)

    DEVNULL_FILE = "null.dat"
    LOGMSG(3, "_fec_getFile: Requesting SplitFile %s" % url)

    #set_trace()

    ret = self._fec_clientGet(host, port, url, htl, None, '__FCP_temp_dl_meta.dat', 0, None, None)
    if ret[0] != 'Success':
        return 0
    
    LOGMSG(4, "Getting headers for SplitFile metadata.")

    pair = self._fec_segmentSplitFile(host, port, '__FCP_temp_dl_meta.dat')
    if pair == None:
        LOGMSG(2, "Couldn't segment SplitFile metadata.")
        return 0
        
    headers = pair[0]

    maps = pair[1]

    for index in range(len(headers)):
        header = headers[index]
        map = maps[index]
        
        nRequired = int(header[1]['BlocksRequired'], 16)
        nBlocks = int(header[1]['BlockCount'], 16)
        blockSize = int(header[1]['BlockSize'], 16)

        nChecks = int(header[1]['CheckBlockCount'], 16)
        fileLength = long(header[1]['FileLength'], 16)
        offset = int(header[1]['Offset'], 16)
        segment = int(header[1]['SegmentNum'], 16)
        segments = int(header[1]['Segments'], 16)
            
        
        # Randomly select required check and data blocks
        indices = self._fec_makeIndexList(nBlocks + nChecks, nRequired)

        dataIndices = []
        checkIndices = []

        for i in indices:
            if i &lt; nBlocks:
                dataIndices.append(i)
            else:
                checkIndices.append(i - nBlocks)

        LOGMSG(4, "Requesting data blocks...")

        for i in dataIndices:
            hexIndex =  "%lx" % i
            key = 'Block.' + hexIndex
            blockURL = map[1][key]
            blockFile = '__FCP_temp_data_block_' + str(i)
            ret = self._fec_clientGet(host, port, blockURL, htl,
                        blockFile, DEVNULL_FILE, 0, None, None)

            if ret == None:
                LOGMSG(3, "Couldn't download block: %d" % i)
                return 0
            if ret[0] != 'Success':
                LOGMSG(3, "Couldn't download block: %d" % i)
                return 0
            
            LOGMSG(4, "Downloaded block: %d" % i)

        for i in checkIndices:
            hexIndex =  "%lx" % i
            key = 'Check.' + hexIndex
            blockURL = map[1][key]
            blockFile = '__FCP_temp_check_block_' + str(i)
            ret = self._fec_clientGet(host, port, blockURL, htl,
                        blockFile, DEVNULL_FILE, 0, None, None)

            if ret == None:
                LOGMSG(3, "Couldn't download check block: %d" % i)
                return 0
            if ret[0] != 'Success':
                LOGMSG(3, "Couldn't download check block: %d" % i)
                return 0
            
            LOGMSG(4, "Downloaded check block: %d" % i)

        requestedIndices = self._fec_findMissingIndices(range(nBlocks), dataIndices)

        blockFiles = ( self._fec_makeFilenames(dataIndices, "__FCP_temp_data_block_") +
                   self._fec_makeFilenames(checkIndices, "__FCP_temp_check_block_") )
        
        reconFiles = self._fec_makeFilenames(requestedIndices, "__FCP_temp_recon_block_")
        
        LOGMSG(3, "FEC decoding...")
        self._fec_decodeSegment(host, port, header,
                     blockFiles,
                     dataIndices, checkIndices, requestedIndices,
                     reconFiles)
        

        LOGMSG(4, "data indices: %s" % dataIndices)
        LOGMSG(4, "requested Indices: %s" % requestedIndices)
        
        reconList = self._fec_makeRebuiltFileList(dataIndices, '__FCP_temp_data_block_',
                             requestedIndices, '__FCP_temp_recon_block_')
        
        LOGMSG(4, "block file list: ")
        LOGMSG(4, reconList)

        LOGMSG(4, "Concatinating blocks....")
        segLen = fileLength
        if segments &gt; 1:
            if segment &lt; segments - 1:
                segLen = nBlocks * blockSize
            else:
                # final segment
                segLen = fileLength - offset
        
        # Seeks and appends as nescessary.        
        self._fec_concatFiles(reconList, segLen, fileName, segment &gt; 0)

        self._fec_removeTmpFiles()

    return 1

</t>
<t tx="aum.20060509223528.51">def _fec_removeTmpFiles(self):

    filz = os.listdir(".")
    for file in filz:
        if len(file) &gt; 2:
            if file[0:11] == "__FCP_temp_":
                os.unlink(file)
                LOGMSG(4, "Removed temp file: %s" % file)
</t>
<t tx="aum.20060509223528.52"># returns A MetadataHint msg if bHint is true and the request succeeds
#     A Success msg if bHint is false and the request succeeds
#     A failure message otherwise.
def _fec_clientGet(self, server, port, uri, htl, dataFileName, metaDataFileName, bHint, hintTime, flags):
    # REDFLAG: remove debugging...
    #print "*** _fec_clientGet ***"
    #print "    server        : ", server
    # segv's printing the port.  wtf?
    #print "    port          : ", port
    #print "    uri            : ", uri
    #print "    htl            : ", htl
    #print "    dataFileName      : ", dataFileName
    #print "    metaDataFileName : ", metaDataFileName
    #print "    bHint         : ", bHint
    #print "    flags         : ", flags
    
    # Build the message.
    dataString=FCP_HEADER_BYTES+"ClientGet\n"+"URI="+uri+"\n"+"HopsToLive="+str(htl)+"\n"
    if bHint:
        dataString += "MetadataHint=true\n"
        if hintTime != None:
            dataString += "RedirectTimeSec=" + str(hintTime) + "\n"

    # To support local key deletion
    if flags != None:
        dataString += "Flags=" + ("%lx" % flags) +"\n"
        
    dataString += "EndMessage\n"

    # Open a socket
    s = self._fec_openSocket(server, port);
    if s is None:
        print "Couldn't connect to FCP port"
        raise IOError

    s.send(dataString)

    file = s.makefile("r")

    hintMsg = None
    errMsg = None
    
    # Total length
    tlen = -1
    # Data length
    dlen = -1
    # Metadata Length
    mlen = -1
    
    msg = self._fec_readMsg(file)

    if dataFileName != None:
        dataFile = open(dataFileName, 'wb')
    else:
        dataFile = None

    if metaDataFileName != None:
        metaFile = open(metaDataFileName, 'wb')
    else:
        metaFile = None
    
    # Total byte count
    count = 0
    
    while msg != None:
        #print "msg: " + msg[0]      
        if msg[0] == 'DataFound':
            tlen = int(msg[1]['DataLength'], 16)
            mlen = 0
            if msg[1].has_key('MetadataLength'):
                mlen = int(msg[1]['MetadataLength'], 16)
            dlen = tlen - mlen
        if msg[0] == 'DataChunk':
            length = int(msg[1]['Length'], 16)
            if count &lt; mlen:
                nBytes = length
                if count + nBytes &gt; mlen:
                    nBytes = mlen
                if metaFile != None:
                    nRead = self._fec_copyBinary(file, nBytes, metaFile)
                    if nRead != nBytes:
                        print "Didn't read enough bytes!"
                        print "nRead: ", nRead, " nBytes: ", nBytes
                        raise IOError

                count += nRead
                length -= nRead

            if count &gt;= mlen:
                nBytes = length
                if count + nBytes &gt; tlen:
                    nBytes = tlen - count

                if dataFile != None:
                    nRead = self._fec_copyBinary(file, nBytes, dataFile)
                    if nRead != nBytes:
                        print "Didn't read enough bytes!"
                        print "nRead: ", nRead, " nBytes: ", nBytes
                        raise IOError
                    count += nRead

        # Handle restarts
        if msg[0] == 'Restarted':
            if dataFile != None:
                dataFile.close()
            if metaFile != None:
                metaFile.close()
            count = 0
            
            dataFile = open(dataFileName, 'wb')
            if metaDataFileName != None:
                metaFile = open(metaDataFileName, 'wb')
            
        # Handle terminal messages
        if msg[0] == 'DataNotFound' or \
            msg[0] == 'RouteNotFound' or \
            msg[0] == 'URIError' or \
            msg[0] == 'FormatError' or \
            msg[0] == 'Failed':
            errMsg = msg
            break
        if msg[0] == 'MetadataHint':
            hintMsg = msg
            break
        
        msg = self._fec_readMsg(file)


    if dataFile != None:
        dataFile.close()
    if metaFile != None:
        metaFile.close()
    file.close()    
    s.close()

    if errMsg != None:
        return errMsg

    if hintMsg != None:
        return hintMsg
    
    return self._fec_makeFakeMsg('Success', 'Downloaded successfully.')

</t>
<t tx="aum.20060509223528.53"># returns the list of segment headers and block maps
# required to download a SplitFile on success
# returns None on failure
def _fec_segmentSplitFile(self, server, port, inputFileName):

    # Get length of the file containing the
    # SplitFile metadata.
    tlen = os.stat(inputFileName)[6]

    # Build the message.
    dataString=FCP_HEADER_BYTES
    dataString += "FECSegmentSplitFile\n"
    dataString += "DataLength=%lx\n" % tlen
    dataString += "Data\n"

    LOGMSG(4, "FECSegmentSplitFile:")
    LOGMSG(4, dataString)
    
    # open the socket
    s=self._fec_openSocket(server, port)
    if s is None:
        print "Couldn't connect to FCP port"
        raise IOError

    # REDFLAG: bush league, use file interface
    s.send(dataString)

    # Send the metadata.
    file = s.makefile("w");
    inputFile = open(inputFileName, "rb")
    self._fec_copyBinary(inputFile, tlen, file)
    inputFile.close()

    # Get response.
    file = s.makefile("r")

    # Hmmmm.... this is inconsistent
    # Should there be a "SegmentedSplitFile" msg?
    # NO, because messages come back as msgs not data
    
    msg = self._fec_readMsg(file)
    if msg[0] != 'SegmentHeader':
        print "Received an unexpected msg:", msg
        return None

    headers = []
    maps = []
    error = 0
    while msg != None:
        if msg[0] != 'SegmentHeader':
            print "Received an unexpected msg!"
            error = 1
            break
        
        headers.append(msg)

        msg = self._fec_readMsg(file)
        if msg[0] != 'BlockMap':
            print "Received an unexpected msg!"
            error = 1
            break;
        
        maps.append(msg)

        msg = self._fec_readMsg(file)
    
    file.close()
    s.close()

    if error:
        return None

    return (headers, maps)

</t>
<t tx="aum.20060509223528.54"># returns 1 on success 0 otherwise
def _fec_decodeSegment(self, server, port, header,
             blockFileNames,
             blockIndices, checkIndices, requestedIndices,
             outputFileNames):


    # REDFLAG: check arguments?
    
    blockCount = int(header[1]['BlockCount'], 16)
    blockSize = int(header[1]['BlockSize'], 16)
    checkBlockCount = int(header[1]['CheckBlockCount'], 16)
    checkBlockSize = int(header[1]['CheckBlockSize'], 16)
    offset = long(header[1]['Offset'], 16)


    #REDFLAG: make client do this themself?
    tmp = []
    for i in checkIndices:
        tmp.append(i + blockCount)

    checkIndices = tmp

    dlen = blockSize * len(blockIndices) + checkBlockSize * len(checkIndices)

    # Reconstruct the SegmentHeader msg
    # so that we can send it in the metadata
    headerString="SegmentHeader\n"
    for field in header[1].keys():
        headerString=headerString+ field+ "=" + header[1][field] + "\n"
    headerString=headerString+"EndMessage\n" 

    mlen = len(headerString)
    tlen = dlen + mlen
    
    # Build the message.
    dataString=FCP_HEADER_BYTES
    dataString += "FECDecodeSegment\n"
    dataString += "DataLength=%lx\n" % tlen
    dataString += "MetadataLength=%lx\n" % mlen
    dataString += "BlockList=%s\n" % self._fec_hexIndexList(blockIndices)
    dataString += "CheckList=%s\n" % self._fec_hexIndexList(checkIndices)
    dataString += "RequestedList=%s\n" % self._fec_hexIndexList(requestedIndices)
    dataString += "Data\n"

    #print "FECDecodeSegment:"
    #print dataString

    #print "SegmentHeader (sent via metadata):"
    #print headerString

    # open the socket
    s=self._fec_openSocket(server, port)
    if s is None:
        print "Couldn't connect to FCP port"
        raise IOError

    file = s.makefile("w")

    # Send the FCP decode request.
    file.write(dataString)

    # Send SegmentHeader in metadata.
    file.write(headerString)

    dataSent = 0;
    
    # Send blocks
    index = 0
    for name in blockFileNames:
        fileSize = blockSize
        if index &gt; len(blockIndices):
            fileSize = checkBlockSize
            
        assert os.stat(name)[6] == fileSize
        
        inputFile = open(name, "rb")
        self._fec_copyBinary(inputFile, fileSize, file)
        inputFile.close()

        dataSent += fileSize
        index = index + 1

    file.flush()
    file.close()

    # Get the confirmation
    file = s.makefile("r")
    msg = self._fec_readMsg(file)

    if msg[0] != 'BlocksDecoded':
        print "Received an unexpected msg:", msg
        return 0

    # grrrrrrr.... C&amp;P, factor this out.

    # Read decoded data blocks off the socket.
    blockNum = 0
    currentFile = open(outputFileNames[blockNum], "wb")
    count = 0
    msg = self._fec_readMsg(file)
    while msg != None:
        #print "msg: " + msg[0]     
        if msg[0] == 'DataChunk':
            length = int(msg[1]['Length'], 16)
            while length &gt; 0:
                boundry = (blockNum + 1) * blockSize
                if count &lt; boundry:
                    # Read into the current block
                    nBytes = boundry - count
                    if nBytes &gt; length:
                        nBytes = length
                    nRead = self._fec_copyBinary(file, nBytes, currentFile)
                    if nRead != nBytes:
                        print "Didn't read enough bytes!"
                        print "nRead: ", nRead, " nBytes: ", nBytes
                        raise IOError
                    count += nRead
                    length -= nRead
                else:
                    # Advance to the next block    
                    currentFile.close()
                    blockNum = blockNum + 1
                    currentFile = open(outputFileNames[blockNum], "wb")
            msg = self._fec_readMsg(file)
        else:
            print "Received an unexpected msg:", msg
            return 0
    

    currentFile.close()

    file.close()
    s.close()

    return 1

</t>
<t tx="aum.20060509223528.55">############################################################
# Automatic insertion and retrieval functions built
# on top of the FCP primatives.
############################################################

############################################################
# Downloads a key from Freenet automatically handling
# redirects.
#
# returns a (success, mimeType, redirectList) tuple
#
# If success is 0, the last entry in the redirectList is the uri that
# couldn't be retrieved.
def _fec_getKey(self, server, port, uri, htl, dataFileName, metaDataFileName, hintTime, flags):
    uris = []
    mimeType = None

    msg = self._fec_clientGet(server, port, uri, htl, dataFileName, metaDataFileName, 1, hintTime, flags)
    uris.append(uri)
    while msg != None:
        #print "uri: ", uri
        #print "msg: ", msg
        if msg[0] == 'MetadataHint':
            if mimeType == None and msg[1].has_key('MimeType'):
                # We take the first mime type definition
                # in the redirect chain
                mimeType = msg[1]['MimeType']

            kind = int(msg[1]['Kind'])
            # ok to leave as a hex string.
            hintTime = msg[1]['TimeSec']

            # Handle metadata using the hint sent
            # by the FCP server. Cool huh.
            #
            if kind == MDH_DATA:
                # Our work is done.
                return (1, mimeType, uris)
                break
            elif kind == MDH_REDIRECT:
                uri = msg[1]['NextURI']
                uris.append(uri)
                msg = self._fec_clientGet(server, port, uri, htl,
                            dataFileName, metaDataFileName, 1, hintTime, flags)
            elif kind == MDH_DATEREDIRECT:
                uri = msg[1]['NextURI']
                # Append increment and offset and evaluation time to dbrs
                uris.append(uri + " [" + msg[1]['Increment'] +
                        ", " + msg[1]['Offset'] + ", " + hintTime + "]" )

                msg = self._fec_clientGet(server, port, uri, htl,
                            dataFileName, metaDataFileName, 1, hintTime, flags)
            elif kind == MDH_SPLITFILE:
                print "Can't handle splitfiles yet!"
                break
            elif kind == MDH_TOODUMB:
                print "FCP server too dumb to parse the metadata!"
                break
            elif kind == MDH_ERROR:
                print "FCP server enountered and error parsing metadata!"
                break
            else:
                print "Phreaked out. UNKNOWN kind constant: " + str(kind)
                break
        else:
            break

    return (0, mimeType, uris)

</t>
<t tx="aum.20060509223528.56">def _fec_hexIndexList(self, indices):
    return ",".join([("%lx" % n) for n in indices])

</t>
<t tx="aum.20060509223528.57"># Opens a socket for an FCP connection.
def _fec_openSocket(self, server, port):
    # REDFLAG: Work around for segv
    # grrrrr.....
    # There is something badly fuXORd with my rh7.1 python2.2
    # install.  People with python properly configured
    # shouldn't have to resort to this.
    portAsString = str(port)
    copyAtNewAddress = int(portAsString)

    #print "_fec_openSocket: server=%s, port=%s" % (server, port)

    # open the socket
    s=None
    for res in socket.getaddrinfo(server, copyAtNewAddress, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, canonname, sa = res
        try:
            s = socket.socket(af, socktype, proto)
        except socket.error, msg:
            s = None
            continue
        try:
            s.connect(sa)
        except socket.error, msg:
            s.close()
            s = None
            continue
        break

    return s

</t>
<t tx="aum.20060509223528.58">def _fec_makeFakeMsg(self, msgName, reason):
    fields = {}
    fields['Reason'] = reason
    return (msgName, fields)

</t>
<t tx="aum.20060509223528.59"># Copy data from a file open for input
# to a file open for output.
#
# Note: This function doesn't close or
#       flush the files.
#
def _fec_copyBinary(self, file, length, outputFile):
    #print "_fec_copyBinary: length=", length 
    requested = length
    count = 0
    while length &gt; 0:
        #print "_fec_copyBinary: ",  count
        nBytes = 16384
        if nBytes &gt; length:
            nBytes = length

        buffer = file.read(nBytes)
        if buffer == '':
            break

        outputFile.write(buffer)
        nWritten = len(buffer)
        count += nWritten
        length -= nWritten
        #if nWritten != nBytes:
        #    break

    if requested != count:
        print "_fec_copyBinary -- only wrote ", count, " of " , requested
        raise IOError

    return count
</t>
<t tx="aum.20060509223528.60">#Output file must be open for writing
def _fec_zeroPad(self, outputFile, length):
    # REDFLAG: hoist out and re-use same buffer?
    # Is this a speed issue?
    buffer = "\x00" * 16384

    while length &gt; 0:
        nBytes = 16384
        if nBytes &gt; length:
            nBytes = length
            buffer = "\x00" * nBytes

        outputFile.write(buffer)
        length -= nBytes
</t>
<t tx="aum.20060509223528.61">def _fec_sameLength(self, fileNameA, fileNameB):
    if os.stat(fileNameA)[6] == os.stat(fileNameB)[6]:
        return 1
    return 0
</t>
<t tx="aum.20060509223528.62">def _fec_diffBinary(self, fileNameA, fileNameB):
    fileA = open(fileNameA, "rb")
    fileB = open(fileNameB, "rb")
    if not self._fec_sameLength(fileNameA, fileNameB):
        print "_fec_diffBinary: lengths don't match! ", fileNameA, " ", fileNameB
        return 0

    length = os.stat(fileNameA)[6]
    count = 0

    nBuf = length / 4096
    if length % 4096 != 0:
        nBuf = nBuf + 1

    for i in range(nBuf):
        bufferA = fileA.read(4096)
        bufferB = fileB.read(4096)

        nReadA = len(bufferA)
        nReadB = len(bufferB)

        if nReadA != nReadB:
            # REDFLAG: underwhelming
            print "My pitiful code choked! Sorry :-("
            assert 0

        for j in range(nReadA):
            if bufferA[j] != bufferB[j]:
                print "Mismatch at byte: " , count
                return 0
            count = count + 1


    assert count == length

    return 1
</t>
<t tx="aum.20060509223528.63">def _fec_concatFiles(self, inputFileNames, length, outputFileName, append):
    #print "_fec_concatFiles: length=" , length
    if append:
        outputFile = open(outputFileName, "ab")
    else:
        outputFile = open(outputFileName, "wb")

    index = 0
    flen = os.stat(inputFileNames[index])[6]
    inputFile = open(inputFileNames[index], "rb")
    while length &gt; 0:
        # print "index: " , index, "length: ", length
        if flen == 0:
            inputFile.close()
            index = index + 1
            flen = os.stat(inputFileNames[index])[6]
            inputFile = open(inputFileNames[index], "rb")
        nBytes = length
        if nBytes &gt; flen:
            nBytes = flen
        self._fec_copyBinary(inputFile, nBytes, outputFile)
        length -= nBytes
        flen -= nBytes
        outputFile.flush()
        # print " outputFile length=", os.stat(outputFileName)[6]

    inputFile.close()
    outputFile.close()
</t>
<t tx="aum.20060509223528.64">def _fec_makeFilenames(self, indices, prefix):
    ret = []
    for i in indices:
        ret.append(prefix + str(i))

    return ret
</t>
<t tx="aum.20060509223528.65">def _fec_makeIndexList(self, max, number):
    if number &gt; max:
        print "Bad arguments number&gt; max"
        assert 0

    list = range(max)
    ret = []
    while len(ret) &lt; number:
        element = random.choice(list)
        ret.append(element);
        list.remove(element)
    ret.sort()
    return ret
</t>
<t tx="aum.20060509223528.66"># makes an ordered list of data block / renonstructed
# block file names
def _fec_makeRebuiltFileList(self, dataIndices, data_prefix, reconstructedIndices, recon_prefix):
    dataMap = {}
    for index in dataIndices:
        dataMap[index] = 'extant'

    reconMap = {}
    for index in reconstructedIndices:
        reconMap[index] = 'extant'

    ret = []
    for index in range(len(dataIndices) + len(reconstructedIndices)):
        if dataMap.has_key(index):
            ret.append(data_prefix + str(index))
        elif reconMap.has_key(index):
            ret.append(recon_prefix + str(index))
        else:
            print "failed, block missing: " , index 
            assert 0
    return ret
</t>
<t tx="aum.20060509223528.67">def _fec_findMissingIndices(self, full_range, partial_range):
    list = {}
    for i in partial_range:
        list[i] = "extant"

    ret = []
    for i in full_range:
        if not list.has_key(i):
            ret.append(i)

    ret.sort()
    return ret
</t>
<t tx="aum.20060509223528.68">class site:
    """
    Class for creation, insertion and retrieval of freesites

    1001 uses, including:
     - creating new freesites from scratch
     - downloading existing freesites from freenet
     - inserting new freesites into freenet
     - refreshing existing freesites owned by client
    """
    @others
</t>
<t tx="aum.20060509223528.69">def __init__(self, **args):
    """
    Constructor for class freenet.site

    Arguments:
     - none

    Keywords:
     - siteType - style of freesite - 'dbr', 'edition' or 'oneshot', default to last
       saved site state, or 'dbr' if no previous site state
     - edition - if siteType is 'edition', specifies the edition number from which
       to start insert attempts - defaults to last saved site state, or 0 if no prev saved state
     - editionMaxTries - maximum number of edition numbers to try - failure results if we
       exhaust all tries - default is last saved site state, or 0 (try forever) if no prev saved state

     - name      - text name of site, must be [A-Za-z0-9_\-\/]+, compulsory
       used in key URI, as in SSK@blahblahPAgM/name//
     - fromdir   - directory to insert from, compulsory if inserting
     - todir     - directory to retrieve to, defaults to unique dir in /tmp
     - htl       - htl for insert/retrieve, default 20
     - pub       - SSK public key, compulsory if refreshing
     - priv      - SSK private key, compulsory if refreshing
     - future    - days in future to insert, default 0
     - default   - file in fromdir to use as default, default='index.html'
     - splitsize - size of splitfile segments
     - map       - metadata map object
     - offset    - offset for DBR, default 0
     - increment - DBR interval in seconds, default 86400 (1 day)
     - retries   - number of retry attempts, default 3
     - allowSplitfiles - allows large files to get split up, default 1 (true)
     - host      - FCP host to use
     - port      - FCP port to use
     - maxthreads - maximum number of insert threads
    """

    self.map = metadata()

    # validation - only accept certain keywords, of certain type
    argmap = {'name':str, 'fromdir':str, 'todir':str, 'htl':int,
              'pub':str, 'priv':str, 'default':str,
              'splitsize':int, 'map':metadata,
              'offset':int, 'increment':int, 'retries':int, 'allowSplitfiles':int,
              'host':str, 'port':int, 'future':int,
              'siteType':str, 'edition':int, 'editionMaxTries':int, 'maxthreads':int,
              'sskSuffix':str,
              }
    self.args = self.chkArgs(argmap, **args)

    if not args.has_key('retries'):
        self.retries = 3
</t>
<t tx="aum.20060509223528.70">def chkArgs(self, argmap, **args):
    """
    Retrieve arguments from args, validate names and types
    """
    goodargs = {}
    for arg in args.keys():
        val = args[arg]
        if not argmap.has_key(arg):
            raise FreenetFreesiteBadArgument(
                "Illegal keyword: '%s'" % arg)
        typ = argmap[arg]
        if typ == str:
            typ = (str, MutableString)
        if not isinstance(val, typ):
            raise FreenetFreesiteBadArgument(
                "'%s' should be type '%s'" % (arg, repr(typ)))
        goodargs[arg] = val
    return goodargs
</t>
<t tx="aum.20060509223528.71">def put(self, fromdir=None, **args):
    """
    Insert this site object into freenet as a complete freesite
    Arguments:
     - fromdir - directory to insert form. If not given, attempts to
       take this from instance variables
    Keywords:
     - host - FCP host to use, defaults to constructor arg
     - port - FCP port to use - defaults to constructor arg

     - siteType - style of freesite - 'dbr', 'edition' or 'oneshot', defaults to constructor
       argument (see __init__)
     - edition - if siteType is 'edition', specifies the edition number from which
       to start insert attempts. defaults to constructor arg (see __init__)
     - editionMaxTries - maximum number of edition numbers to try - failure results if we
       exhaust all tries - defaults to contstructor arg (see __init__)

     - name (optional, defaults to 'site'
       called, otherwise taken from instance var
     - htl - optional, default 20
     - pub - ssk public key
     - priv - ssk private key
     - future - optional, default 0
     - default - file to use as site default, default 'index.html'
     - splitsize - size of splitfile chunks, default 262144
     - offset - dbr offset in seconds, default 0
     - increment - dbr increment in seconds, default 86400
     - maxthreads - default 8, maximum number of parallel insert threads
     - allowSplitfiles - default 1, allow large files to be split
     - files - dict of files to insert into the freesite. The keys of the dict are
       relative paths (as they appear, for example:
         - the 'path/to/file.txt' in 'SSK@BblahblahPAgM/fred//path/to/file.txt'.
       The value is a dict containing the keys:
         - mimetype - a standard mimetype string, AND one of:
             - raw - a raw string comprising the file's content, OR
             - fullpath - an absolute path on the host filesystem
       Example::

         { 'index.html' ;     {'mimetype' : 'text/html',
                               'raw' : '&lt;html&gt;&lt;body&gt;Here is index.html&lt;/body&gt;&lt;/html&gt;'
                               },
           '/fred/mary.txt' : {'mimetype' : 'text/plain',
                               'raw' : 'This is fred/mary.txt'
                               },
           }

    Returns:
     - a uri object for the inserted site

    After any insertion attempt, the pub/priv keypair, htl, splitsize, offset
    and increment get stored in a pickle in file /.freesiterc in the site's
    directory - but only if the caller did not pass a fileset
    """

    dontsave = False

    # create temporary instance if needed
    #if not isinstance(self, site):
    #    inst = site()
    #    return inst.put(fromdir, **args)

    LOGMSG(4, "site.put: entered")

    if args.has_key('files'):
        files = args['files']
        lastconf = {}
        dontsave = True
    else:
        # determine source directory
        if fromdir == None:
            fromdir = self.args.get('fromdir')
        if fromdir == None:
            raise FreenetFreesiteBadDir('')
        LOGMSG(3, "site.put: fromdir='%s'" % fromdir)
    
        # Read the 'fromdir' directory
        try:
            files = self.readdir(fromdir)
        except OSError:
            raise FreenetFreesiteBadDir(fromdir)
        if len(files) == 0:
            raise FreenetFreesiteBadDir(fromdir)
    
        # Try to uplift configuration from freesite dir as '.freesiterc'
        #print "Trying to uplift config from %s" % self.fromdir
        conffile = "%s/.freesiterc" % fromdir
        try:
            # pick up keys from pickled file
            fd = open(conffile)
            lastconf = pickle.load(fd)
            fd.close
            LOGMSG(3, "site.put: got configs from site dir")
        except:
            lastconf = {}
            LOGMSG(3, "site.put: inserting site for the first time")

    # general args
    host = args.get('host', self.args.get('host', defaultHost))
    port = args.get('port', self.args.get('port', defaultPort))
    name = lastconf.get('name', args.get('name', self.args.get('name', 'site')))
    pub = args.get('pub', self.args.get('pub', lastconf.get('pub', None)))
    priv = args.get('priv', self.args.get('priv', lastconf.get('priv', None)))
    default = args.get('default', lastconf.get('default', self.args.get('default', 'index.html')))
    splitsize = args.get('splitsize', lastconf.get('splitsize', self.args.get('splitsize', 262144)))
    htl = args.get('htl', self.args.get('htl', lastconf.get('htl', 20)))
    allowSplitfiles = args.get('allowSplitfiles', self.args.get('allowSplitfiles', defaultAllowSplitfiles))

    maxthreads = args.get('maxthreads', self.args.get('maxthreads', defaultMaxSiteThreads))

    # site-type-specific args
    siteType = args.get('siteType', lastconf.get('siteType', self.args.get('siteType', 'dbr')))
    edition = args.get('edition', lastconf.get('edition', self.args.get('edition', 0)))
    editionMaxTries = args.get('editionMaxTries', lastconf.get('editionMaxTries', self.args.get('editionMaxTries', 0)))
    offset = lastconf.get('offset', args.get('offset', self.args.get('offset', 0)))
    increment = lastconf.get('increment', args.get('increment', self.args.get('increment', 86400)))
    future = args.get('future', self.args.get('future', 0))

    sskSuffix = args.get('sskSuffix', self.args.get('sskSuffix', 'PAgM'))

    # take action for different site types
    if siteType == 'oneshot':
        manifestPubUri = uri("SSK@%s%s/%s" % (pub, sskSuffix, name))
        manifestPrivUri = uri("SSK@%s/%s" % (priv, name), sskpriv=True)
        pass

    elif siteType == 'edition':
        pass

    elif siteType == 'dbr':
        dbrPrefix = dbr(future, increment, offset)
        manifestPubUri = uri("SSK@%s%s/%s-%s" % (pub, sskSuffix, dbrPrefix, name))
        manifestPrivUri = uri("SSK@%s/%s-%s" % (priv, dbrPrefix, name), sskpriv=True)

        LOGMSG(3, "manifestPrivUri=%s" % manifestPrivUri)
        LOGMSG(3, "manifestPubUri=%s" % manifestPubUri)
        LOGMSG(3, "offset=%s" % offset)
        LOGMSG(3, "increment=%s" % increment)
        LOGMSG(3, "future=%d" % future)
        LOGMSG(3, "dbr-prefix=%s" % dbrPrefix)

    # grab a temporary FCP interface object
    mynode = node(host, port, htl, allowSplitfiles=allowSplitfiles)

    gotprevkeys=False # means we need to write keys
    # make up some keys, if needed
    if (pub == None) ^ (priv == None):
        raise FreenetFreesiteBadKeys(pub, priv)

    # Create new keypair if we don't have one
    if pub == None:
        (pub, priv) = mynode.genkeypair()
        LOGMSG(3, "site.put: created new keys pub=%s, priv=%s" % (pub, priv))

    # determine key URIs
    puburi = uri("SSK@%s%s/%s" % (pub, sskSuffix, name))
    privuri = uri("SSK@%s/%s" % (priv, name), sskpriv=True)

    LOGMSG(3, "puburi=%s" % puburi)
    LOGMSG(3, "privuri=%s" % privuri)
    LOGMSG(3, "name=%s" % name)
    LOGMSG(3, "pubkey=%s" % pub)
    LOGMSG(3, "privkey=%s" % priv)
    LOGMSG(3, "default=%s" % default)
    LOGMSG(3, "splitsize=%d" % splitsize)
    LOGMSG(3, "htl=%d" % htl)

    # ----------------------
    # Insert all the files
    # ----------------------
    
    # function to be run in dispatcher threads, to insert each file
    def inserter(dispObj, f):
        files = dispObj.files
        LOGMSG(4, "site.put: Inserting file %s, %d threads running" % (f, dispObj._numrunning))
        if files[f].has_key('fullpath'):
            fd = open(files[f]['fullpath'])
            fdat = fd.read()
            fd.close()
        elif files[f].has_key('raw'):
            fdat = files[f]['raw']
        else:
            raise FreenetFreesiteBadArgument("relative path '%s' has neither file nor raw content" % f)
        metaFile = metadata()
        metaFile.add('', mimetype=files[f]['mimetype'])
        #if allowSplitfiles:
        #    raise Exception
        mynode = node(dispObj.host, dispObj.port, dispObj.htl, allowSplitfiles=dispObj.allowSplitfiles)

        curbackoff = 3
        expbackoff = 1.25
        while 1:
            try:
                insertedkey = mynode.put(fdat,
                                         metaFile,
                                         "CHK@",
                                         htl=dispObj.htl,
                                         allowSplitfiles=dispObj.allowSplitfiles)
                files[f]['uri'] = insertedkey.uri
                LOGMSG(3, "site.put: File %s inserted as %s, %d threads running" % (
                                f, files[f]['uri'], dispObj._numrunning))
                break
            except FreenetRouteNotFound:
                LOGMSG(2, "site.put: got RNF inserting file %s\nbacking off for %s secs" % (
                               f, curbackoff))
                time.sleep(curbackoff)
                curbackoff = curbackoff * expbackoff

    # create a dispatcher object and feed in common attributes
    dispObj = Dispatcher(inserter, maxthreads)
    dispObj.files = files
    dispObj.host = host
    dispObj.port = port
    dispObj.htl = htl
    dispObj.allowSplitfiles = allowSplitfiles

    # load dispatcher with insert jobs
    for f in files.keys():
        dispObj.add(f)

    # launch insert dispatcher
    LOGMSG(3, "site.put: Launching dispatcher for file inserts")
    dispObj.start()
    
    # wait for dispatcher to finish
    LOGMSG(3, "site.put: Waiting for dispatcher to complete")
    dispObj.wait()
    LOGMSG(3, "site.put: Dispatcher has finished")

    if 0: # old insert loop - one at a time - yikes
        for f in files.keys():
            LOGMSG(4, "site.put: Inserting file %s" % f)
            if files[f].has_key('fullpath'):
                fd = open(files[f]['fullpath'])
                fdat = fd.read()
                fd.close()
            elif files[f].has_key('raw'):
                fdat = files[f]['raw']
            else:
                raise FreenetFreesiteBadArgument("relative path '%s' has neither file nor raw content" % f)
            metaFile = metadata()
            metaFile.add('', mimetype=files[f]['mimetype'])
            #if allowSplitfiles:
            #    raise Exception
            insertedkey = mynode.put(fdat, metaFile, "CHK@", htl=htl, allowSplitfiles=allowSplitfiles)
            files[f]['uri'] = insertedkey.uri
            LOGMSG(3, "site.put: File %s inserted as %s" % (f, files[f]['uri']))

    # Construct metadata for site manifest
    manifest = metadata()
    for f in files.keys():
        manifest.add(f, "Redirect", target=files[f]['uri'])
    # Don't forget our default file!
    manifest.add("", "Redirect",
                 target=files[default]['uri'],
                 mimetype=guessMimetype(default))

    # insert the manifest at a URI according to the site type (dbr/edition/oneshot)
    if siteType == 'dbr':
        # Create and Insert DBR main pointer key
        metaDbr = metadata()
        metaDbr.add('', 'DateRedirect',
                    target=puburi,
                    increment=increment,
                    offset=offset)
        #print metaDbr
        LOGMSG(4, "site.put: about to insert dbr")
        mynode.put('', metaDbr, privuri, htl=htl, allowSplitfiles=0)
        LOGMSG(3, "site.put: dbr inserted")
    
        # Now insert the manifest du jour as the dbr target
        LOGMSG(4, "site.put: inserting manifest to %s\n%s" % (manifestPrivUri, manifest))
        keyNow = mynode.put('', manifest, manifestPrivUri, htl=htl, allowSplitfiles=allowSplitfiles)

    elif siteType == 'oneshot':
        # just insert the manifest at the main URI
        LOGMSG(4, "site.put: inserting one-shot manifest at %s" % privuri)
        keyNow = mynode.put('', manifest, privuri, htl=htl, allowSplitfiles=allowSplitfiles)
    
    elif siteType == 'edition':
        # not quite so trivial - keep trying to insert until we stop getting key collisions
        LOGMSG(4, "site.put: attempting manifest inserts, starting at %s/%d" % (privuri, edition))
        curEd = edition
        if editionMaxTries != 0:
            maxEd = edition + editionMaxTries
        else:
            maxEd = 1000000000
        
        while curEd &lt; maxEd:
            manifestPrivUri = privuri + "/%d" % curEd
            manifestPubUri = puburi + "/%d" % curEd
            try:
                keyNow = mynode.put('', manifest, manifestPrivUri, htl=htl, allowSplitfiles=allowSplitfiles)
                edition = curEd
                keyNow.edition = edition
                break
            except FreenetKeyCollision:
                curEd = curEd + 1
                continue
        if curEd == maxEd:
            raise FreenetEditionsExhausted("failed to insert edition freesite %s/n" % puburi)

    LOGMSG(3, "site.put: manifest inserted successfully")

    #set_trace()

    # Write out the keypair to the freesite dir if needed
    if not dontsave and not gotprevkeys:
        try:
            #print "Trying to write out keypair to %s/.sskkeys" % fromdir
            #set_trace()
            conf = {'name':name,
                    'pub':pub,
                    'priv':priv,
                    'default':default,
                    'htl':htl,
                    'offset':offset,
                    'increment':increment,
                    'splitsize':splitsize,
                    'allowSplitfiles':allowSplitfiles,
                    'siteType':siteType,
                    'edition':edition,
                    'editionMaxTries':editionMaxTries,
                    }
            fd = open(conffile, "w")
            pickle.dump(conf, fd)
            fd.close()
            LOGMSG(4, "site.put: saved settings")
        except:
            # directory must be write-protected - author's fault!
            LOGMSG(2, "site.put: failed to save site settings")
            pass

    # well, i'll be darned - might be done now!
    #print manifest
    LOGMSG(4, "puburi         = %s" % puburi)
    LOGMSG(4, "privuri        = %s" % privuri)
    LOGMSG(4, "manifestPubUri = %s" % manifestPubUri)
    LOGMSG(4, "manifestPrivUri = %s" % manifestPrivUri)
    LOGMSG(4, "keyNow         = %s" % keyNow)


    self.uri = puburi
    #return puburi
    return keyNow.uri
</t>
<t tx="aum.20060509223528.72">def get(self, siteuri=None, todir=None, docname=None, **args):
    """
    Retrieves a freesite, lock, stock'n'barrel.

    Arguments (not required if instance vars present):
     - siteuri - full URI of site to retrieve
     - todir - directory to store the retrieved site
       Note - this direcctory must already exist.
    Keywords:
     - past - number of time intervals (default 0) to regress
       when retrieving the site. Note that most DBR sites work
       at offset 0, increment 86400 (1 day)
     - htl - hops to live - how deeply to delve within the Freenet
       for retrieving this site
     - docname - only used during recursive calls - ignore this
     - host - FCP host to use, defaults to constructor arg
     - port - FCP port to use - defaults to constructor arg
    Returns:
     - True if retrieval succeeded, False if failed
    Note:
     - Site's files will be written *into* directory 'todir'
       So if you're fetching 'SSK@blahblah/somesite', you should
       perhaps create a directory called 'somesite' somewhere first.
    """

    # Create temporary instance if called statically
    #if not isinstance(self, site):
    #    inst = site()
    #    inst.get(siteuri, todir, **args)
    #    return inst

    LOGMSG(4, "site.retrieve: entered")

    self.failures = 0
    #set_trace()
    k = self.__get(siteuri, todir, **args)
    LOGMSG(3, "retrieve completed with %d failures" % self.failures)
    self.failures = 0
    self.uri = siteuri
    LOGMSG(4, "k=%s" % k)
    return k

</t>
<t tx="aum.20060509223528.73">def readdir(self, dirpath, prefix=''):
    """
    Reads a directory, returning a sequence of file dicts.
    Arguments:
      - dirpath - relative or absolute pathname of directory to scan
      
    Each returned dict in the sequence has the keys:
      - fullpath - usable for opening/reading file
      - relpath - relative path of file (the part after 'dirpath'),
        for the 'SSK@blahblah//relpath' URI
      - mimetype - guestimated mimetype for file
    """

    #set_trace()
    #print "dirpath=%s, prefix='%s'" % (dirpath, prefix)
    entries = {}
    for f in os.listdir(dirpath):
        relpath = prefix + f
        fullpath = dirpath + "/" + f
        if f == '.freesiterc':
            continue
        if os.path.isdir(fullpath):
            entries.update(self.readdir(dirpath+"/"+f, relpath + "/"))
        else:
            #entries[relpath] = {'mimetype':'blah/shit', 'fullpath':dirpath+"/"+relpath}
            entries[relpath] = { 'fullpath':dirpath+"/"+f,
                                 'mimetype':guessMimetype(f)
                                 }
    return entries

</t>
<t tx="aum.20060509223528.74">def __get(self, siteuri=None, todir=None, parentdoc=None, **args):
    """
    Private recursive method for site.get - do not call this method
    """
    
    LOGMSG(4, "site.__retrieve: entered")

    sskSuffix = args.get('sskSuffix', self.args.get('sskSuffix', 'PAgM'))

    host = args.get('host', self.args.get('host', defaultHost))
    port = args.get('port', self.args.get('port', defaultPort))
    htl = args.get('htl', self.args.get('htl', defaultHtl))

    self.node = node(host, port, htl)
    
    #
    # Get and validate args
    #
    if siteuri == None:
        if not self.args.has_key('name') or not self.args.has_key('pub'):
            raise FreenetFreesiteCantDetermineUri
        # got enough instance vars
        siteuri = uri(type='SSK',
                      hash=self.args['pub'],
                      sskpath=self.args['name'],
                      pub=sskSuffix)
        LOGMSG(1, "site.retrieve: fetching '%s'" % siteuri)
    else:
        if not isinstance(siteuri, uri):
            #set_trace()
            siteuri = uri(siteuri, pub=sskSuffix)
    if todir == None:
        todir = getattr(self, 'todir', None)
    if todir == None or todir == '' or not os.path.isdir(todir):
        os.makedirs(todir)
        #raise FreenetFreesiteBadDir(todir)

    LOGMSG(3, "site.retrieve: uri='%s', dir='%s'" \
                % (siteuri, todir))

    # Set htl and past args
    htl = args.get('htl', self.args.get('htl', 20))
    past = args.get('past', 0)

    #
    # Get the key
    #
    LOGMSG(3, "site.get: htl=%d name='%s' key='%s'" % (htl, parentdoc, siteuri))
    failed = True
    try:
        basekey = self.node.get(siteuri, raw=1, htl=htl, numtries=3)
    except:
        LOGMSG(2, "site.get: failed to get doc '%s', key '%s'" % (parentdoc, siteuri))
        self.failures += 1
        raise
    LOGMSG(3, "site.get: successfully got key '%s'" % siteuri)

    #
    # If there's no metadata map, just save the file
    #
    doclist = basekey.metadata.map.keys()
    if len(doclist) == 0:
        # save this key
        fd = self.opendocfile(todir, parentdoc)
        fd.write(str(basekey))
        fd.close()

    # recursively get all the files
    #set_trace()
    for doc in doclist:
        tgt = basekey.metadata.targeturi(doc)

        #set_trace()

        if type(tgt) == types.ListType:
            #
            # reassemble a splitfile
            #
            if parentdoc and not doc:
                doc = parentdoc
            fd = self.opendocfile(todir, doc)
            for chunk in tgt:
                try:
                    chunkKey = self.node.get(chunk, raw=1, htl=htl)
                except:
                    LOGMSG(3, "site.__get: failed to get chunk %s" % chunk)
                    fd.close()
                    os.unlink(splitname)
                    self.failures += 1
                    continue
                fd.write(str(chunkKey))
            fd.close()
        elif tgt != None:
            # named file target
            #set_trace()
            if parentdoc:
                doc = parentdoc
            self.__get(tgt, todir, doc, htl=htl)

        else:
            # no target - write out file now
            if parentdoc and not doc:
                doc = parentdoc
            fd = self.opendocfile(todir, doc)
            fd.write(str(basekey))
            fd.close()

    return basekey

    LOGMSG(4, "site.retrieve: metadata:\n%s" % basekey.metadata)

    #set_trace()
    tgt = basekey.metadata.targeturi(siteuri.mskpath, -past)

    LOGMSG(3, "site.retrieve: fetching map at %s" % tgt)
    nextkey = node.get(tgt, raw=1, htl=htl)
    LOGMSG(4, "site.retrieve: metadata:\n%s" % nextkey.metadata)

    LOGMSG(4, "nextkey = '%s'" % nextkey)
   
    return nextkey
</t>
<t tx="aum.20060509223528.75">def opendocfile(self, todir, docfile):
    """
    Internal utility - open a new doc file for writing,
    first creating any needed parent directories.

    Arguments:
     - todir - base directory
     - docname - name of document, which includes relative directory paths
    """

    if docfile == None or docfile == '':
        docfile = "__default__"

    fullpath = todir + "/" + docfile

    pathbits = fullpath.split("/")

    filename = pathbits.pop()
    parentdir = "/".join(pathbits)

    if not os.path.isdir(parentdir):
        os.makedirs(parentdir)

    LOGMSG(3, "writing key to file %s" % fullpath)
    fd = open(fullpath, "w")
    return fd

</t>
<t tx="aum.20060509223528.76">class key(MutableString):
    """
    freenet.key is a MutableString subclass
    extended to contain and manipulate *retrieved* freenet keys
    the raw key data, plus other pertinent stuff like metadata, uri etc.

    Client programs should not normally need to create key objects.

    Attributes:
      - data     - raw data for the key, also returned by repr(inst)
      - metadata - key's metadata
      - uri      - uri object for key
    Methods:
      - all the usual string methods
    """

    @others
</t>
<t tx="aum.20060509223528.77">def __init__(self, rawdata='', meta='', keyuri=None, **attrs):
    """
    Creates an instance of a key object.
    Arguments:
      - raw - raw data for key
      - meta - key's metadata
      - uri - key's uri
    Keywords:
      - host - FCP host, defaults to global 'defaultHost'
      - port - FCP port, defaults to global 'defaultPort'
    """

    #set_trace()
    if rawdata == None:
        rawdata = ''

    # stick in raw key data
    MutableString.__init__(self, rawdata)

    # add other mandatory stuff
    #print "key init: metadata = ", meta
    if isinstance(meta, metadata):
        self.metadata = meta
    elif meta != '':
        self.metadata = metadata(meta)
    else:
        self.metadata = None

    self._sskSuffix = attrs.get('sskSuffix', 'PAgM')

    if isinstance(keyuri, uri):
        self.uri = keyuri
    elif keyuri == None:
        self.uri = None
    elif keyuri != '':
        self.uri = uri(keyuri, pub=self._sskSuffix)
    else:
        self.uri = None

    #print "freenet.key.__init__: keyuri='%s'" % keyuri
    #print "key init: attrs = ", attrs

    # now stick in the optional stuff
    self.host = defaultHost
    self.port = defaultPort

    for k in attrs.keys():
        #print "key init: adding attr ", k, "=", attrs[k]
        setattr(self, k, attrs[k])
</t>
<t tx="aum.20060509223528.78">def get(self, keyuri=None, **args):
    """
    Unimethod which retrieves the key

    Atguments:
     - keyuri - URI to fetch. If none, looks for URI instance var
    Returns:
     - if called statically, returns a new key object with the retrieved key
     - if called from an instance, fetches the key into the instance and
       returns a ref to that instance.
    Keywords:
     - htl - hops to live
     - retries - number of times to retry, default 0
     - graceful - default False, fail gracefully, returning None
       if graceful is not set, then key read failures raise an exception
    """
    #set_trace()
    #if not isinstance(self, key):
    #    return key('', '', keyuri).get(**args)

    if keyuri == None:
        if self.uri == None:
            raise FreenetKeyReadFail("&lt;no uri&gt;")
        else:
            keyuri = self.uri
        
    # create temporary accessor object
    #set_trace()
    host = args.get('host', self.host)
    port = args.get('port', self.port)
    
    mynode = node(host, port)

    retries = args.get('retries', 0)
    htl = args.get('htl', 20)
    graceful = args.get('graceful', 0)
    LOGMSG(3, "key.get: htl=%d retries=%d graceful=%d uri=%s" \
                % (htl, retries, graceful, keyuri))
    
    failed = True
    for i in range(retries+1):
        try:
            k = mynode.get(keyuri, htl=args.get('htl', 20))
            failed = False
            break;
        except FreenetKeyNotFound:
            pass
    if failed:
        if not graceful:
            raise FreenetKeyNotFound
        else:
            return None

    # success
    self.data = k.data
    self.metadata = k.metadata
    self.uri = k.uri
    return self
</t>
<t tx="aum.20060509223528.79">def put(self, keyuri=None, rawdata=None, meta=None, **args):
    """
    Unimethod which inserts a key

    Atguments:
     - keyuri - URI to insert. If none, seeks uri from instance vars
     - rawdata - raw data to insert,
     - metadata - metadata to insert with key
    Keywords:
     - htl - hops to live, default taken from instance if called from instance
     - raw - default 1, whether to insert as raw
    Returns:
     - if called statically, returns a new key object with the retrieved key
     - if called from an instance, fetches the key into the instance and
       returns a ref to that instance.
    """
    #set_trace()
    #if not isinstance(self, key):
    #    return key(rawdata, meta, keyuri, **args).put()

    if keyuri != None:
        self.uri = keyuri
    if self.uri == None:
        raise FreenetKeyInsertFail("&lt;no uri&gt;")
    if rawdata != None:
        self.data = rawdata
    if meta != None:
        self.metadata = metadata(meta)
    if args.has_key('htl'):
        self.htl = args['htl']
    if args.has_key('raw'):
        self.raw = args['raw']
    else:
        self.raw = 1
    
    # create temporary accessor object
    host = args.get('host', self.host)
    port = args.get('port', self.port)
    
    mynode = node(host, port)

    mynode.put(self.data, self.metadata, self.uri, htl=self.htl)
    return self
</t>
<t tx="aum.20060509223528.80">class uri(MutableString):
    """
    Representation of a freenet key URI, broken up into its
    component parts.
    """

    reTrailpub = re.compile(".*(PAgM|BCMA)$")
    validKeyTypes = ['KSK', 'SSK', 'CHK', 'SVK', 'MSK']

    @others

</t>
<t tx="aum.20060509223528.81">def __init__(self, raw='', type='', hash='', sskpath='', mskpath='', pub='PAgM', **args):
    """
    Instantiates a URI object
    """

    fmtargs = "raw='%s', type='%s', hash='%s', sskpath='%s', mskpath='%s', pub='%s'" % (
                raw, type, hash, sskpath, mskpath, pub)
    LOGMSG(5, fmtargs)

    # just in case we're trying to use a uri object as the 'raw' arg
    if isinstance(raw, uri):
        self.type = raw.type
        self.hash = raw.hash
        self.sskpath = raw.sskpath
        self.mskpath = raw.mskpath
        self.pub = raw.pub
        self.data = raw.render()
        return

    elif raw:

        #print "uri: raw='%s'" % raw

        issskpriv = args.get('sskpriv', False)

        if (True in [i != '' for i in [type, hash, sskpath, mskpath]]):
            # spit - trying to instantiate with raw uri AND uri parts
            raise FreenetUriRawMustExcludeOthers(fmtargs)

        # key specs are one of:
        #  [freenet:]KSK@&lt;hash&gt;[//[&lt;mskpath&gt;]]
        #  [freenet:]CHK@&lt;hash&gt;[//[&lt;mskpath&gt;]]
        #  [freenet:]SSK@&lt;hash&gt;[/[&lt;sskpath&gt;]][//[&lt;mskpath&gt;]]
        #  [freenet:]CHK@&lt;hash&gt;[//[&lt;mskpath&gt;]]

        # strip off the 'freenet:'
        #tmp = raw.split("freenet:")
        if raw[0:8] in ["freenet:", "entropy:"]:
            raw = raw[8:]
        tmp = [raw]
 
        tmpl = len(tmp)
        if tmpl &gt; 2:
            print "fail 1"
            raise FreenetInvalidUriError(fmtargs)    # more than one 'freenet:' in uri
        elif tmpl == 2:
            if tmp[0] != '':
                print "fail 2"
                raise FreenetInvalidUriError(fmtargs) # there's stuff before the 'freenet:' in URI
            else:
                raw = tmp[1] # grab the bit after the 'freenet:'
        elif tmpl == 1:
            pass # ok - no 'freenet:' in uri
        else:
            print "fail 3"
            raise FreenetInvalidUriError(fmtargs) # empty raw string

        # now grab keytype
        tmp = raw.split("@")
        tmpl = len(tmp)
        if tmpl == 1:
            tmp[0:0] = ["KSK"]
        elif tmpl &gt; 2:
            print "fail 4"
            raise FreenetInvalidUriError(fmtargs) # must have exactly one '@'
        type = tmp[0]
        nextbit = tmp[1]
        if type not in self.validKeyTypes:
            print "fail 5"
            raise FreenetInvalidUriKeyType(fmtargs)

        mskpath = nextbit.split("//")
        premsk = mskpath.pop(0)
        mskpath = "//".join(mskpath)
        if type == 'SSK':
            # extract bits from SSK
            sskpath = premsk.split("/")
            hash = sskpath.pop(0)
            sskpath = "/".join(sskpath)
            #print "HASH =", hash
            if not self.reTrailpub.match(hash):
                #print "NO HASH MATCH"
                if not issskpriv:
                    #print "strange - no 'PAgM"
                    #print "fail 6"
                    #raise FreenetInvalidUriError # ssk hash doesn't end in magic 'PAgM'
                    pass
                else:
                    pass
                pub = ''

            if hash.endswith("PAgM") or hash.endswith("BCMA"):
                pub = hash[-4:]
                hash1 = hash[:-4]
            else:
                pub = ''
                hash1 = hash
            if hash == '':
                print "strange - no 'PAgM' or 'BCMA'"
                # raise FreenetInvalidUriError
            else:
                hash = hash1
        else:
            hash = premsk
            pub = ''

        self.type = type
        self.hash = hash
        self.pub = pub
        self.sskpath = sskpath
        self.mskpath = mskpath

    else:
        if type == '':
            type = 'KSK'
        if hash == '':
            raise FreenetInvalidUriError(fmtargs)
        if type not in self.validKeyTypes:
            raise FreenetInvalidUriKeyType(fmtargs)

        if type != 'SSK':
            pub = ''

        self.type = type
        self.hash = hash
        self.pub = pub
        self.sskpath = sskpath
        self.mskpath = mskpath

    self.data = self.render()


</t>
<t tx="aum.20060509223528.82">def render(self):
    """
    Assemble the URI components into a URI string
    """

    #print "uri_repr: entered"
        
    if self.type == 'SSK' and self.sskpath != '':
        sskbits = "/" + self.sskpath
    else:
        sskbits = ''
    if self.mskpath != '':
        mskbits = "//" + self.mskpath
    else:
        mskbits = ''

    if self.type in ['SSK', 'SVK']:
        ret = "%s@%s%s%s%s" % (self.type,
                               self.hash,
                               self.pub,
                               sskbits,
                               mskbits)
    else:
        ret = "%s@%s%s" % (self.type, self.hash, mskbits)
    #print "uri: repr = '%s'" % ret
    return ret
</t>
<t tx="aum.20060509223528.83">def dbr(self, future=0, increment=86400, offset=0):
    """
    Calculates a DBR-modified URI, based on offset and increment.
    Spits if the uri is not an SSK or KSK

    Arguments:
     - future - number of time intervals in future (default 0)

    Returns:
     - a new URI object with the date prefix

    Exceptions:
     - FreenetIllegalDBR - key is not a KSK or SSK, so DBR can't happen
    """
    if self.type not in ['KSK', 'SSK']:
        raise FreenetIllegalDBR(self.render())

    return uri(type=self.type,
               hash=self.hash,
               sskpath="%s-%s" % (dbr(future, increment, offset), self.sskpath),
               pub=self.pub)
</t>
<t tx="aum.20060509223528.84">def __repr__(self):
    """
    Render the URI into a plain string
    """
    return repr(self.render())
</t>
<t tx="aum.20060509223528.85">def __str__(self):
    """
    Return URI rendered as a plain string
    """
    return self.render()

</t>
<t tx="aum.20060509223528.86">class metadata(MutableString):
    """
    This class will develop into a 'swiss army knife' for freenet metadata

    With the metadata class, you can parse a raw metadata string
    received from a key fetch.

    You can also construct a metadata string with the high level
    methods.

    """

    @others
</t>
<t tx="aum.20060509223528.87"># build some regexps for parsing
reDocHeader = re.compile("\s*Version[\r\n]+\s*")
reDocFooter = re.compile("\s*End[ \t]*[\r\n]+")
rePartSep = re.compile("\s*EndPart[\r\n]+\s*Document[\r\n]+\s*")
reLineSep = re.compile("\s*[\r\n]+\s*")
reEqSep = re.compile("\s*=\s*")

MetadataKeywords = ['Name',
                    'Info.Format',
#                        'Info.Description',
                    'Redirect.Target',
                    'DateRedirect.Target',
                    'DateRedirect.Offset',
                    'DateRedirect.Increment',
                    'SplitFile.Size', 
                    'SplitFile.BlockCount',
                    'SplitFile.Block.[0-9a-fA-F]+']
#print MetadataKeywords
MetadataKeywords = ["^%s$" % k.replace(".", "\\.") for k in MetadataKeywords]
#print MetadataKeywords
reMetaKeywords = re.compile("|".join(MetadataKeywords))
#print "ok"

data = ''
metaRevision = '1'
metaParts = []
metaDict = {}
metaTrailing = ''

</t>
<t tx="aum.20060509223528.88">def __init__(self, raw=None, **args):
    """
    Constructor for metadata objects.

    You can instantiate a metadata object in one of 2 ways:
     - pass the constructor an existing string of raw metadata,
       as received from a freenet key fetch, or
     - pass in nothing, or some high-level keywords, to build
       up a complete metadata object from scratch. Note that
       if you dont' give any keywords, you can invoke the 'add'
       method at any time to add documents to the metadata.

    Arguments:
     - raw  - optional - Raw string to be parsed upon creation
       of the object
    Keywords:
     - to be defined
    Exceptions:
     - to be defined
    """

    # save the raw string, if any
    if raw == None:
        raw = ''
    #self.data = raw
    self.map = {}
    if isinstance(raw, metadata):
        self.map = raw.map
        self.data = raw.data
        self.metaTrailing = raw.metaTrailing
        self.metaRevision = raw.metaRevision
    else:
        self.parseRaw(raw)

</t>
<t tx="aum.20060509223528.89">def add(self, name='', action=None, **args):
    """
    Add a document to a metadata map.
    Arguments:
     - name - name of the document
       (eg, 'fred', for SSK@blahdeblah/blahdeblah//fred)
     - mimetype - MIMEtype of the document, default 'text/plain'.
     - action - how to fetch the document, one of:
        - None (default) - look no further (invalid unless name = '')
        - 'Redirect'     - perform a straight redirect to another key
        - 'DateRedirect' - do a date-based redirect to another key
        - 'SplitFile'    - swarm in the document from a splitfile spec

    Keyword Args (required or not, according to 'action'):
     - target ([Date]Redirect only) - target URI to go for
     - mimetype - the mimetype for the file
     - offset (DateRedirect only) - DBR offset in seconds from
       midnight GMT, default 0
     - increment (DateRedirect only) - frequency of DBR in seconds
       (default 86400, 1 day)
     - splitsize (SplitFile only, mandatory, no default) - size of each
       splitfile chunk
     - splitchunks (Splitfile only, mandatory, no default) a sequence of
       URIs for the splitfile chunks, in exact order
     - extras - a dict of extra declarations, that will be rendered into
       the document metadata verbatim.

    Returns:
     - None

    Exceptions:
     - lots - yet to be defined

    Examples:
     - x.add("images/fred.jpg", mimetype="image/jpeg")
     - x.add("fred.jpg", "Redirect", target="CHK@blahblah", mimetype="image/jpeg")
     - x.add("fred.html", "DateRedirect", target="KSK@blah", mimetype="text/html",
       increment=3600)

    Warning:
     - If you add a doc with the same name as an existing doc, the old one will
       get overwritten by the new one, without warning.

    For more information on metadata, refer to the Metadata Specification
    on the Freenet website - www.freenetproject.org, click on
    'Developers/Public Area'.
    """
    # Are we adding the default document?
    if action==None or action == '':
        # spit if any illegal keywords given
        for arg in args.keys():
            if arg not in ['mimetype', 'extras']:
                raise FreenetMetadataBadArguments(
                    "No keywords allowed with default action except 'mimetype' and 'extras'")
        # spit if name given
        if name != '':
            raise FreenetMetadataBadArguments(
                "You must specify an 'action' keyword when adding a non-default document")
        mimetype = args.get('mimetype', 'text/plain')
        self.map[name] = {'mimetype': mimetype, 'action':''}

    # Adding a Redirect document?
    elif action=='Redirect':
        # just need redirect target, spit at anything else
        if not args.has_key('target'):
            raise FreenetMetadataBadArguments(
                "Redirect requires 'target' keyword")
        for k in args.keys():
            if k not in ['target', 'mimetype', 'extras']:
                raise FreenetMetadataBadArguments(
                    "'target' is the only permitted arg with redirect")
        tgturi = uri(args['target'])
        self.map[name] = {'action':'Redirect', 'target':tgturi}
        if args.has_key('mimetype'):
            self.map[name]['mimetype'] = args['mimetype']

    # Adding a DateRedirect?
    elif action=='DateRedirect':
        # date-based redirect - pick off dbr-related args
        if not args.has_key('target'):
            raise FreenetMetadataBadArguments(
                "DateRedirect requires 'target' keyword")
        for k in args.keys():
            if k not in ['target', 'offset', 'increment', 'extras']:
                raise FreenetMetadataBadArguments(
                    "Illegal DBR argument keyword '%s'" % k)
        tgturi = uri(args['target'])
        offset = args.get('offset', 0)
        increment = args.get('increment', 86400)
        self.map[name] = {'action':'DateRedirect', 'target':tgturi}
        if offset != 0:
            self.map[name]['offset'] = offset
        if increment != 86400:
            self.map[name]['increment'] = increment

    # Adding a SplitFile set?
    elif action=='SplitFile':
        if not args.has_key('splitsize'):
            raise FreenetMetadataBadArguments(
                "Missing splitsize")
        if not args.has_key('splitchunks'):
            raise FreenetMetadataBadArguments(
                "Missing splitchunks")
        splitchunks = args['splitchunks']
        if not isinstance(splitchunks, list):
            raise FreenetMetadataBadArguments(
                "splitchunks arg should be a list of URIs")
        for k in args.keys():
            if k not in ['splitsize', 'splitchunks', 'extras']:
                raise FreenetMetadataBadArguments(
                    "Illegal DBR argument keyword '%s'" % k)
        # splitfiles need a default mimetype
        mimetype = args.get('mimetype', 'text/plain')

        # grab chunk details
        splitsize = int(args['splitsize'])
        splitchunks = [uri(chunk) for chunk in splitchunks]

        # construct map entry
        self.map[name] = {'action':'SplitFile',
                          'splitsize':splitsize,
                          'splitchunks':splitchunks,
                          'mimetype':mimetype}
    else:
        raise FreenetMetadataBadArguments(
            "Illegal action '%s'" % action)

    # add any extras
    self.map[name]['extras'] = args.get('extras', {})
</t>
<t tx="aum.20060509223528.90">def set(self, doc, attr, val=None):
    """
    Set the metadata attributes for a document in the map.

    Older settings remain intact, unless the attributes you're passing
    include a name of an existing attribute. (For example, if existing
    map has 'Info.Format', and     you call this func with a new
    'Info.Format' setting, it will overwrite the old one).

    Arguments:
     - doc - name of document in the map. If document is not present in map,
       an exception will occur
     - Either:
         - attribs - dict of attribs to set for this document
       OR:
         - name - name of attrib to set
         - value - value of attrib
    """

    # is doc already in the map?
    if not self.map.has_key(doc):
        raise FreenetMetadataBadArguments("set(): doc '%s' nonexistent in map" % doc)

    if type(attr) is types.DictType:
        for k in attr.keys():
            if k == 'mimetype':
                self.map[doc]['mimetype'] = attr[k]
            else:
                self.map[doc]['extras'][k] = attr[k]
    elif isinstance(attr, str):
        if val != None:
            self.map[doc]['extras'][attr] = str(val)
    else:
        raise FreenetMetadataBadArguments("set: must pass dict or name and value")
</t>
<t tx="aum.20060509223528.91">def targeturi(self, doc='', future=0, **kw):
    """
    Determines the target uri required to reach document 'doc'.
    Automatically handles redirects, dateredirects etc.

    Arguments:
     - doc - the document to look up in the map. Defaults to the map's
       default document
     - future - only valid for date-based redirect - number of time intervale
       in the future to calculate
    Returns - depends on document action:
     - None, if there are no redirects or splitfiles
     - uri of target, if it's a straight redirect or dateredirect
     - sequence of splitfile URIs, if target is a splitfile
    Exceptions:
     - FreenetMetadataNoSuchDocument - document is not present in the map
    """


    if doc == None:
        doc = ''
    if not self.map.has_key(doc):
        if doc == '':
            return None # bit of a fudge
        else:
            u = self.targeturi()
            #set_trace()
            u.mskpath = doc
            return u
            return uri(str(u) + "//" + doc) # yikes - hack alert!!!
        #raise FreenetMetadataNoSuchDocument

    docprops = self.map[doc]
    action = docprops['action']

    if action == '':
        # use data from this key, don't chase metadata
        return None 

    elif action == 'Redirect':
        return docprops['target']

    elif action == 'DateRedirect':
        tgt = docprops['target']
        return tgt.dbr(future, docprops['increment'], docprops['offset'])

    elif action == 'SplitFile':
        return docprops['splitchunks']

    else:
        raise FreenetMetadataNoSuchDocument(doc)
</t>
<t tx="aum.20060509223528.92">def documents(self):
    """
    Returns a list of documents listed in the key's metadata map
    """
    return self.metadata.map.keys()
</t>
<t tx="aum.20060509223528.93">def parseRaw(self, raw='', strict=True):
    """
    Parse and store a raw metadata string.
    Discards any old metadata strings or elements that were stored.
    """

    if not isinstance(raw, str) and not isinstance(raw, MutableString):
        raise FreenetMetadataNotStringError

    #set_trace()

    #print "parseRaw: parsing metadata '%s'\n" % raw
    strict = True

    self.data = raw
    self.metaRevision = '1'
    #self.metaParts = []
    self.map = {}
    self.metaTrailing = ''
    if raw=='':
        #print "no metadata"
        return None # nothing to do

    #set_trace()

    # tear off header
    raw = self.reDocHeader.split(raw, 1)
    if len(raw) == 1:
        if strict:
            raise FreenetMetadataBadHeader
        return False # can't do much more here
    if raw[0] != '':
        if strict:
            raise FreenetMetadataBadHeader
        # if not strict, can just ignore junk before header
    raw = raw[1]

    # tear off footer
    raw = self.reDocFooter.split(raw, 1)
    if len(raw) == 1:
        if strict:
            raise FreenetMetadataBadFooter
        return False # missing footer
    self.metaTrailing = raw[1]
    raw = raw[0]

    # now, can carve up into parts
    parts = self.rePartSep.split(raw)
    if len(parts) == 0:
        return False # no actual metadata here!

    # dice up each section into lines
    parts = [[self.parseRawLine(line)
                for line in self.reLineSep.split(part)]
                  for part in parts]

    # extract and validate head section
    headpart = parts.pop(0)
    if len(headpart) != 1 or len(headpart[0]) != 2 or headpart[0][0] != 'Revision':
        if strict:
            raise FreenetMetadataBadRevision
        else:
            self.metaRevision = '1' # sane default
    else:
        self.metaRevision = headpart[0][1]

    #
    # now convert the whole thing into a dict of doc names with properties
    #
    metadict = {}
    #print 'dicing up into parts:\n', parts
    for part in parts:
        absDict = {} # absDict == 'abstract dictionary'
        partdict = dict(part)
        name = partdict.get('Name', '')
        if partdict.has_key('Info.Format'):
            absDict['mimetype'] = partdict.get('Info.Format')
        if partdict.has_key('Info.Description'):
            absDict['mimetype'] = partdict.get('Info.Description')

        # handle other keywords
        if partdict.has_key('Redirect.Target'):
            # plain redirect
            absDict['action'] = 'Redirect'
            absDict['target'] = uri(partdict['Redirect.Target'])
            absDict['args'] = partdict
        elif partdict.has_key('DateRedirect.Target'):
            # Date-based redirect
            absDict['action'] = 'DateRedirect'
            #absDict['DateRedirect.Target'] = partdict.get('DateRedirect.Target')
            absDict['target'] = uri(partdict['DateRedirect.Target'])
            # note - 86400 == 0x15180
            absDict['increment'] = int(partdict.get('DateRedirect.Increment', '15180'), 16)
            absDict['offset'] = int(partdict.get('DateRedirect.Offset', '0'), 16)
            absDict['args'] = partdict
        elif partdict.has_key('SplitFile.BlockCount'):
            # Splitfile
            absDict['action'] = 'SplitFile'
            absDict['splitsize'] = int(partdict['SplitFile.Size'], 16)
            nblocks = int(partdict['SplitFile.BlockCount'], 16)
            blocks = []
            #set_trace()
            for i in range(nblocks):
                tmpuri = uri(partdict['SplitFile.Block.%x' % (i+1)])
                blocks.append(tmpuri)
            absDict['splitchunks'] = blocks
        else:
            # No action - only parse mimetype
            absDict['action'] = ''
            if not absDict.has_key('mimetype'):
                absDict['mimetype'] = "text/plain"

        # add the extras
        absDict['extras'] = {}
        for e in partdict.keys():
            if not self.reMetaKeywords.match(e):
                absDict['extras'][e] = partdict[e]

        # add to the map
        metadict[name] = absDict
    #print "parts:\n", parts

    # save the parts
    #self.metaParts = parts
    self.map = metadict
</t>
<t tx="aum.20060509223528.94">def __repr__(self):
    """
    Return a rendered string representation of the metadata
    """
    #set_trace()
    return repr(self.render())
</t>
<t tx="aum.20060509223528.95">def __str__(self):
    """
    Return a printable string of the rendered metadata
    """
    #set_trace()
    return self.render()
</t>
<t tx="aum.20060509223528.96">def parseRawLine(self, line):
    """
    Dices up a 'field = val' line
    Strips all leading/trailing spaces
    """

    bits = self.reEqSep.split(line, 1)
    if len(bits) != 2 or bits[0] == '':
        raise FreenetMetadataBadLine(line)
    return bits
</t>
<t tx="aum.20060509223528.97">def render(self):
    """
    Assemble a raw metadata string from this object's metadata components
    """
    #print "calling repr"
    parts = ["Version\nRevision=%s\n" % self.metaRevision]

    #numparts = len(self.metaParts)
    #for i in range(0, numparts):
    #    if i &lt; numparts:
    #        raw += "EndPart\nDocument\n"
    #    for line in self.metaParts[i]:
    #        raw += "%s=%s\n" % (line[0], line[1])
    #raw += "End\n"
    #raw += self.metaTrailing
    ##print raw.__class__
    #return raw

    #set_trace()

    # Build doc entries from our map
    for name in self.map.keys():
        rawpart = ''
        doc = self.map[name]
        if name != '':
            rawpart += "Name=%s\n" % name # Add name if not default doc
        action = doc['action']
        if action == 'Redirect':
            rawpart += "Redirect.Target=%s\n" % doc['target']
            if name == '':
            #    # default doc - add mimetype
            #    rawpart += "Info.Format=%s\n" % doc['mimetype']
                pass
        elif action == 'DateRedirect':
            rawpart += "DateRedirect.Target=%s\n" % doc['target']
            if doc.has_key('offset'):
                rawpart += "DateRedirect.Offset=%x\n" % doc['offset']
            if doc.has_key('increment'):
                rawpart += "DateRedirect.Increment=%x\n" % doc['increment']
        elif action == 'SplitFile':
            rawpart += "SplitFile.Size=%x\n" % doc['splitsize']
            chunks = doc['splitchunks']
            numchunks = len(chunks)
            rawpart += "SplitFile.BlockCount=%x\n" % numchunks
            for i in range(numchunks):
                rawpart += "SplitFile.Block.%x=%s\n" % (i+1, chunks[i])
        if doc.has_key('mimetype'):
            rawpart += "Info.Format=%s\n" % doc['mimetype']
        if doc.has_key('description'):
            rawpart += "Info.Description=%s\n" % doc['description']

        # Add the extra bits
        if doc.has_key('extras'):
            extras = doc['extras']
            for e in extras.keys():
                rawpart += "%s=%s\n" % (e, extras[e])
        parts.append(rawpart)
    
    # Now chuck it all together
    raw = "EndPart\nDocument\n".join(parts) + "End\n"
    return raw

</t>
<t tx="aum.20060509223528.98">class Dispatcher:

    """
    Class to manage the multi-threaded dispatch of a function, with
    each thread running the function with a different set of arguments

    Example::

      def myfunc(dispObj, arg1, **kw):

          # do some stuff
          time.sleep(random.randint(2, 10))
          print "global1 = %s" % dispObj.global1
          print "arg1 = %s" % arg1
          print "keywords: %s" % kw
        
      dispObj = Dispatcher(myfunc, 4)

      dispObj.global1 = "dispatcher-global arg"
      dispObj.add("First thread")
      dispObj.add("Second thread", a=1, x="blah")
      dispObj.add("Third thread", x=9)

      dispObj.start() # launch the dispatcher

      dispObj.wait() # wait till all jobs are complete
      
    """
    def __init__(self, func, maxthreads=8):
        """
        Constructs a thread dispatcher object.

        Arguments:
         - func - some callable which should be invoked in each thread
           Upon each dispatch, the func will be called in a thread. The
           first argument of the call will be a ref to this dispatcher
           object itself

         - maxthreads - maximum number of threads which can run at any
           one time - default 8

        If there are any data items which are not thread-specific, they
        should be written as instance attributes of the dispatcher.
        """
        self._func = func
        self._jobs = Queue.Queue(0)
        self._alldispatched = Queue.Queue(1)
        self._alldone = Queue.Queue(1)
        self._threads = Queue.Queue(0)
        self._maxthreads = maxthreads
        self._threadpool = threading.Semaphore(maxthreads)
        self._countlock = threading.Lock()
        self._numrunning = 0


    def start(self):
        """
        Starts the dispatcher engine
        """
        thread.start_new_thread(self._engine, ())


    def add(self, *args, **kw):
        """
        Adds a task to the dispatcher queue

        Arguments:
         - whatever you like, however many you like

        Keywords:
         - whatever you like, however many you like

        NOTES:

         1. When this task gets launched, the func will be called
            with a ref to the dispatcher object as the first argument,
            and the subsequent args following.

            So if you call this method as::

              dispObj.add(2, "xyz", a=8, b=9)

            then upon dispatch, the callable function will be invoked as::

              func(dispObj, 2, "xyz", a=8, b=9)

         2. It's perfectly ok to invoke this method at any times before, or
            after, you launch the engine with 'start'.
        """
        self._jobs.put((args, kw))


    def wait(self, timeout=-1):
        """
        Wait for all threads to terminate

        Arguments:
         - timeout - time in seconds to wait for threads to finish,
           default is to wait forever
        """
        # pass the quit sentinel to the engine
        self._jobs.put(None)

        # wait till all jobs are dispatched (none more to launch)
        self._alldispatched.get()

        # now wait till all remaining threads have terminated
        self._alldone.get()

    def quit(self):
        """
        Causes any call to 'wait()' to return.
        
        Typically, a thread will trigger this if it decides that the aim of the
        dispatcher object has been fulfilled
        """
        self._alldone.put(None)

    def _thread(self, *args, **kw):
        """
        Launched in a thread.
        Calls the callable func
        """
        self._countlock.acquire()
        self._numrunning += 1
        self._countlock.release()

        try:
            self._threads.put(None)
            self._func(self, *args, **kw)
            self._threadpool.release()
        except:
            LOGMSG(1, "A dispatcher thread crashed!!")
            traceback.print_exc()

        self._countlock.acquire()
        self._numrunning -= 1
        if self._numrunning == 0:
            self._alldone.put(None)
        self._countlock.release()


    def _engine(self):
        """
        Do the actual work of grabbing thread slots and dispatching
        the threads.
        """
        self._running = 1
        while 1:

            # get a thread slot, or wait till one comes available
            self._threadpool.acquire()

            # get a job, or wait till one comes available
            job = self._jobs.get()

            # have we received the 'please quit' sentinel?
            if job is None:
                self._alldispatched.put(None)
                return

            # no - we have a real job to launch
            args, kw = job
            thread.start_new_thread(self._thread, args, kw)
</t>
<t tx="aum.20060509223528.99"># Warm up a connection to the FCP host
def connect(fcphost="127.0.0.1",
            fcpport=8481,
            defaultHtl=15,
            raw=False,
            maxSplitThreads=4):
    """
    You must call this function before doing any other
    operations on Freenet.

    Arguments:
      - host            - FCP host to connect to (127.0.0.1)
      - defaultHtl      - default Hops To Live (15)
      - raw             - raw mode (False)
      - maxSplitThreads - max threads when inserting splitfiles (4)
    Returns:
      - None
    Exceptions:
      - Raises FreenetHostConnectFail exception if connection failed
    """

    global defaultHost
    global defaultPort

    try:
        node(fcphost, fcpport)
    except:
        raise FreenetHostConnectError("Failed to connect to node at %s:%s" % (fcphost, fcpport))

    # got a connection
    defaultHost = fcphost
    defaultPort = fcpport
</t>
<t tx="aum.20060509223528.100">def initfec(fcphost, fcpport):
    """
    Set up some shit in the fish module
    """

    #
    # export some of our stuff into module 'fcp'
    #

    # set up fish data structures
</t>
<t tx="aum.20060509223528.101">def verbosity(level=None):
    """
    Set the verbosity level for log messages.
    Arguments:
      - 0 - Shut Up
      - 1 - Critical messages only
      - 2 - Normal Detail
      - 3 - Verbose
      - 4 - Debug (very noisy)
    A second argument sets the verbosity for the python-level callback
    Returns:
      - None
    """
    global logLevel

    if level != None:
        #_checkIfConnected()
        #if level != None:
        #    freenet_.setLogDetail(level)
        #if pylevel != None:
        logLevel = level

    return logLevel
</t>
<t tx="aum.20060509223528.102">def tempFilename():
    """
    Wrapper around tempfile.mktemp that suppresses the
    shitty warning message
    """

    warnings.filterwarnings("ignore")
    t = tempfile.mktemp()
    warnings.resetwarnings()
    return t
</t>
<t tx="aum.20060509223528.103">def _transferArgs(args, kwds):
    """
    Extracts keywords in list 'kwds' from dict 'args'.
    Arguments:
      - args - dict of args
      - kwds - list of allowed keywords
    Returns:
      - a dict with only those args found in 'args'
    """
    retargs = {}
    for k in kwds:
        v = args.get(k, None)
        if v != None:
            retargs[k] = v
    return retargs
</t>
<t tx="aum.20060509223528.104">def guessMimetype(filename):
    """
    Returns a guess of a mimetype based on a filename's extension
    """
    m = mimetypes.guess_type(filename, False)[0]
    if m == None:
        m = "text/plain"
    return m
</t>
<t tx="aum.20060509223528.105">def dbr(future=0, increment=86400, offset=0):
    """
    Useful little utility func.
    
    Calculates a target prefix for Date-Based Redirects.
    Returns it as a hex string (since this is what's needed
    for FCP interactions).

    Arguments:
     - future (default 0) - number of time periods in the future
       to calculate
     - increment (default 86400) - the period of the DBR, most
       sites are based on a 1-day (86400 seconds) period
     - offset (default 0) - number of seconds after midnight GMT
       to calculate from. Most DBR sites are based around midnight GMT

    Returns:
     - number of seconds after the epoch, formatted as a string
       containing this number in hex format.
    """
    now = time.time()
    secsSinceFirstHit = now - offset
    lastHitTime = (int(secsSinceFirstHit/increment) * increment) + offset
    wantedHitTime = lastHitTime + (future * increment)
    return "%x" % wantedHitTime
</t>
<t tx="aum.20060509223528.106">def setLogCallback(func):
    global LOGMSG
    LOGMSG = func

def defaultLogCallback(level, msg, back=0):
    global logLevel
    msg = str(msg).replace("\r\n", "\n")
    if level &lt;= logLevel:
        caller = traceback.extract_stack()[-2-back]
        full = "%s:%s:%s(): %s" % (caller[0], caller[1], caller[2], msg.replace("\n", "\n* "))

        now = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(time.time()))
        finalmsg = "%s %s\n" % (now, full)
        sys.stdout.write(finalmsg)

LOGMSG = defaultLogCallback

           </t>
<t tx="aum.20060509223528.107">
base64tab = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789~-"
base64tabEntropy = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_~"

base64Reverse = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7,
                 'I': 8, 'J': 9, 'K':10, 'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 
                 'Q':16, 'R':17, 'S':18, 'T':19, 'U':20, 'V':21, 'W':22, 'X':23, 
                 'Y':24, 'Z':25, 'a':26, 'b':27, 'c':28, 'd':29, 'e':30, 'f':31, 
                 'g':32, 'h':33, 'i':34, 'j':35, 'k':36, 'l':37, 'm':38, 'n':39,
                 'o':40, 'p':41, 'q':42, 'r':43, 's':44, 't':45, 'u':46, 'v':47,
                 'w':48, 'x':49, 'y':50, 'z':51, '0':52, '1':53, '2':54, '3':55,
                 '4':56, '5':57, '6':58, '7':59, '8':60, '9':61, '~':62, '-':63}

base64ReverseE= {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7,
                 'I': 8, 'J': 9, 'K':10, 'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 
                 'Q':16, 'R':17, 'S':18, 'T':19, 'U':20, 'V':21, 'W':22, 'X':23, 
                 'Y':24, 'Z':25, 'a':26, 'b':27, 'c':28, 'd':29, 'e':30, 'f':31, 
                 'g':32, 'h':33, 'i':34, 'j':35, 'k':36, 'l':37, 'm':38, 'n':39,
                 'o':40, 'p':41, 'q':42, 'r':43, 's':44, 't':45, 'u':46, 'v':47,
                 'w':48, 'x':49, 'y':50, 'z':51, '0':52, '1':53, '2':54, '3':55,
                 '4':56, '5':57, '6':58, '7':59, '8':60, '9':61, '_':62, '~':63}

isentropy=0

@others
</t>
<t tx="aum.20060509223528.108">def str2b64(raw, **kw):

    # encode using standard RFC1521 base64
    enc = base64.encodestring(raw)
    
    # convert the characters to freenet or entropy encoding schemes
    if kw.get('entropy', 0):
        #b64tab = base64tab
        #b64rev = base64ReverseE
        #padchar = "-"
        enc = enc.replace("+", "_")
        enc = enc.replace("/", "~")
        enc = enc.replace("=", "-")
    else:
        #b64tab = base64tabEntropy
        #b64rev = base64Reverse
        #padchar = "_"
        enc = enc.replace("+", "~")
        enc = enc.replace("/", "-")
        enc = enc.replace("=", "_")
    enc = enc.replace("\n", "")
    return enc
</t>
<t tx="aum.20060509223528.109">def b642str(enc, nbits=None, **kw):
    """
    Decodes a base64 string (freenet or entropy encoded) back to a binary string

    Arguments:
     - enc - base64 string to decode
     - nbits - not used at present
    Keywords:
     - entropy - 1 to use Entropy's base64 alphabet (defaults to freenet)
    """
    # convert the characters from freenet or entropy encoding schemes
    # to standard RFC1521, so the base64 module can handle it
    if kw.get('entropy', 0):
        #b64tab = base64tab
        #b64rev = base64ReverseE
        #padchar = "-"
        enc = enc.replace("_", "+")
        enc = enc.replace("~", "/")
        enc = enc.replace("-", "=")
    else:
        #b64tab = base64tabEntropy
        #b64rev = base64Reverse
        #padchar = "_"
        enc = enc.replace("~", "+")
        enc = enc.replace("-", "/")
        enc = enc.replace("_", "=")

    # add pad chars as needed
    #enc = enc + "=" * (3 - ((len(enc) + 3) % 4))

    # now ready to decode
    raw = base64.decodestring(enc)
    return raw

</t>
<t tx="aum.20060509223528.110">def num2bits(n):
    "converts a long int to an array of bits"
    bits = []
    while n:
        bits.append(n % 2)
        n = n &gt;&gt; 1
    bits.reverse()
    return bits
</t>
<t tx="aum.20060509223528.111">def str2bits(s):
    "converts a string to a bit array"
    bits = []
    for c in s:
        cbits = []
        n = ord(c)
        for i in range(0,8):
            cbits.append(n % 2)
            n = n &gt;&gt; 1
        cbits.reverse()
        bits.extend(cbits)
    return bits

</t>
<t tx="aum.20060509223528.112">def bits2str(bits, threshold=0.5):
    """
    converts an array of bits into a raw string.
    NOTE - each 'bit' in the array can be a float, in which case the optional
    argument 'threshold' (default 0.5) is used to determine if it's a 1 or a 0
    """
    strlst = []
    bitnum = 0
    n = 0
    for bit in bits:
        if bit &gt;= threshold:
            val = 1
        else:
            val = 0
        n = (n &lt;&lt; 1) + val
        bitnum += 1
        if bitnum % 8 == 0:
            strlst.append(chr(n))
            bitnum = 0
            n = 0
    if bitnum % 8 != 0:
        n = n &lt;&lt; (8 - (bitnum % 8))
        strlst.append(chr(n))
    return "".join(strlst)
</t>
<t tx="aum.20060509223528.113">def bits2num(bits):
    n = 0
    for i in bits:
        n = (n &lt;&lt; 1) + i
    return n
</t>
<t tx="aum.20060509223528.114">def base64encodeEntropy(s):
    return str2b64(s, entropy=1)

def base64decodeEntropy(s, numbits=None):
    return b642str(s, numbits, entropy=1)
</t>
<t tx="aum.20060509223528.115">def ssk2bits(enc, **kw):
    """
    Converts an SSK key (pub or priv) into a bit array
    
    Arguments:
        - enc - the base64 string
    
    Keywords:
        - entropy - if 1, uses entropy's base64 alphabet (defaults to freenet)
    """
    isEntropy = kw.get('entropy', 0)
    
    s = b642str(enc+"A", entropy=isEntropy)
    return str2bits(s)

def ssk2bitsE(enc):
    return ssk2bits(enc, entropy=1)
</t>
<t tx="aum.20060509223528.116">def bits2ssk(bits, **kw):
    """
    Converts a bit array into an SSK key
    
    Arguments:
      - bits - a bit array
    Keywords:
      - entropy - if 1, uses entropy base64 alphabet for encoding (defaults to freenet)
    """
    isEntropy = kw.get('entropy', 0)
    
    s = bits2str(bits)
    return str2b64(s, entropy=isEntropy)[0:27]

def bits2sskE(bits):
    return bits2ssk(bits, entropy=1)
</t>
<t tx="aum.20060509223528.117">def str2num(s):
    """str2num(string) : long
    Convert a byte string to a long integer.

    This is (essentially) the inverse of num2str().
    """
    n = long(0)
    for ch in s:
        n = 256 * n + ord(ch)
    return n

</t>
<t tx="aum.20060509223528.118">def num2str(n):
    """
    convert a number back to a string
    """
    chars = []
    while n &gt; 0:
        rest, chn = divmod(n, 256)
        chars.append(chr(chn))
        n = rest
    chars.reverse()
    return "".join(chars)

</t>
<t tx="aum.20060509223528.119"># define a few exceptions

class FreenetError(Exception):
    """Generic Freenet Error"""
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return "%s" % str(self.value)

class FreenetDataNotFound(FreenetError):
    """Got a 'DataNotFound' from node"""

class FreenetRouteNotFound(FreenetError):
    """Got a 'RouteNotFound' from node"""

class FreenetNotConnectedError(FreenetError):
    """Must first connect to FCP host via connectHost()"""

class FreenetHostConnectError(FreenetError):
    """Failed to connect to host FCP access port"""

class FreenetUriRawMustExcludeOthers(FreenetError):
    """When instantiating a freenet.uri object, must pass a
    raw text uri, or the uri components, not both."""

class FreenetInvalidUriError(FreenetError):
    """Invalid syntax in key URI"""

class FreenetInvalidUriKeyType(FreenetError):
    """URI Key Types must be CHK, SSK, KSK or SVK"""

class FreenetInvalidHelloResponse(FreenetError):
    """Invalid response from ClientHello"""

class FreenetOperationFailed(FreenetError):
    """A freenet operation failed"""

class FreenetKeyNotFound(FreenetError):
    """Failed to retrieve a key"""

class FreenetKeyInsertFail(FreenetError):
    """Key Insertion failed"""

class FreenetKeyOpenFail(FreenetError):
    """Failed to open Key"""

class FreenetKeyCloseFail(FreenetError):
    """Failed to close Key"""

class FreenetKeyReadFail(FreenetError):
    """Failed to read from Key"""
    def __init__(self, val=None):
        self.val = val
    def __str__(self):
        return "Failed to read key %s" % self.val

class FreenetKeyWriteFail(FreenetError):
    """Failed to write from Key"""

class FreenetKeySequenceFail(FreenetError):
    """Failed to insert or retrieve sequenced key"""

class FreenetKeyCollision(FreenetError):
    """A key with the same URI has already been inserted"""

class FreenetEditionsExhausted(FreenetError):
    """An insert or fetch of an edition-based freesite has
    exhausted its editionMaxTries parameter"""

class FreenetMetadata(FreenetError):
    """Base class of metadata processing exceptions"""

class FreenetMetadataNotString(FreenetMetadata):
    """class metadata can only parse strings or MutableString objects"""

class FreenetMetadataBadHeader(FreenetMetadata):
    """Malformed header in metadata text"""

class FreenetMetadataBadFooter(FreenetMetadata):
    """Malformed footer in metadata text"""

class FreenetMetadataBadRevision(FreenetMetadata):
    """Malformed footer in metadata text"""

class FreenetMetadataSyntax(FreenetMetadata):
    """Catch-all for syntax errors in metadata"""

class FreenetMetadataBadLine(FreenetMetadata):
    """
    Malformed line in metadata
    """
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return "Bad Line: %s" % str(self.value)

class FreenetMetadataBadArguments(FreenetMetadata):
    """
    Illegal combination of arguments to freenet.metadata.addDoc()
    """
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return str(self.value)

class FreenetFreesiteBadArgument(FreenetMetadata):
    """
    Malformed line in metadata
    """
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return "Bad argument: %s" % self.value

class FreenetFreesiteBadDir(FreenetMetadata):
    """
    Malformed line in metadata
    """
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return "Error reading directory: %s" % self.value

class FreenetFreesiteBadKeys(FreenetMetadata):
    """
    Malformed line in metadata
    """
    def __init__(self, pub, priv):
        self.pub = pub
        self.priv = priv
    def __str__(self):
        return "One or both SSK keys '%s' and '%s' are invalid" % (self.pub, self.priv)

class FreenetFreesiteCantRefresh(FreenetMetadata):
    """
    Malformed line in metadata
    """
    def __init__(self, val):
        self.val = val
    def __str__(self):
        return "Can't refresh freesite: %s" % self.val

class FreenetFreesiteCantDetermineUri(FreenetMetadata):
    """
    Cannot determine URI for request
    """
    def __str__(self):
        return "Cannot determine URI from method args or instance vars"

class FreenetMetadataNoSuchDocument(FreenetMetadata):
    """
    Document doesn't exist in metadata map
    """
    def __init__(self, val):
        self.val = val
    def __str__(self):
        return "Metadata map has no document called '%s'" % self.val

class FreenetIllegalDBR(FreenetMetadata):
    """
    Can't calculate DBR on this URI
    """
    def __init__(self, val):
        self.val = val
    def __str__(self):
        return "Cannot calculate date-based redirect for key %s" % self.val

class FreenetFcpError(FreenetError):
    """
    Some failure with talking FCP to node
    """
    def __init__(self, val):
        self.val = val
    def __str__(self):
        return self.val

class FreenetFcpConnectError(FreenetError):
    """
    Some failure with connecting to FCP port
    """
    def __init__(self, val):
        self.val = val
    def __str__(self):
        return self.val
</t>
<t tx="aum.20060509224119">def readdir(dirpath, prefix='', gethashes=False):
    """
    Reads a directory, returning a sequence of file dicts.

    Arguments:
      - dirpath - relative or absolute pathname of directory to scan
      - gethashes - also include a 'hash' key in each file dict, being
        the SHA1 hash of the file's name and contents
      
    Each returned dict in the sequence has the keys:
      - fullpath - usable for opening/reading file
      - relpath - relative path of file (the part after 'dirpath'),
        for the 'SSK@blahblah//relpath' URI
      - mimetype - guestimated mimetype for file
    """

    #set_trace()
    #print "dirpath=%s, prefix='%s'" % (dirpath, prefix)
    entries = []
    for f in os.listdir(dirpath):
        relpath = prefix + f
        fullpath = dirpath + "/" + f
        if f == '.freesiterc' or f.endswith("~"):
            continue
        if os.path.isdir(fullpath):
            entries.extend(readdir(dirpath+"/"+f, relpath + "/", gethashes))
        else:
            #entries[relpath] = {'mimetype':'blah/shit', 'fullpath':dirpath+"/"+relpath}
            fullpath = dirpath + "/" + f
            entry = {'relpath' :relpath,
                     'fullpath':fullpath,
                     'mimetype':guessMimetype(f)
                     }
            if gethashes:
                h = sha.new(relpath)
                fobj = file(fullpath, "rb")
                while True:
                    buf = fobj.read(262144)
                    if len(buf) == 0:
                        break
                    h.update(buf)
                fobj.close()
                entry['hash'] = h.hexdigest()
            entries.append(entry)
    entries.sort(lambda f1,f2: cmp(f1['relpath'], f2['relpath']))

    return entries

</t>
<t tx="aum.20060509224221">def guessMimetype(filename):
    """
    Returns a guess of a mimetype based on a filename's extension
    """
    m = mimetypes.guess_type(filename, False)[0]
    if m == None:
        m = "text/plain"
    return m
</t>
<t tx="aum.20060511001853">def putdir(self, uri, **kw):
    """
    Inserts a freesite

    Arguments:
        - uri - uri under which to insert the key
    
    Keywords:
        - dir - the directory to insert - mandatory, no default.
          This directory must contain a toplevel index.html file
        - name - the name of the freesite, defaults to 'freesite'
        - usk - set to True to insert as USK (Default false)
        - version - the USK version number, default 0
        
        - filebyfile - default False - if True, manually inserts
          each constituent file, then performs the ClientPutComplexDir
          as a manifest full of redirects. You *must* use this mode
          if inserting from across a LAN

        - maxretries - maximum number of retries, default 3
        - priority - default 1

        - id - the job identifier, for persistent requests
        - async - default False - if True, return immediately with a job ticket
        - persistence - default 'connection' - the kind of persistence for
          this request. If 'reboot' or 'forever', this job will be able to
          be recalled in subsequent FCP sessions. Other valid values are
          'reboot' and 'forever', as per FCP spec
        - Global - default false - if evaluates to true, puts this request
          on the global queue. Note the capital G in Global. If you set this,
          persistence must be 'reboot' or 'forever'
        - verbosity - default 0 - sets the Verbosity mask passed in the
          FCP message

    Returns:
        - the URI under which the freesite can be retrieved
    """
    log = self._log

    log(INFO, "putdir: uri=%s dir=%s" % (uri, kw['dir']))

    # -------------------------------------
    # format the command
    # 
    # note that with this primitive, we have to format the command
    # buffer ourselves, not just drop it through as a bunch of keywords,
    # since we want to control the order of keyword lines

    # get keyword args
    dir = kw['dir']
    sitename = kw.get('name', 'freesite')
    usk = kw.get('usk', False)
    version = kw.get('version', 0)
    maxretries = kw.get('maxretries', 3)
    priority = kw.get('priority', 1)
    filebyfile = kw.get('filebyfile', False)
    verbosity = kw.get('verbosity', 0)

    id = kw.pop("id", None)
    if not id:
        id = self._getUniqueId()

    # derive final URI for insert
    uriFull = uri + sitename + "/"
    if kw.get('usk', False):
        uriFull += "%d/" % int(version)
        uriFull = uriFull.replace("SSK@", "USK@")
        while uriFull.endswith("/"):
            uriFull = uriFull[:-1]
    
    # hack here - insert as ssk as toad suggests
    #parts = uriFull.replace("USK@", "SSK@").split("/")
    #uriFull = "/".join(parts[:-1]) + "-" + parts[-1]
    #log("putdir: toad hack: URI now is %s" % uriFull)

    # scan directory and add its files
    manifest = readdir(kw['dir'])
    
    manifestDict = {}
    jobs = []
    allAtOnce = False
    if filebyfile:
        # insert each file, one at a time
        for file in manifest:
            relpath = file['relpath']
            fullpath = file['fullpath']
            mimetype = file['mimetype']
            
            manifestDict[relpath] = file

            log(INFO, "Launching insert of %s" % relpath)

            raw = file(fullpath, "rb").read()
            job = self.put("CHK@",
                           data=raw,
                           mimetype=mimetype,
                           async=1,
                           verbosity=verbosity,
                           )
            jobs.append(job)
            file['job'] = job

            if not allAtOnce:
                job.wait()
                log(INFO, "Insert finished for %s" % relpath)

        # wait for jobs to complete
        if allAtOnce:
            log(INFO, "Waiting for raw file inserts to finish")
            while len([j for j in jobs if not j.isComplete()]) &gt; 0:
                time.sleep(1)
        
        # all done
        log(INFO, "All raw files now inserted (or failed)")

    # build a big command buffer
    msgLines = ["ClientPutComplexDir",
                "Identifier=%s" % id,
                "Verbosity=%s" % verbosity,
                "MaxRetries=%s" % maxretries,
                "PriorityClass=%s" % priority,
                "URI=%s" % uriFull,
                "Persistence=%s" % kw.get("persistence", "connection"),
                "DefaultName=index.html",
                ]

    if kw.get('Global', False):
        msgLines.append("Global=true")
    else:
        msgLines.append("Global=false")

    # add the files
    n = 0
    default = None
    for file in manifest:
        relpath = file['relpath']
        fullpath = file['fullpath']
        mimetype = file['mimetype']

        if filebyfile:
            if isinstance(file['job'].result, Exception):
                log(ERROR, "File %s failed to insert" % relpath)
                continue

        if relpath == 'index.html':
            default = file
        self._log(DETAIL, "n=%s relpath=%s" % (repr(n), repr(relpath)))

        msgLines.extend(["Files.%d.Name=%s" % (n, relpath),
                         ])
        if filebyfile:
            msgLines.extend(["Files.%d.UploadFrom=redirect" % n,
                             "Files.%d.TargetURI=%s" % (n, file['job'].result),
                            ])
        else:
            msgLines.extend(["Files.%d.UploadFrom=disk" % n,
                             "Files.%d.Filename=%s" % (n, fullpath),
                            ])
        n += 1

    # now, add the default file
    if 0:
        if filebyfile:
            msgLines.extend(["Files.%d.Name=" % n,
                             "Files.%d.UploadFrom=disk" % n,
                             "Files.%d.Filename=%s" % (n, default['fullpath']),
                             ])
        else:
            msgLines.extend(["Files.%d.Name=" % n,
                             "Files.%d.UploadFrom=redirect" % n,
                             "Files.%d.TargetURI=%s" % file['job'].result,
                             ])

    msgLines.append("EndMessage")
    
    for line in msgLines:
        self._log(DETAIL, line)
    fullbuf = "\n".join(msgLines) + "\n"

    # --------------------------------------
    # now dispatch the job
    return self._submitCmd(id, "ClientPutComplexDir",
                           rawcmd=fullbuf,
                           async=kw.get('async', False),
                           callback=kw.get('callback', False),
                           Persistence=kw.get('Persistence', 'connection'),
                           )

</t>
<t tx="aum.20060511003500">from fcp import *

n = FCPNode(host="thoth", verbosity=DETAIL)

pub, priv = n.genkey()

n.putdir(priv, name="fred", dir="/home/david/freenet/testdir", usk=True)

</t>
<t tx="aum.20060511101147">@first #! /usr/bin/env python
"""
A small freesite insertion/management utility
"""
@others
</t>
<t tx="aum.20060511103841">class JobTicket:
    """
    A JobTicket is an object returned to clients making
    asynchronous requests. It puts them in control of how
    they manage n concurrent requests.
    
    When you as a client receive a JobTicket, you can choose to:
        - block, awaiting completion of the job
        - poll the job for completion status
        - receive a callback upon completion

    Attributes of interest:
        - isPersistent - True if job is persistent
        - isGlobal - True if job is global
        - value - value returned upon completion, or None if not complete
        - node - the node this job belongs to
        - id - the job Identifier
        - cmd - the FCP message header word
        - kw - the keywords in the FCP header
        - msgs - any messages received from node in connection
          to this job
    """
    @others

</t>
<t tx="aum.20060511103841.1">def __init__(self, node, id, cmd, kw):
    """
    You should never instantiate a JobTicket object yourself
    """
    self.node = node
    self.id = id
    self.cmd = cmd

    # find out if persistent
    if kw.get("Persistent", "connection") != "connection" \
    or kw.get("PersistenceType", "connection") != "connection":
        self.isPersistent = True
    else:
        self.isPersistent = False

    if kw.get('Global', 'false') == 'true':
        self.isGlobal = True
    else:
        self.isGlobal = False

    self.kw = kw

    self.msgs = []

    callback = kw.pop('callback', None)
    if callback:
        self.callback = callback


    self.lock = threading.Lock()
    self.lock.acquire()
    self.result = None

    self.reqSentLock = threading.Lock()
    self.reqSentLock.acquire()

</t>
<t tx="aum.20060511103952">def isComplete(self):
    """
    Returns True if the job has been completed
    """
    return self.result != None

</t>
<t tx="aum.20060511103952.1">def wait(self, timeout=None):
    """
    Waits forever (or for a given timeout) for a job to complete
    """
    while not self.lock.acquire(False):
        time.sleep(0.1)
    self.lock.release()

    return self.getResult()
</t>
<t tx="aum.20060511113333"># standard lib imports
import sys, os, sha, traceback, getopt
from ConfigParser import SafeConfigParser

# fcp imports
import node
from node import FCPNode
from node import SILENT, FATAL, CRITICAL, ERROR, INFO, DETAIL, DEBUG

</t>
<t tx="aum.20060511113333.1">fcpHost = node.defaultFCPHost
fcpPort = node.defaultFCPPort
#verbosity = DETAIL
verbosity = None
logfile = None

</t>
<t tx="aum.20060511113333.3">def update(self):
    """
    Insert/update all registered freesites
    """
    noSites = True

    log = self._log

    kw = self.kw

    # get a node handle
    self.createNode(logfile=logfile, **kw)

    conf = self.config
    for sitename in conf.sections():

        # fill in any incomplete details with site entries
        needToSave = False
        if not conf.has_option(sitename, "hash"):
            needToSave = True
            conf.set(sitename, "hash", "")

        if not conf.has_option(sitename, "version"):
            needToSave = True
            conf.set(sitename, "version", "0")

        if not conf.has_option(sitename, "privatekey"):
            needToSave = True
            pub, priv = self.node.genkey()
            uri = pub.replace("SSK@", "USK@") + sitename + "/0"
            conf.set(sitename, "uri", uri)
            conf.set(sitename, "privatekey", priv)
        if needToSave:
            self.saveConfig()

        uri = conf.get(sitename, "uri")
        dir = conf.get(sitename, "dir")
        hash = conf.get(sitename, "hash")
        version = conf.get(sitename, "version")
        privatekey = conf.get(sitename, "privatekey")
        
        files = node.readdir(dir, gethashes=True)
        h = sha.new()
        for f in files:
            h.update(f['hash'])
        hashNew = h.hexdigest()
        if hashNew != hash:
            log(INFO, "Updating site %s" % sitename)
            log(INFO, "privatekey=%s" % privatekey)
            noSites = False
            try:
                res = self.node.put(privatekey,
                                    id="freesite:%s" % sitename,
                                    dir=dir,
                                    name=sitename,
                                    version=version,
                                    usk=True,
                                    verbosity=self.Verbosity,
                                    filebyfile=self.filebyfile)
                log(INFO, "site %s updated successfully" % sitename)
            except:
                traceback.print_exc()
                log(ERROR, "site %s failed to update" % sitename)
            conf.set(sitename, "hash", hashNew)
        else:
            log(INFO, "Site %s not changed, no need to update" % sitename)

    self.saveConfig()

    if noSites:
        log(INFO, "No sites needed updating")

</t>
<t tx="aum.20060511114439">class SiteMgr:
    """
    Manages insertion and updating of freesites
    """
    @others

</t>
<t tx="aum.20060511114439.1">def __init__(self, **kw):
    """
    Creates a site manager object.
    
    Arguments:

    Keywords:
        - configfile - pathname of where config file lives, defaults
          to ~/.freesites (or ~/freesites.ini on doze)
        - logfile - a pathname or open file object to which to write
          log messages, defaults to sys.stdout
        - verbosity - logging verbosity level, refer to fcp.node
        - fcphost - hostname of fcp, default fcp.node.defaultFCPHost
        - fcpport - port number of fcp, default fcp.node.defaultFCPPort
        - filebyfile - default False - if True, inserts files manually
          as chks, then builds a manifest full of redirects
    """
    # set up the logger
    logfile = kw.pop('logfile', sys.stderr)
    if not hasattr(logfile, 'write'):
        # might be a pathname
        if not isinstance(logfile, str):
            raise Exception("Bad logfile, must be pathname or file object")
        logfile = file(logfile, "a")
    self.logfile = logfile
    self.verbosity = kw.get('verbosity', 0)
    self.Verbosity = kw.get('Verbosity', 0)

    self.fcpHost = fcpHost
    self.fcpPort = fcpPort

    self.filebyfile = kw.get("filebyfile", False)

    self.kw = kw

    self.node = None

    # determine pathname for sites ini file
    configFile = kw.get('configfile', None)
    if configFile == None:
        isDoze = sys.platform.lower().startswith("win")
        homedir = os.path.expanduser("~")
        if isDoze:
            filename = "freesites.ini"
        else:
            filename = ".freesites"
        configFile = os.path.join(homedir, filename)

    self.configFile = configFile

    if os.path.isfile(configFile):
        self.loadConfig()
    else:
        self.config = SafeConfigParser()
        self.config.set("DEFAULT", "fcphost", self.fcpHost)
        self.config.set("DEFAULT", "fcpport", str(self.fcpPort))
</t>
<t tx="aum.20060511114439.2">def createConfig(self, **kw):
    """
    Creates a whole new config
    """
    #if not kw.has_key("fcpHost"):
    #    kw['fcpHost'] = node.defaultFCPHost
    #if not kw.has_key("fcpPort"):
    #    kw['fcpPort'] = node.defaultFCPPort

    #self.fcpHost = kw['fcpHost']
    #self.fcpPort = kw['fcpPort']

    file(self.configFile, "w").write("\n".join([
        "# config file for freesites",
        "# being inserted via pyfcp 'sitemgr' utility",
        "#",
        "# edit this file with care",
        "",
#        "# FCP access details",
#        "[DEFAULT]",
#        "fcpHost=%s" % self.fcpHost,
#        "fcpPort=%s" % self.fcpPort,
        "",
        "# for each new site, just copy the following two lines",
        "# to the end of this file, uncomment them, change as needed",
        "",
        "# [mysite]",
        "# dir=/path/to/mysite/directory",
        "",
        "",
        ]))

</t>
<t tx="aum.20060511114604">def loadConfig(self):
    """
    Loads the sites config file into self.config as a SafeConfigParser
    object
    """
    conf = self.config = SafeConfigParser()
    conf.read(self.configFile)

    try:
        self.fcpHost = conf.get("DEFAULT", "fcphost")
    except:
        conf.set("DEFAULT", "fcphost", self.fcpHost)
    try:
        self.fcpPort = conf.getint("DEFAULT", "fcpport")
    except:
        conf.set("DEFAULT", "fcpport", str(self.fcpPort))
    

    for sitename in conf.sections():

        if not conf.has_option(sitename, "dir"):
            raise Exception("Config file error: No directory specified for site '%s'" \
                            % sitename)

</t>
<t tx="aum.20060511114604.1">def saveConfig(self):
    """
    Saves the amended config file to disk
    """
    self.createConfig()

    self.config.set("DEFAULT", "fcphost", self.fcpHost)
    self.config.set("DEFAULT", "fcpport", str(self.fcpPort))

    f = file(self.configFile, "a")

    self.config.write(f)

    f.close()

</t>
<t tx="aum.20060511120024">if __name__ == '__main__':

    if '-h' in sys.argv:
        help()

    if '-v' in sys.argv:
        verbosity = node.DETAIL

    s = SiteMgr()
    s.update()
    s.shutdown()

</t>
<t tx="aum.20060511120059">def createNode(self, **kw):
    """
    Creates and saves a node object, if one not already present
    """
    if isinstance(self.node, FCPNode):
        return

    opts = {}

    if kw.has_key("fcpHost"):
        opts['host'] = kw['fcpHost']
    else:
        opts['host'] = self.fcpHost

    if kw.has_key("fcpPort"):
        opts['port'] = self.fcpPort
    else:
        opts['port'] = self.fcpPort

    if kw.has_key("verbosity"):
        opts['verbosity'] = kw['verbosity']
    else:
        opts['verbosity'] = node.INFO

    opts['Verbosity'] = self.Verbosity

    if kw.has_key("logfile"):
        opts['logfile'] = kw['logfile'] or sys.stdout
    else:
        opts['logfile'] = sys.stdout

    opts['name'] = 'freesitemgr'

    #print "createNode:"
    #print "  kw=%s"% kw
    #print "  opts=%s" % opts
    #sys.exit(0)
    
    self.node = FCPNode(**opts)

</t>
<t tx="aum.20060511130507">def help():

    print "%s: A console-based, cron-able freesite inserter" % sys.argv[0]
    print "Usage: %s" % sys.argv[0]

    print "This utility inserts/updates freesites, and is"
    print "driven by a simple config file."
    print
    print "The first time you run this utility, a config file"
    print "will be created for you in your home directory,"
    print "You will be told where this file is (~/.freesites on *nix"
    print "or ~/freesites.ini on doze)"
    print "then you can edit this file and add details of"
    print "your freesites, and run it again."
    print
    print "Note - freesites are only updated if they have"
    print "changed since the last update, because a hash"
    print "of each site gets stored in the config"

    sys.exit(0)

</t>
<t tx="aum.20060511205201">def shutdown(self):
    """
    Terminates the manager thread
    
    You should explicitly shutdown any existing nodes
    before exiting your client application
    """
    self.running = False

    # give the manager thread a chance to bail out
    time.sleep(pollTimeout * 3)

    # shut down FCP connection
    if hasattr(self, 'socket'):
        if not self.noCloseSocket:
            self.socket.close()
            del self.socket

    # and close the logfile
    if self.logfile not in [sys.stdout, sys.stderr]:
        self.logfile.close()

</t>
<t tx="aum.20060511205201.1">def _on_rxMsg(self, msg):
    """
    Handles incoming messages from node
    
    If an incoming message represents the termination of a command,
    the job ticket object will be notified accordingly
    """
    log = self._log

    # find the job this relates to
    id = msg.get('Identifier', '__global')

    hdr = msg['header']

    job = self.jobs.get(id, None)
    if not job:
        # we have a global job and/or persistent job from last connection
        log(INFO, "Got %s from prior session" % hdr)
        job = JobTicket(self, id, hdr, msg)
        self.jobs[id] = job

    # action from here depends on what kind of message we got

    # -----------------------------
    # handle GenerateSSK responses

    if hdr == 'SSKKeypair':
        # got requested keys back
        keys = (msg['RequestURI'], msg['InsertURI'])
        job.callback('successful', keys)
        job._putResult(keys)

        # and remove job from queue
        self.jobs.pop(id, None)
        return

    # -----------------------------
    # handle ClientGet responses

    if hdr == 'DataFound':
        log(INFO, "Got DataFound for URI=%s" % job.kw['URI'])
        mimetype = msg['Metadata.ContentType']
        if job.kw.has_key('Filename'):
            # already stored to disk, done
            #resp['file'] = file
            result = (mimetype, job.kw['Filename'])
            job.callback('successful', result)
            job._putResult(result)
            return

        elif job.kw['ReturnType'] == 'none':
            result = (mimetype, 1)
            job.callback('successful', result)
            job._putResult(result)
            return

        # otherwise, we're expecting an AllData and will react to it then
        else:
            # is this a persistent get?
            if job.kw['ReturnType'] == 'direct' \
            and job.kw.get('Persistence', None) != 'connection':
                # gotta poll for request status so we can get our data
                # FIXME: this is a hack, clean it up
                log(INFO, "Request was persistent")
                if not hasattr(job, "gotPersistentDataFound"):
                    if job.isGlobal:
                        isGlobal = "true"
                    else:
                        isGlobal = "false"
                    job.gotPersistentDataFound = True
                    log(INFO, "  --&gt; sending GetRequestStatus")
                    self._txMsg("GetRequestStatus",
                                Identifier=job.kw['Identifier'],
                                Persistence=msg.get("Persistence", "connection"),
                                Global=isGlobal,
                                )

            job.callback('pending', msg)
            job.mimetype = mimetype
            return

    if hdr == 'AllData':
        result = (job.mimetype, msg['Data'])
        job.callback('successful', result)
        job._putResult(result)
        return

    if hdr == 'GetFailed':
        # see if it's just a redirect problem
        if msg.get('ShortCodeDescription', None) == "New URI":
            uri = msg['RedirectURI']
            job.kw['URI'] = uri
            self._txMsg(job.cmd, **job.kw)
            log(DETAIL, "Redirect to %s" % uri)
            return

        # return an exception
        job.callback("failed", msg)
        job._putResult(FCPGetFailed(msg))
        return

    # -----------------------------
    # handle ClientPut responses

    if hdr == 'URIGenerated':

        job.uri = msg['URI']
        newUri = msg['URI']
        job.callback('pending', msg)

        return

        # bail here if no data coming back
        if job.kw.get('GetCHKOnly', False) == 'true':
            # done - only wanted a CHK
            job._putResult(newUri)
            return

    if hdr == 'PutSuccessful':
        result = msg['URI']
        job.callback('successful', result)
        job._putResult(result)
        return

    if hdr == 'PutFailed':
        job.callback('failed', msg)
        job._putResult(FCPPutFailed(msg))
        return

    # -----------------------------
    # handle progress messages

    if hdr == 'StartedCompression':
        job.callback('pending', msg)
        return

    if hdr == 'FinishedCompression':
        job.callback('pending', msg)
        return

    if hdr == 'SimpleProgress':
        job.callback('pending', msg)
        return

    # -----------------------------
    # handle persistent job messages

    if hdr == 'PersistentGet':
        job.callback('pending', msg)
        job._appendMsg(msg)
        return

    if hdr == 'PersistentPut':
        job.callback('pending', msg)
        job._appendMsg(msg)
        return

    if hdr == 'PersistentPutDir':
        job.callback('pending', msg)
        job._appendMsg(msg)
        return

    if hdr == 'EndListPersistentRequests':
        job._appendMsg(msg)
        job.callback('successful', job.msgs)
        job._putResult(job.msgs)
        return

    # -----------------------------
    # handle various errors

    if hdr == 'ProtocolError':
        job.callback('failed', msg)
        job._putResult(FCPProtocolError(msg))
        return

    if hdr == 'IdentifierCollision':
        log(ERROR, "IdentifierCollision on id %s ???" % id)
        job.callback('failed', msg)
        job._putResult(Exception("Duplicate job identifier %s" % id))
        return

    # -----------------------------
    # wtf is happening here?!?

    log(ERROR, "Unknown message type from node: %s" % hdr)
    job.callback('failed', msg)
    job._putResult(FCPException(msg))
    return
</t>
<t tx="aum.20060511205201.2">def _on_clientReq(self, job):
    """
    takes an incoming request job from client and transmits it to
    the fcp port, and also registers it so the manager thread
    can action responses from the fcp port.
    """
    id = job.id
    cmd = job.cmd
    kw = job.kw

    # register the req
    if cmd != 'WatchGlobal':
        self.jobs[id] = job
    
    # now can send, since we're the only one who will
    self._txMsg(cmd, **kw)

    job.reqSentLock.release()

</t>
<t tx="aum.20060511222538">def _msgIncoming(self):
    """
    Returns True if a message is coming in from the node
    """
    return len(select.select([self.socket], [], [], pollTimeout)[0]) &gt; 0

</t>
<t tx="aum.20060512101715">def _submitCmd(self, id, cmd, **kw):
    """
    Submits a command for execution
    
    Arguments:
        - id - the command identifier
        - cmd - the command name, such as 'ClientPut'
    
    Keywords:
        - async - whether to return a JobTicket object, rather than
          the command result
        - callback - a function taking 2 args 'status' and 'value'.
          Status is one of 'successful', 'pending' or 'failed'.
          value is the primitive return value if successful, or the raw
          node message if pending or failed
        - rawcmd - a raw command buffer to send directly
        - options specific to command such as 'URI'
    
    Returns:
        - if command is sent in sync mode, returns the result
        - if command is sent in async mode, returns a JobTicket
          object which the client can poll or block on later
    """
    async = kw.pop('async', False)
    job = JobTicket(self, id, cmd, kw)
    
    if cmd == 'ClientGet':
        job.uri = kw['URI']

    if cmd == 'ClientPut':
        job.mimetype = kw['Metadata.ContentType']

    self.clientReqQueue.put(job)

    self._log(DEBUG, "_submitCmd: id=%s cmd=%s kw=%s" % (id, cmd, str(kw)[:256]))

    if cmd == 'WatchGlobal':
        return
    elif async:
        return job
    else:
        self._log(DETAIL, "Waiting on job")
        return job.wait()

</t>
<t tx="aum.20060512102840">def _putResult(self, result):
    """
    Called by manager thread to indicate job is complete,
    and submit a result to be picked up by client
    """
    self.result = result

    if not self.isPersistent:
        try:
            del self.node.jobs[self.id]
        except:
            pass

    self.lock.release()

</t>
<t tx="aum.20060512140230">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060512150118">def __del__(self):

    try:
        if hasattr(self, 'node'):
            self.node.shutdown()
        del self.node
        self.node = None
    except:
        pass

</t>
<t tx="aum.20060512152233">@first #! /usr/bin/env python

import time

import fcp

n = fcp.FCPNode(host="thoth", verbosity=fcp.ERROR)
pub, priv = n.genkey()
print pub
print priv

n.shutdown()

#del n
#time.sleep(3)
#print "done"

</t>
<t tx="aum.20060512172707">@first #! /usr/bin/env python
"""
fcpxmlrpc.py

Exposes some pyfcp primitives over an XML-RPC service
"""

@others
</t>
<t tx="aum.20060512172843"># standard library imports
import sys
from SimpleXMLRPCServer import SimpleXMLRPCServer
from SocketServer import ThreadingMixIn

# FCP imports
import node

</t>
<t tx="aum.20060512173027"># where to listen, for the xml-rpc server
xmlrpcHost = "127.0.0.1"
xmlrpcPort = 19481

</t>
<t tx="aum.20060512175041">class FCPXMLRPCServer(ThreadingMixIn, SimpleXMLRPCServer):
    """
    Multi-threaded XML-RPC server for freenet FCP access
    """
    @others

</t>
<t tx="aum.20060512175041.1">def __init__(self, **kw):
    """
    Creates the xml-rpc server

    Keywords:
        - host - hostname to listen on for xml-rpc requests, default 127.0.0.1
        - port - port  to listen on for xml-rpc requests, default 19481
        - fcpHost - hostname where FCP port is
        - fcpPort - port where FCP port is
        - verbosity - verbosity of output messages, 0 (silent) through 6 (noisy),
          default 4. Refer verbosity constants in fcp module
    """
    # create the server
    host = kw.get('host', xmlrpcHost)
    port = kw.get('port', xmlrpcPort)

    SimpleXMLRPCServer.__init__(self, (host, port))

    # create the fcp node interface
    fcpHost = kw.get('fcpHost', node.defaultFCPHost)
    fcpPort = kw.get('fcpPort', node.defaultFCPPort)
    verbosity = kw.get('verbosity', node.SILENT)

    self.node = node.FCPNode(host=fcpHost,
                             port=fcpPort,
                             verbosity=verbosity,
                             )

    # create the request handler
    hdlr = FreenetXMLRPCRequestHandler(self.node)

    # link in the request handler object
    self.register_instance(hdlr)
    self.register_introspection_functions()

</t>
<t tx="aum.20060512175218">def run(self):
    """
    Launch the server to run forever
    """
    try:
        self.serve_forever()
    except KeyboardInterrupt:
        self.node.shutdown()
        raise

</t>
<t tx="aum.20060512181209">def callback(self, status, value):
    """
    This will be replaced in job ticket instances wherever
    user provides callback arguments
    """
    # no action needed

</t>
<t tx="aum.20060513071956">def shutdown(self):
    self.node.shutdown()

</t>
<t tx="aum.20060513073239">@path fcp
</t>
<t tx="aum.20060513073239.1"></t>
<t tx="aum.20060513073239.2">freesitemgr is a simple console-based
app which inserts and maintains freesites
</t>
<t tx="aum.20060513073239.3">@first #!/bin/bash

# a wrapper which starts the freenet node,
# and is used with the cron'ed freesite insertion
# scripts

# change this to where your bash startup script lives
source /home/david/.bashrc

# change this to where your freenet is installed
cd /home/david/freenet

# now start the freenet node
./run.sh start

</t>
<t tx="aum.20060513073239.4">@first #!/bin/bash

# a wrapper which starts the freenet node,
# and is used with the cron'ed freesite insertion
# scripts

# change this to where your bash startup script lives
source /home/david/.bashrc

# change this to where your freenet is installed
cd /home/david/freenet

# now stop the freenet node
./run.sh stop

</t>
<t tx="aum.20060513073239.5"></t>
<t tx="aum.20060513073239.6"></t>
<t tx="aum.20060513180215"></t>
<t tx="aum.20060513180215.1">@nocolor
README file for PyFCP

PyFCP is a Python client library for Freenet FCP that aims
to be easy to use, yet flexible enough to accomodate a wide range
of programming mind-sets.

This PyFCP release includes:

 - python package 'fcp', containing:
    - 'node' - core FCP node interface
    - 'sitemgr' - freesite management class
    - 'xmlrpc' - freenet XML-RPC server

 - various command-line client apps, which will get installed as
   executable commands in your PATH, including:
     - freesitemgr - a simple yet flexible freesite management utility
     - fcpget - a single key fetcher
     - fcpput - a single key inserter
     - fcpgenkey - a keypair generator

To get good API documentation, run:

    $ epydoc -n "PyFCP API manual" -o html fcp

When you install this package (refer INSTALL), you should 
end up with a command 'freesitemgr' on your PATH.

'freesitemgr' is a console-based freesite insertion utility
which keeps your freesite configs and status in a single
config file (~/.freesites, unless you specify otherwise).

Invoke 'freesitemgr -h' (or if on windows, 'freesitemgr.py -h')
and read the options.

</t>
<t tx="aum.20060513180716">@nocolor
INSTALL file for PyFCP

System requirements:

   This package requires:
     - Python2.3 or later
     - access to a freenet FCP port, on same or other machine
     - third party module 'SSLCrypto' (source included here)

Installation:

   1) Test if SSLCrypto is installed

      If you already have the Python 'SSLCrypto' package installed,
      you can skip to step 3.

      You can test if SSLCrypto is installed by typing:

        $ python -c "import SSLCrypto"

      If the command completes quietly, then SSLCrypto is installed
      and working. Otherwise, if you see something like 'ImportError:...',
      you need to install SSLCrypto.

   2) Install SSLCrypto if needed

      (i)   go in to the 'dependencies' directory
      (ii)  unpack both the 'Pyrex...' and the 'SSLCrypto...' tarballs
      (iii) cd into the 'Pyrex-...' directory, become root, then type:

               python setup.py install

      (iv)  cd into the 'SSLCrypto...' directory, become root, then type:

               python setup.py install

   3) Now, you should be able to install pyfcp and its applications.
      To do this, get back into the toplevel pyfcp directory, then
      become root, then type 'python setup.py install'

</t>
<t tx="aum.20060513180932">@nocolor
The PyFCP modules and scripts were written
by David McNab (aum) in May, 2006.

Contact the author at:
  david@freenet.org.nz

</t>
<t tx="aum.20060513181137">@nocolor

The PyFCP files are released under the
GNU Lesser General Public License (LGPL).

A copy of this license document is available from:
  http://www.gnu.org

No warranty is given or even implied, as to the
safety, security, reliability or functionality
of this software.

You are free to use, copy, modify and distribute
this software within the terms of the LGPL license.

</t>
<t tx="aum.20060513181205">@nocolor

Bugs:
 - no support for persistent operations
 - probably heaps of other bugs

</t>
<t tx="aum.20060513181313">@nocolor

Revision history for PyFCP

- Version 0.1.5

    - added global queue and persistence support for fcpget/fcpput
    - added 'nowait' option to fcpput

- Version 0.1.4

    - added manpages for console programs
    - improved mimetype determination algorithm for fcp put
    - added 'freedisk', a rudimentary linux filesystem that maps freenet
      into a mountable fs - limited functionality at present
    - added support for use of env vars FCP_HOST and FCP_PORT for specifying
      FCP host/port - useful for people who access FCP across a LAN, since
      it avoids annoyance of having to specify -H or -P with each command

- Version 0.1.3

    - added 'fcpget' and 'fcpput' command-line key retrieve/insert apps
    - added 'freesitemgr' command-line freesite insertion app
    - several bug fixes

- Version 0.1.2

    - added xmlrpc server app
    - added xmlrpc server CGI module (for embedding a Freenet XML-RPC
      server into websites)
    - added 'freesitemgr', a console freesite insertion app

- Version 0.1.1
    - 2006-May-13
        - First packaged release

</t>
<t tx="aum.20060513182312">@first #!/usr/bin/env python

import sys, os, commands

version = "0.1.5"

releaseDir = "pyfcp-%s" % version
tarball = releaseDir + ".tar.gz"

freesiteDir = "/thoth/home/david/freenet/mysites/pyfcp"

thothTestDir = "/thoth/home/david/freenet/pyfcp"

file("release.log", "w").close()

def sh(cmd):
    f = file("release.log", "a")
    f.write("Executing:\n  %s\n" % cmd)
    s = commands.getoutput(cmd)
    f.write(s)
    f.close()

files = [
    "AUTHORS", "README", "INSTALL", "COPYING", "BUGS", "CHANGELOG",
    "setup.py",
    "fcp",
    "dependencies",
    "freesitemgr", "freesitemgr.py",
    "tutorial.py",
    "fcpxmlrpc.cgi",
    "fcpget.py", "fcpget",
    "fcpput.py", "fcpput",
    "fcpgenkey.py", "fcpgenkey",
    "manpages",
    "freedisk.py", "freedisk", "freedisk.conf",
    "html",
    ]

print "Creating release directory..."
sh("rm -rf %s" % releaseDir)
os.mkdir(releaseDir)

print "Generate doco..."
#sh("rm -rf html/*")
sh("epydoc -n \"PyFCP API Manual\" -o html fcp")

print "Copying release files..."
sh("cp -r %s %s" % (" ".join(files), releaseDir))

print "Creating tarball..."
sh("tar cfz %s %s" % (tarball, releaseDir))

print "Releasing tarball to freesite..."
sh("cp -r %s %s" % (tarball, freesiteDir))

print "Copying release files to thoth test dir..."
sh("rm -rf %s/*" % thothTestDir)
sh("cp -r %s/* %s" % (releaseDir, thothTestDir))

</t>
<t tx="aum.20060514124642">def refreshPersistentRequests(self, **kw):
    """
    Sends a ListPersistentRequests to node, to ensure that
    our records of persistent requests are up to date.
    
    Since, upon connection, the node sends us a list of all
    outstanding persistent requests anyway, I can't really
    see much use for this method. I've only added the method
    for FCP spec compliance
    """
    self._log(INFO, "listPersistentRequests")

    if self.jobs.has_key('__global'):
        raise Exception("An existing non-identifier job is currently pending")

    # ---------------------------------
    # format the request
    opts = {}

    id = '__global'
    opts['Identifier'] = id

    opts['async'] = kw.pop('async', False)
    if kw.has_key('callback'):
        opts['callback'] = kw['callback']

    # ---------------------------------
    # now enqueue the request
    return self._submitCmd(id, "ListPersistentRequests", **opts)

</t>
<t tx="aum.20060514124934">def _appendMsg(self, msg):
    self.msgs.append(msg)

</t>
<t tx="aum.20060514132715">import sys, os, time, commands, traceback, getopt

import fcp.node
from fcp.sitemgr import SiteMgr

</t>
<t tx="aum.20060514132715.1">progname = sys.argv[0]

# time we wait after starting fred, to allow the node to 'warm up'
# and make connections to its peers
startupTime = 180

# directory where we have freenet installed,
# change it as needed
#freenetDir = "/home/david/freenet"

homeDir = os.path.expanduser("~")

# derive path of freenet pid file, the (non)existence
# of which is the easiest test of whether the freenet
# node is running
#freenetPidFile = os.path.join(freenetDir, "Freenet.pid")

logFile = os.path.join(homeDir, "updatesites.log")
pidFile = os.path.join(homeDir, "updatesites.pid")

if sys.platform.startswith("win"):
    confFileName = "freesites.ini"
else:
    confFileName = ".freesites"
confFile = os.path.join(homeDir, confFileName)

</t>
<t tx="aum.20060514132715.2"># small wrapper which, if freenet isn't already running,
# starts it prior to inserting then stops it after
# inserting
def main_old(verbose=None):

    os.chdir(freenetDir)

    if verbose == None:
        verbose = ('-v' in sys.argv)

    if os.path.isfile(pidFile):
        print "updatesites.py already running: pid=%s" % file(pidFile).read()
        sys.exit(1)
    f = file(pidFile, "w")
    f.write(str(os.getpid()))
    f.close()

    #logfile = file(logFile, "w")
    logfile = sys.stdout

    logfile.write("----------------------\n")
    logfile.write(time.asctime() + "\n")

    try:
        print "--------------------------------------------"
        print "Start of site updating run"
        print "Status being logged to file %s" % logFile
        
        # start freenet and let it warm up, if it's not already running
        if not os.path.isfile(freenetPidFile):
            startingFreenet = True
            os.chdir(freenetDir)
            print "Starting freenet..."
            print os.system("%s/start.sh &amp;" % freenetDir)
            print "Letting node settle for %s seconds..." % startupTime
            time.sleep(startupTime)
        else:
            print "Freenet node is already running!"
            startingFreenet = False
    
        # add verbosity argument if needed    
        if verbose:
            kw = {"verbosity" : fcp.DETAIL}
            kw['Verbosity'] = 65535
        else:
            kw = {"verbosity" : fcp.INFO}
    
        # get a site manager object, and perform the actual insertions
        print "Creating SiteMgr object"
        s = fcp.sitemgr.SiteMgr(logfile=logfile, **kw)
        print "Starting updates"
        try:
            s.update()
        except:
            traceback.print_exc()
        print "Updates done"
        del s
        
        # kill freenet if it was dynamically started
        if startingFreenet:
            print "Waiting %s for inserts to finish..." % startupTime
            time.sleep(startupTime)
            print "Stopping node..."
            os.system("./run.sh stop")
            print "Node stopped"
        else:
            print "Not killing freenet - it was already running"
    except:
        traceback.print_exc()
        pass

    # can now drop our pidfile
    os.unlink(pidFile)

</t>
<t tx="aum.20060514132715.3">if __name__ == '__main__':
    main()

</t>
<t tx="aum.20060514134235">def getResult(self):
    """
    Returns result of job, or None if job still not complete

    If result is an exception object, then raises it
    """
    if isinstance(self.result, Exception):
        raise self.result
    else:
        return self.result

</t>
<t tx="aum.20060514162944">def cancel(self):
    """
    Cancels the job, if it is persistent
    
    Does nothing if the job was not persistent
    """
    if not self.isPersistent:
        return

    # remove from node's jobs lists
    try:
        del self.node.jobs[self.id]
    except:
        pass
    
    # send the cancel
    if self.isGlobal:
        isGlobal = "true"
    else:
        isGlobal = "False"

    self.node._txMsg("RemovePersistentRequest",
                     Global=isGlobal,
                     Identifier=self.id)

</t>
<t tx="aum.20060514164052">def __repr__(self):
    if self.kw.has_key("URI"):
        uri = " URI=%s" % self.kw['URI']
    else:
        uri = ""
    return "&lt;FCP job %s:%s%s" % (self.id, self.cmd, uri)

</t>
<t tx="aum.20060514191601">def setVerbosity(self, verbosity):
    """
    Sets the verbosity for future logging calls
    """
    self.verbosity = verbosity

</t>
<t tx="aum.20060514223716"># basic FCP primitives

@others

</t>
<t tx="aum.20060514223822">def getPersistentJobs(self):
    """
    Returns a list of persistent jobs, excluding global jobs
    """
    return [j for j in self.jobs.values() if j.isPersistent and not j.isGlobal]

</t>
<t tx="aum.20060514223845">def getGlobalJobs(self):
    """
    Returns a list of global jobs
    """
    return [j for j in self.jobs.values() if j.isGlobal]

</t>
<t tx="aum.20060514223936">def getAllJobs(self):
    """
    Returns a list of persistent jobs, excluding global jobs
    """
    return self.jobs.values()

</t>
<t tx="aum.20060514224020">def getTransientJobs(self):
    """
    Returns a list of non-persistent, non-global jobs
    """
    return [j for j in self.jobs.values() if not j.isPersistent]

</t>
<t tx="aum.20060514224855">def listenGlobal(self, **kw):
    """
    Enable listening on global queue
    """
    self._submitCmd(None, "WatchGlobal", Enabled="true", **kw)

</t>
<t tx="aum.20060514224919">def ignoreGlobal(self, **kw):
    """
    Stop listening on global queue
    """
    self._submitCmd(None, "WatchGlobal", Enabled="false", **kw)

</t>
<t tx="aum.20060514225725">def purgePersistentJobs(self):
    """
    Cancels all persistent jobs in one go
    """
    for job in self.getPersistentJobs():
        job.cancel()

</t>
<t tx="aum.20060514232355"></t>
<t tx="aum.20060514232355.1">@first #! /usr/bin/env python

import sys, os

# ------------------------------------------
# This is a tutorial introduction to PyFCP,
# arranged as comments and code interspersed
# in a python script
# 
# read through this carefully, and learn
# ------------------------------------------


# ------------------------------------------
# first things first - import fcp module

import fcp

# ------------------------------------------
# state where our FCP port is

fcpHost = "127.0.0.1"


# ------------------------------------------
# create a node connection object
# 
# we're setting a relatively high verbosity so you
# can see the traffic

node = fcp.FCPNode(host=fcpHost, verbosity=fcp.DETAIL)


# -----------------------------------------------
# now, perform a simple direct insert of a string

val = raw_input("Please enter a string to insert: ")
ksk = raw_input("Please enter a short KSK key name: ")

uri = "KSK@" + ksk
print "Inserting %s, containing '%s'" % (uri, val)

# do the put - note that 'data=' inserts a string directly
# note too that mimetype is optional, defaulting to text/plain
node.put("KSK@"+ksk, data=val, mimetype="text/plain")

print "insert completed successfully"

# ------------------------------------------
# now, retrieve it back

print "trying to retrieve our value back"
mimetype, val1 = node.get(uri)

# ensure it's correct
if val == val1:
    print "retrieved ok, values match"
else:
    print "huh? values don't match"

# ------------------------------------------
# now, insert from a file

val = raw_input("Please enter a string to insert: ")
ksk = raw_input("Please enter a short KSK key name: ")
path = raw_input("Enter a temporary filename: ")

# write our string to a file
f = file(path, "w")
f.write(val)
f.close()

uri = "KSK@" + ksk
print "Inserting %s, from file '%s'" % (uri, path)

# do the put - note that 'file=' inserts from a filename or file object
node.put("KSK@"+ksk, file=path)

# ------------------------------------------
# now, demonstrate asynchronous requests

print "Launching asynchronous request"
job = node.get(uri, async=True)

# we can poll the job
if job.isComplete():
    print "Yay! job complete"
else:
    # or we can await its completion
    result = job.wait()

print "Result='%s'" % str(result)

# ------------------------------------------
# similarly, we can get to a file

path = raw_input("temporary file to retrieve to: ")
node.get(path, file=path)

# again, the 'file=' can be a pathname or an open file object

# ------------------------------------------
# TODO: demonstrate persistent requests

# ------------------------------------------
# TODO: demonstrate global requests

</t>
<t tx="aum.20060515193950">"""
distutils installation script for pyfcp
"""
import sys, os

# barf if prerequisite module 'SSLCrypto' is not installed
try:
    sys.stdout.write("Testing if SSLCrypto module is installed...")
    sys.stdout.flush()
    import SSLCrypto
    print "ok!"
except:
    print "failed!"
    print
    print "You have not installed the SSLCrypto module"
    print "Please refer to the INSTALL file in this directory"
    print "and follow the instructions"
    print
    print "You can continue with this installation, but you will"
    print "not have the protection of encrypted config files."
    resp = raw_input("Continue installation anyway? [Y/n] ")
    resp = resp.strip().lower() or "y"
    resp = resp[0]
    if resp == 'n':
        print "Installation aborted"
        sys.exit(1)
    else:
        print "Installing without encryption"

# barf if user is not running this script as root
if (os.getuid() != 0) and not sys.platform.lower().startswith("win"):
    print "You must be root to do this installation"
    sys.exit(1)


if sys.platform.lower().startswith("win"):
    freesitemgrScript = "freesitemgr.py"
    fcpgetScript = "fcpget.py"
    fcpputScript = "fcpput.py"
    fcpgenkeyScript = "fcpgenkey.py"
    freediskScript = "freedisk.py"
else:
    freesitemgrScript = "freesitemgr"
    fcpgetScript = "fcpget"
    fcpputScript = "fcpput"
    fcpgenkeyScript = "fcpgenkey"
    freediskScript = "freedisk"

from distutils.core import setup
setup(name="PyFCP",
      version="0.1",
      description="Freenet FCP access freesite management and XML-RPC modules",
      author="David McNab",
      author_email="david@freenet.org.nz",
       url ="http://127.0.0.1:8888/USK@yhAqcwNdN1y1eyRQQwZfhu4dpn-tPNlZMeNRZxEg1bM,zBUodpjtZdJvzWmwYKgr8jO5V-yKxZvetsr8tADNg2U,AQABAAE/pyfcp/0",

      packages = ['fcp'],
      scripts = [freesitemgrScript, fcpgetScript, fcpputScript,
                 fcpgenkeyScript, freediskScript,
                 ],


#      py_modules=["fcp", "fcpxmlrpc", "fcpsitemgr"]

    )

</t>
<t tx="aum.20060515195621">@first #! /usr/bin/env python

# CGI-based XML-RPC interface to FCP
# You can use this on your FCP server


@others

import fcpxmlrpc

</t>
<t tx="aum.20060515195621.1"># hostname and port of FCP interface
fcpHost = "10.0.0.1"
fcpPort = 9481

# verbosity for logging
verbosity = node.DETAIL

# where the logfile is
logfile = "/tmp/fcpxmlrpc.log"

</t>
<t tx="aum.20060515195621.2">from SimpleXMLRPCServer import CGIXMLRPCRequestHandler

import fcp
from fcp.xmlrpc import FreenetXMLRPCRequestHandler

</t>
<t tx="aum.20060515195621.3">def main():

    # create the fcp node interface
    node = fcp.FCPNode(host=fcpHost,
                                 port=fcpPort,
                                 verbosity=verbosity,
                                 logfile=logfile,
                                 )

    # create the request handler
    hdlr = FreenetXMLRPCRequestHandler(node)

    # create the handler
    handler = CGIXMLRPCRequestHandler()
    handler.register_introspection_functions()

    # link in the node wrapper
    handler.register_instance(hdlr)

    # now do the business
    handler.handle_request()

    node.shutdown()

</t>
<t tx="aum.20060515200029">if __name__ == '__main__':
    main()

</t>
<t tx="aum.20060516115529">@nocolor

* convert everything to a package 'fcp'

    * create __init__.py, add __all__

* stick a main() with getopt() into fcp.sitemgr

    * options:
        -c - create initial ~/.freesites, prompt to overwrite, prompt for:
            - fcp host/port

        -a - add a freesite
        -u - update one or all freesites
        -l - list freesites
        -d - delete a freesite
        -h - help

    * no options - ask to run with -h

* add a script which runs fcp.sitemgr

* add a script which runs xmlrpc server

* update setup.py

</t>
<t tx="aum.20060516141235">from node import FCPNode, JobTicket
from node import ConnectionRefused, FCPException, FCPGetFailed, \
                 FCPPutFailed, FCPProtocolError

from node import SILENT, FATAL, CRITICAL, ERROR, INFO, DETAIL, DEBUG

import freenetfs

__all__ = ['node', 'sitemgr', 'xmlrpc', 'freenetfs',
           'FCPNode', 'JobTicket',
           'ConnectionRefused', 'FCPException', 'FCPPutFailed',
           'FCPProtocolError',
           ]


</t>
<t tx="aum.20060516142202">def run():
    """
    Runs the sitemgr in a console environment
    """
    import getopt

    opts = {'verbosity': node.INFO,
            'host':xmlrpcHost,
            'port':xmlrpcPort,
            'fcpHost':node.defaultFCPHost,
            'fcpPort':node.defaultFCPPort,
            }

    try:
        cmdopts, args = getopt.getopt(sys.argv[1:],
                                   "?hv:",
                                   ["help", "verbosity=", "host=", "port=",
                                    "fcphost=", "fcpport="])
    except getopt.GetoptError:
        # print help information and exit:
        usage()
        sys.exit(2)
    output = None
    verbose = False
    #print cmdopts
    for o, a in cmdopts:
        if o in ("-h", "--help"):
            usage(ret=0)
        elif o == "--host":
            opts['host'] = a
        elif o == "--port":
            opts['port'] = int(a)

</t>
<t tx="aum.20060516143534"></t>
<t tx="aum.20060516143534.1">def help():
    """
    dump help info and exit
    """
    print "%s: a console-based freesite insertion utility" % progname
    
    print "Usage: %s [options] &lt;command&gt; &lt;args&gt;" % progname
    print "Options:"
    print "  -h, --help"
    print "          - display this help message"
    print "  -f, --file=filename"
    print "          - use a different config file (default is %s)" % confFile
    print "  -v, --verbose"
    print "          - run verbosely"
    print "  -q, --quiet"
    print "          - run quietly"
    print "  -l, --logfile=filename"
    print "          - location of logfile (default %s)" % logFile
    print "  -s, --single-files"
    print "          - insert one file at a time as CHKs, then insert"
    print "            a manifest which redirects to these, useful"
    print "            for debugging. Also, you MUST use this mode if"
    print "            inserting a freesite from across a LAN (ie, if"
    print "            the FCP service is on a different machine to"
    print "            the machine running freesitemgr"
    print
    print "Available Commands:"
    print "  setup          - create/edit freesite config file interactively"
    print "  add            - add new freesite called &lt;name&gt; using directory &lt;dir&gt;"
    print "  list [&lt;name&gt;]  - display a summary of all freesites, or a"
    print "                   detailed report of one site if &lt;name&gt; given"
    print "  remove &lt;name&gt;  - remove given freesite"
    print "  update         - reinsert any freesites which have changed since"
    print "                   they were last inserted"

</t>
<t tx="aum.20060516143534.2">def main():

    # default job options
    opts = {
            "configfile" : confFile,
            "verbosity" : fcp.node.INFO,
            "logfile" : logFile,
            "filebyfile" : False,
            }

    # process command line switches
    try:
        cmdopts, args = getopt.getopt(
            sys.argv[1:],
            "?hvf:l:s",
            ["help", "verbose", "file=", "logfile=", "single-files",
             ]
            )
    except getopt.GetoptError:
        # print help information and exit:
        usage()
        sys.exit(2)
    output = None
    verbose = False
    #print cmdopts
    for o, a in cmdopts:

        if o in ("-?", "-h", "--help"):
            help()
            sys.exit(0)

        if o in ("-v", "--verbosity"):
            opts['verbosity'] = fcp.node.DETAIL
            opts['Verbosity'] = 1023
        
        if o in ("-q", "--quiet"):
            opts['verbosity'] = fcp.node.SILENT
        
        if o in ("-f", "--file"):
            opts['configfile'] = a
        
        if o in ("-l", "--logfile"):
            opts['logfile'] = a
        
        if o in ("-s", "--single-files"):
            opts['filebyfile'] = True

    # process command
    if len(args) &lt; 1:
        usage(msg="No command given")

    cmd = args.pop(0)

    if cmd not in ['setup','add','remove','list','update']:    
        usage(msg="Unrecognised command '%s'" % cmd)

    # we now have a likely valid command, so now we need a sitemgr
    sitemgr = SiteMgr(**opts)

    if cmd == 'setup':
        editCreateConfig(sitemgr)

    elif cmd == 'add':
        addSite(sitemgr)

    elif cmd == 'remove':
        if not args:
            print "Remove site: no freesites selected"
            return
        for sitename in args:
            removeSite(sitemgr, sitename)
        pass
        print "Removed freesites: " + " ".join(args)
        return

    elif cmd == 'list':
        if not args:
            # summary list
            print " ".join(sitemgr.getSiteNames())
        else:
            for sitename in args:
                if not sitemgr.hasSite(sitename):
                    print "No such site '%s'" % sitename
                else:
                    info = sitemgr.getSiteInfo(sitename)
                    print "%s:" % sitename
                    print "    dir: %s" % info['dir']
                    print "    uri: %s" % info['uri']
                    print "    privkey: %s" % info['privatekey']
                    print "    version: %s" % info['version']
                    
            pass
        return

    elif cmd == 'update':
        sitemgr.update()
        pass

</t>
<t tx="aum.20060516144850">def usage(ret=-1, msg=None):
    if msg != None:
        print msg
    print "Usage: %s [options] &lt;command&gt; [&lt;arguments&gt;]" % progname
    print "Do '%s -h' for help" % progname

    sys.exit(ret)

</t>
<t tx="aum.20060516145032">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060516145032.1">"""
A utility to update freesites from within a cron environment
"""
@others
</t>
<t tx="aum.20060516150511">def editCreateConfig(sitemgr):
    """
    Creates an initial config file interactively
    """
    print "Setting up configuration file %s" % sitemgr.configFile

    # get fcp hostname
    fcpHost = raw_input("FCP Hostname [%s] (* for all): " % sitemgr.fcpHost).strip()
    if not fcpHost:
        fcpHost = sitemgr.fcpHost
    if fcpHost == '*':
        fcpHost = ""
    
    # get fcp port
    while 1:
        fcpPort = raw_input("FCP Port [%s]: " % sitemgr.fcpPort).strip()
        if not fcpPort:
            fcpPort = sitemgr.fcpPort
        try:
            fcpPort = int(fcpPort)
        except:
            continue
        break

    print "Trying FCP port at %s:%s" % (fcpHost, fcpPort)
    try:
        fcpnode = fcp.FCPNode(host=fcpHost, port=fcpPort)
    except Exception, e:
        print "Failed to connect to FCP Port: %s" % e
        print "Setup aborted"
        return
    fcpnode.shutdown()

    sitemgr.fcpHost = fcpHost
    sitemgr.fcpPort = fcpPort

    # confirm and save
    if getyesno("Save configuration", True):
        sitemgr.saveConfig()

    print "Configuration saved to %s" % sitemgr.configFile

</t>
<t tx="aum.20060516153119">def getyesno(ques, default=False):
    """
    prompt for yes/no answer, with default
    """
    if default:
        prmt = "[Y/n]"
    else:
        prmt = "[y/N]"
        
    resp = raw_input(ques + " " + prmt + " ").strip().lower()
    
    if not resp:
        return default
    elif resp[0] in ['y', 't']:
        return True
    else:
        return False
</t>
<t tx="aum.20060516184736">def hasSite(self, sitename):
    """
    returns True if site is known in this config
    """
    return self.config.has_section(sitename)

</t>
<t tx="aum.20060516184736.1">def addSite(sitemgr):
    """
    Interactively adds a new site to config
    """
    print "Add new site"

    while 1:
        sitename = raw_input("Name of freesite, or empty line to cancel: ").strip()
        if not sitename:
            print "Add site aborted"
            return
        elif sitemgr.hasSite(sitename):
            print "Freesite '%s' already exists" % sitename
            continue
        break

    while 1:
        sitedir = raw_input("Directory where freesite's files reside: ").strip()
        if not sitedir:
            print "Add site aborted"
            return
        sitedir = os.path.abspath(sitedir)
        if not os.path.isdir(sitedir):
            print "'%s' is not a directory, try again" % sitedir
            continue
        elif not os.path.isfile(os.path.join(sitedir, "index.html")):
            print "'%s' has no index.html, try again" % sitedir
            continue
        break
    
    # good to go - add the site
    sitemgr.addSite(sitename, sitedir)

    print "Added new freesite: '%s' =&gt; %s" % (sitename, sitedir)

</t>
<t tx="aum.20060516192715">def addSite(self, sitename, sitedir):
    
    if self.hasSite(sitename):
        raise Exception("Site %s already exists" % sitename)

    conf = self.config
    conf.add_section(sitename)
    conf.set(sitename, "dir", sitedir)
    
    self.saveConfig()

</t>
<t tx="aum.20060516193650">def removeSite(sitemgr, sitename):
    """
    tries to remove site from config
    """
    if not sitemgr.hasSite(sitename):
        print "No such freesite '%s'" % sitename
        return

    if getyesno("Are you sure you wish to delete freesite '%s'", False):
        sitemgr.removeSite(sitename)
        print "Removed freesite '%s'" % sitename
    else:
        print "Freesite deletion aborted"

</t>
<t tx="aum.20060516194016">def getSiteNames(self):
    return self.config.sections()

</t>
<t tx="aum.20060516194958">def getSiteInfo(self, sitename):
    """
    returns a record of info about given site
    """
    if not self.hasSite(sitename):
        raise Exception("No such freesite '%s'" % sitename)

    conf = self.config

    if conf.has_option(sitename, "hash"):
        hash = conf.get(sitename, "hash")
    else:
        hash = None
    
    if conf.has_option(sitename, "version"):
        version = conf.getint(sitename, "version")
    else:
        version = None

    if conf.has_option(sitename, "privatekey"):
        privkey = conf.get(sitename, "privatekey")
    else:
        privkey = None
    
    if conf.has_option(sitename, "uri"):
        uri = conf.get(sitename, "uri")
    else:
        uri = None

    return {'name' : sitename,
            'dir' : conf.get(sitename, 'dir'),
            'hash' : hash,
            'version' : version,
            'privatekey' : privkey,
            'uri' : uri,
            }

</t>
<t tx="aum.20060516200626">def removeSite(self, sitename):
    """
    Drops a freesite from the config
    """
    if not self.hasSite(sitename):
        raise Exception("No such site '%s'" % sitename)

    conf = self.config
    conf.remove_section(sitename)
    
    self.saveConfig()

</t>
<t tx="aum.20060521111625"></t>
<t tx="aum.20060521111625.1"></t>
<t tx="aum.20060521111727">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060521111727.1">import sys, os, getopt, traceback, mimetypes

import fcp

</t>
<t tx="aum.20060521111727.2">def main():
    """
    Front end for fcpget utility
    """
    # default job options
    verbosity = fcp.ERROR
    verbose = False
    fcpHost = fcp.node.defaultFCPHost
    fcpPort = fcp.node.defaultFCPPort
    Global = False

    opts = {
            "Verbosity" : 0,
            "persistence" : "connection",
            }

    # process command line switches
    try:
        cmdopts, args = getopt.getopt(
            sys.argv[1:],
            "?hvH:P:gp:",
            ["help", "verbose", "fcpHost=", "fcpPort=", "global", "persistence=",
             ]
            )
    except getopt.GetoptError:
        #traceback.print_exc()
        # print help information and exit:
        usage()
        sys.exit(2)
    output = None
    verbose = False
    #print cmdopts
    for o, a in cmdopts:

        if o in ("-?", "-h", "--help"):
            help()

        if o in ("-v", "--verbosity"):
            verbosity = fcp.node.DETAIL
            opts['Verbosity'] = 1023
            verbose = True

        if o in ("-H", "--fcpHost"):
            fcpHost = a
        
        if o in ("-P", "--fcpPort"):
            try:
                fcpPort = int(a)
            except:
                usage("Invalid fcpPort argument %s" % repr(a))

        if o in ("-p", "--persistence"):
            if a not in ("connection", "reboot", "forever"):
                usage("Persistence must be one of 'connection', 'reboot', 'forever'")
            opts['persistence'] = a

        if o in ("-g", "--global"):
            opts['Global'] = "true"

    # process args    
    nargs = len(args)
    if nargs &lt; 1 or nargs &gt; 2:
        usage("Invalid number of arguments")
    
    uri = args[0]
    if not uri.startswith("freenet:"):
        uri = "freenet:" + uri

    # determine where to put output
    if nargs == 1:
        outfile = None
    else:
        outfile = args[1]

    # try to create the node
    try:
        node = fcp.FCPNode(host=fcpHost,
                           port=fcpPort,
                           verbosity=verbosity,
                           Global=Global,
                           logfile=sys.stderr)
    except:
        if verbose:
            traceback.print_exc(file=sys.stderr)
        usage("Failed to connect to FCP service at %s:%s" % (fcpHost, fcpPort))

    # try to retrieve the key
    try:
        mimetype, data = node.get(uri, **opts)
    except:
        if verbose:
            traceback.print_exc(file=sys.stderr)
        node.shutdown()
        sys.stderr.write("%s: Failed to retrieve key %s\n" % (progname, repr(uri)))
        sys.exit(1)

    node.shutdown()

    # try to dispose of the data
    if outfile:
        # figure out an extension, if none given
        base, ext = os.path.splitext(outfile)
        if not ext:
            ext = mimetypes.guess_extension(mimetype)
            if not ext:
                ext = ""
            outfile = base + ext

        # try to save to file
        try:           
            f = file(outfile, "wb")
            f.write(data)
            f.close()
            if verbose:
                sys.stderr.write("Saved key to file %s\n" % outfile)
        except:
            # save failed
            if verbose:
                traceback.print_exc(file=sys.stderr)
            usage("Failed to write data to output file %s" % repr(outfile))
    else:
        # no output file given, dump to stdout
        sys.stdout.write(data)
        sys.stdout.flush()

    # all done
    sys.exit(0)

</t>
<t tx="aum.20060521111727.3">if __name__ == '__main__':
    main()

</t>
<t tx="aum.20060521131205">argv = sys.argv
argc = len(argv)
progname = argv[0]

</t>
<t tx="aum.20060521131205.1">def usage(msg=None, ret=1):
    """
    Prints usage message then exits
    """
    if msg:
        sys.stderr.write(msg+"\n")
    sys.stderr.write("Usage: %s [options] key_uri [filename]\n" % progname)
    sys.stderr.write("Type '%s -h' for help\n" % progname)
    sys.exit(ret)

</t>
<t tx="aum.20060521131205.2">def help():
    """
    print help options, then exit
    """
    print "%s: a simple command-line freenet key retrieval command" % progname
    print "Usage: %s [options] key_uri [&lt;filename&gt;]" % progname
    print
    print "Arguments:"
    print "  &lt;key_uri&gt;"
    print "     A freenet key URI, such as 'freenet:KSK@gpl.txt'"
    print "     Note that the 'freenet:' part may be omitted if you feel lazy"
    print "  &lt;filename&gt;"
    print "     The filename to which to write the key's data. Note that if"
    print "     this filename has no extension (eg .txt), a file extension"
    print "     will be guessed based on the key's returned mimetype."
    print "     If this argument is not given, the key's data will be"
    print "     printed to standard output"
    print
    print "Options:"
    print "  -h, -?, --help"
    print "     Print this help message"
    print "  -v, --verbose"
    print "     Print verbose progress messages to stderr"
    print "  -H, --fcpHost=&lt;hostname&gt;"
    print "     Connect to FCP service at host &lt;hostname&gt;"
    print "  -P, --fcpPort=&lt;portnum&gt;"
    print "     Connect to FCP service at port &lt;portnum&gt;"
    print "  -p, --persistence="
    print "     Set the persistence type, one of 'connection', 'reboot' or 'forever'"
    print "  -g, --global"
    print "     Do it on the FCP global queue"
    print
    print "Environment:"
    print "  Instead of specifying -H and/or -P, you can define the environment"
    print "  variables FCP_HOST and/or FCP_PORT respectively"
    sys.exit(0)

</t>
<t tx="aum.20060521133455"></t>
<t tx="aum.20060521133455.1">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060521133455.2">"""
fcpget - a simple command-line program for freenet key retrieval
"""
@others
</t>
<t tx="aum.20060521134332"></t>
<t tx="aum.20060521134332.1">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060521134737">"""
fcpput - a simple command-line program for freenet key insertion
"""
@others
</t>
<t tx="aum.20060521134737.1">import sys, os, getopt, traceback, mimetypes

import fcp

</t>
<t tx="aum.20060521134737.2">argv = sys.argv
argc = len(argv)
progname = argv[0]

</t>
<t tx="aum.20060521134737.3">def usage(msg=None, ret=1):
    """
    Prints usage message then exits
    """
    if msg:
        sys.stderr.write(msg+"\n")
    sys.stderr.write("Usage: %s [options] key_uri [filename]\n" % progname)
    sys.stderr.write("Type '%s -h' for help\n" % progname)
    sys.exit(ret)

</t>
<t tx="aum.20060521134737.4">def help():
    """
    print help options, then exit
    """
    print "%s: a simple command-line freenet key insertion command" % progname
    print "Usage: %s [options] key_uri [&lt;filename&gt;]" % progname
    print
    print "Arguments:"
    print "  &lt;key_uri&gt;"
    print "     A freenet key URI, such as 'freenet:KSK@gpl.txt'"
    print "     Note that the 'freenet:' part may be omitted if you feel lazy"
    print "  &lt;filename&gt;"
    print "     The filename from which to source the key's data. If this filename"
    print "     is '-', or is not given, then the data will be sourced from"
    print "     standard input"
    print
    print "Options:"
    print "  -h, -?, --help"
    print "     Print this help message"
    print "  -v, --verbose"
    print "     Print verbose progress messages to stderr"
    print "  -H, --fcpHost=&lt;hostname&gt;"
    print "     Connect to FCP service at host &lt;hostname&gt;"
    print "  -P, --fcpPort=&lt;portnum&gt;"
    print "     Connect to FCP service at port &lt;portnum&gt;"
    print "  -m, --mimetype=&lt;mimetype&gt;"
    print "     The mimetype under which to insert the key. If not given, then"
    print "     an attempt will be made to guess it from the filename. If no"
    print "     filename is given, or if this attempt fails, the mimetype"
    print "     'text/plain' will be used as a fallback"
    print "  -p, --persistence="
    print "     Set the persistence type, one of 'connection', 'reboot' or 'forever'"
    print "  -g, --global"
    print "     Do it on the FCP global queue"
    print "  -n, --nowait"
    print "     Don't wait for completion, exit immediately"
    print
    print "Environment:"
    print "  Instead of specifying -H and/or -P, you can define the environment"
    print "  variables FCP_HOST and/or FCP_PORT respectively"

    sys.exit(0)

</t>
<t tx="aum.20060521134737.5">def main():
    """
    Front end for fcpget utility
    """
    # default job options
    verbosity = fcp.ERROR
    verbose = False
    fcpHost = fcp.node.defaultFCPHost
    fcpPort = fcp.node.defaultFCPPort
    mimetype = None
    nowait = False

    opts = {
            "Verbosity" : 0,
            "persistence" : "connection",
            "async" : False,
            }

    # process command line switches
    try:
        cmdopts, args = getopt.getopt(
            sys.argv[1:],
            "?hvH:P:m:gp:n",
            ["help", "verbose", "fcpHost=", "fcpPort=", "mimetype=", "global",
             "persistence=", "nowait"
             ]
            )
    except getopt.GetoptError:
        # print help information and exit:
        usage()
        sys.exit(2)
    output = None
    verbose = False
    #print cmdopts
    for o, a in cmdopts:

        if o in ("-?", "-h", "--help"):
            help()

        if o in ("-v", "--verbosity"):
            verbosity = fcp.node.DETAIL
            opts['Verbosity'] = 1023
            verbose = True

        if o in ("-H", "--fcpHost"):
            fcpHost = a
        
        if o in ("-P", "--fcpPort"):
            try:
                fcpPort = int(a)
            except:
                usage("Invalid fcpPort argument %s" % repr(a))

        if o in ("-m", "--mimetype"):
            mimetype = a

        if o in ("-p", "--persistence"):
            if a not in ("connection", "reboot", "forever"):
                usage("Persistence must be one of 'connection', 'reboot', 'forever'")
            opts['persistence'] = a

        if o in ("-g", "--global"):
            opts['Global'] = "true"

        if o in ("-n", "--nowait"):
            opts['async'] = True
            nowait = True

    # process args    
    nargs = len(args)
    if nargs &lt; 1 or nargs &gt; 2:
        usage("Invalid number of arguments")
    
    uri = args[0]
    if not uri.startswith("freenet:"):
        uri = "freenet:" + uri

    # determine where to get input
    if nargs == 1 or args[1] == '-':
        infile = None
    else:
        infile = args[1]

    # figure out a mimetype if none present
    if infile and not mimetype:
        base, ext = os.path.splitext(infile)
        if ext:
            mimetype = mimetypes.guess_type(ext)[0]

    if mimetype:
        # mimetype explicitly specified, or implied with input file,
        # stick it in.
        # otherwise, let FCPNode.put try to imply it from a uri's
        # 'file extension' suffix
        opts['mimetype'] = mimetype

    # try to create the node
    try:
        node = fcp.FCPNode(host=fcpHost, port=fcpPort, verbosity=verbosity,
                           logfile=sys.stderr)
    except:
        if verbose:
            traceback.print_exc(file=sys.stderr)
        usage("Failed to connect to FCP service at %s:%s" % (fcpHost, fcpPort))

    # grab the data
    if not infile:
        data = sys.stdin.read()
    else:
        try:
            data = file(infile, "rb").read()
        except:
            node.shutdown()
            usage("Failed to read input from file %s" % repr(infile))

    # try to insert the key
    try:
        print "opts=%s" % str(opts)
        uri = node.put(uri, data=data, **opts)
    except:
        if verbose:
            traceback.print_exc(file=sys.stderr)
        node.shutdown()
        sys.stderr.write("%s: Failed to insert key %s\n" % (progname, repr(uri)))
        sys.exit(1)

    if nowait:
        # got back a job ticket, wait till it has been sent
        uri.waitTillReqSent()
    else:
        # successful, return the uri
        sys.stdout.write(uri)
        sys.stdout.flush()

    node.shutdown()

    # all done
    sys.exit(0)

</t>
<t tx="aum.20060521134737.6">if __name__ == '__main__':
    main()

</t>
<t tx="aum.20060521135828">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060521163241">@
FreeDisk implements a linux filesystem over Freenet, using
FUSE (Filesystem in Userspace, http://fuse.sourceforge.net)

</t>
<t tx="aum.20060521163823">@first #! /usr/bin/env python
"""
A FUSE-based filesystem for freenet

Written May 2006 by aum

Released under the GNU Lesser General Public License

Requires:
    - python2.3 or later
    - FUSE kernel module installed and loaded
      (apt-get install fuse-source, crack tarball, build and install)
    - python2.3-fuse
    - libfuse2
"""

@others

</t>
<t tx="aum.20060521163823.1">import sys, os, time, stat, errno
from StringIO import StringIO
import thread
from threading import Lock
import traceback
from Queue import Queue
import sha, md5
from UserString import MutableString

from errno import *
from stat import *

try:
    import warnings
    warnings.filterwarnings('ignore',
                            'Python C API version mismatch',
                            RuntimeWarning,
                            )
except:
    pass
 
import sys
from errno import *

import fcp

from fcp.xmlobject import XMLFile
from fcp.node import guessMimetype, base64encode, base64decode, uriIsPrivate

</t>
<t tx="aum.20060521163823.2">class FreenetBaseFS:

	@others

</t>
<t tx="aum.20060521163823.3">def __init__(self, mountpoint, *args, **kw):
    """
    Create a freenetfs
    
    Arguments:
        - mountpoint - the dir in the filesystem at which to mount the fs
        - other args get passed to fuse
    
    Keywords:
        - multithreaded - whether to run the fs multithreaded, default True
        - fcpHost - hostname of FCP service
        - fcpPort - port number of FCP service
        - verbosity - defaults to fcp.DETAIL
        - config - location of config file
        - debug - whether to run in debug mode, default False
    """

    self.log("FreenetBaseFS.__init__: args=%s kw=%s" % (args, kw))

    for k in ['multithreaded',
              'fcpHost',
              'fcpPort',
              'verbosity',
              'debug',
              ]:
        if kw.has_key(k):
            v = kw.pop(k)
            try:
                v = int(v)
            except:
                pass
                
            setattr(self, k, v)

    self.optlist = list(args)
    self.optdict = dict(kw)

    self.mountpoint = mountpoint
    
    #if not self.config:
    #    raise Exception("Missing 'config=filename.conf' argument")

    #self.loadConfig()
    self.setupFiles()
    self.setupFreedisks()

    # do stuff to set up your filesystem here, if you want
    #thread.start_new_thread(self.mythread, ())

    if 0:
        self.log("xmp.py:Xmp:mountpoint: %s" % repr(self.mountpoint))
        self.log("xmp.py:Xmp:unnamed mount options: %s" % self.optlist)
        self.log("xmp.py:Xmp:named mount options: %s" % self.optdict)

    try:
        self.node = None
        self.connectToNode()
    except:
        raise
        pass

</t>
<t tx="aum.20060521163823.4">def mythread(self):

    """
    The beauty of the FUSE python implementation is that with the python interp
    running in foreground, you can have threads
    """    
    self.log("mythread: started")
    #while 1:
    #    time.sleep(120)
    #    print "mythread: ticking"

</t>
<t tx="aum.20060521163823.5">multithreaded = 0
flags = 1
debug = False
fcpHost = fcpHost
fcpPort = fcpPort
verbosity = defaultVerbosity
allow_other = False
kernel_cache = False
config = os.path.join(os.path.expanduser("~"), ".freediskrc")

# Files and directories already present in the filesytem.
# Note - directories must end with "/"

initialFiles = [
    "/",
    "/get/",
    "/put/",
    "/keys/",
    "/usr/",
    "/cmds/",
    ]

chrFiles = [
    ]

</t>
<t tx="aum.20060521163823.6">def getattr(self, path):

    rec = self.files.get(path, None)
    if not rec:
        # each of these code segments should assign a record to 'rec',
        # or raise an IOError
        
        # retrieving a key?
        if path.startswith("/keys/"):
            &lt;&lt;generate keypair&gt;&gt;
        elif path.startswith("/get/"):
            &lt;&lt;retrieve/cache key&gt;&gt;
        elif path.startswith("/cmds/"):
            &lt;&lt;base64 command&gt;&gt;
        else:
            raise IOError(errno.ENOENT, path)

    self.log("getattr: path=%s" % path)
    self.log("  mode=0%o" % rec.mode)
    self.log("  inode=0x%x" % rec.inode)
    self.log("  dev=0x%x" % rec.dev)
    self.log("  nlink=0x%x" % rec.nlink)
    self.log("  uid=%d" % rec.uid)
    self.log("  gid=%d" % rec.gid)
    self.log("  size=%d" % rec.size)
    self.log("  atime=%d" % rec.atime)
    self.log("  mtime=%d" % rec.mtime)
    self.log("  ctime=%d" % rec.ctime)
    self.log("rec=%s" % str(rec))

    return tuple(rec)

</t>
<t tx="aum.20060521163823.7">def readlink(self, path):

	ret = os.readlink(path)
    self.log("readlink: path=%s\n  =&gt; %s" % (path, ret))
	return ret

</t>
<t tx="aum.20060521163823.8">def getdir(self, path):

    rec = self.files.get(path, None)

    if rec:
        files = [os.path.split(child.path)[-1] for child in rec.children]
        files.sort()
        if rec.isdir:
            if  path != "/":
                files.insert(0, "..")
            files.insert(0, ".")
    else:
        self.log("Hit main fs for %s" % path)
        files = os.listdir(path)

    ret = map(lambda x: (x,0), files)

    self.log("getdir: path=%s\n  =&gt; %s" % (path, ret))
    return ret

</t>
<t tx="aum.20060521163823.9">def unlink(self, path):

    self.log("unlink: path=%s" % path)

    # remove existing file?
    if path.startswith("/get/") \
    or path.startswith("/put/") \
    or path.startswith("/keys/"):
        rec = self.files.get(path, None)
        if not rec:
            raise IOError(2, path)
        self.delFromCache(rec)
        return 0

    if path.startswith("/usr"):
        # remove a file within a freedisk

        # barf if nonexistent
        rec = self.files.get(path, None)
        if not rec:
            raise IOError(errno.ENOENT, path)

        # barf if removing dir
        if rec.isdir:
            raise IOError(errno.EISDIR, path)

        # barf if trying to remove a . control file
        bits = path.split("/")[2:]
        diskPath = "/".join(path.split("/")[:3])
        if len(bits) == 2 and bits[1] in freediskSpecialFiles:
            raise IOError(errno.EACCES, path)

        # barf if not on an existing freedisk
        diskRec = self.files.get(diskPath, None)
        if not diskRec:
            raise IOError(errno.ENOENT, path)

        # barf if freedisk not writeable
        if not diskRec.canwrite:
            raise IOError(errno.EACCES, path)

        # ok to delete
        self.delFromCache(rec)

        ret = 0
    else:
        raise IOError(errno.ENOENT, path)

    # fallback on host fs
    self.log("unlink:   =&gt; %s" % ret)
	return ret

</t>
<t tx="aum.20060521163823.10">def rmdir(self, path):

    self.log("rmdir: path=%s" % path)

    rec = self.files.get(path, None)

    # barf if no such directory
    if not rec:
        raise IOError(errno.ENOENT, path)

    # barf if not a directory
    if not rec.isdir:
        raise IOError(errno.ENOTDIR, path)

    # barf if not within freedisk mounts
    if not path.startswith("/usr/"):
        raise IOError(errno.EACCES, path)

    # seek the freedisk record
    bits = path.split("/")
    diskPath = "/".join(bits[:3])
    diskRec = self.files.get(diskPath, None)

    # barf if nonexistent
    if not diskRec:
        raise IOError(errno.ENOENT, path)

    # if a freedisk root, just delete
    if path == diskPath:
        # remove directory record
        self.delFromCache(rec)

        # and remove children
        for k in self.files.keys():
            if k.startswith(path+"/"):
                del self.files[k]

        return 0

    # now, it's a subdir within a freedisk
    
    # barf if non-empty
    if rec.children:
        raise IOError(errno.ENOTEMPTY, path)
    
    # now, at last, can remove
    self.delFromCache(rec)
    ret = 0

    self.log("rmdir:   =&gt; %s" % ret)

	return ret

</t>
<t tx="aum.20060521163823.11">def symlink(self, path, path1):

    raise IOError(errno.EPERM, path)

	ret = os.symlink(path, path1)
    self.log("symlink: path=%s path1=%s\n  =&gt; %s" % (path, path1, ret))
	return ret

</t>
<t tx="aum.20060521163823.12">def rename(self, path, path1):

    rec = self.files.get(path, None)
    if not rec:
        raise IOError(errno.ENOENT, path)

    del self.files[path]
    self.files[path1] = rec
    rec.haschanged = True
    ret = 0

    self.log("rename: path=%s path1=%s\n  =&gt; %s" % (path, path1, ret))
	return ret

</t>
<t tx="aum.20060521163823.13">def link(self, path, path1):

    raise IOError(errno.EPERM, path)

	ret = os.link(path, path1)
    self.log("link: path=%s path1=%s\n  =&gt; %s" % (path, path1, ret))
	return ret

</t>
<t tx="aum.20060521163823.14">def chmod(self, path, mode):

	ret = os.chmod(path, mode)
    self.log("chmod: path=%s mode=%s\n  =&gt; %s" % (path, mode, ret))
	return ret

</t>
<t tx="aum.20060521163823.15">def chown(self, path, user, group):

	ret = os.chown(path, user, group)
    self.log("chmod: path=%s user=%s group=%s\n  =&gt; %s" % (path, user, group, ret))
	return ret

</t>
<t tx="aum.20060521163823.16">def truncate(self, path, size):

    self.log("truncate: path=%s size=%s" % (path, size))

    if not path.startswith("/usr/"):
        raise IOError(errno.EPERM, path)

    parentPath, filename = os.path.split(path)

    if os.path.split(parentPath)[0] != "/usr":
        raise IOError(errno.EPERM, path)

    rec = self.files.get(path, None)
    if not rec:
        raise IOError(errno.ENOENT, path)

    # barf at readonly files
    if filename == '.status':
        raise IOError(errno.EPERM, path)

    rec.data = ""

    ret = 0

    self.log("truncate:    =&gt; %s" % ret)

    return ret

</t>
<t tx="aum.20060521163823.17">def mknod(self, path, mode, dev):
    """ Python has no os.mknod, so we can only do some things """

    if path == "/":
        #return -EINVAL
        raise IOError(errno.EEXIST, path)
    
    parentPath = os.path.split(path)[0]
    if parentPath in ['/', '/usr']:
        #return -EINVAL
        raise IOError(errno.EPERM, path)

    # start key write, if needed
    if parentPath == "/put":

        # see if an existing file
        if self.files.has_key(path):
            raise IOError(errno.EEXIST, path)

        rec = self.addToCache(
            path=path, isreg=True, iswriting=True,
            perm=0644)
        ret = 0

    elif path.startswith("/usr/"):
        # creating a file in a user dir
        
        # barf if no write permission in dir
        diskPath = "/".join(path.split("/")[:3])
        diskRec = self.files.get(diskPath, None)
        #if not diskRec:
        #    raise IOError(errno.ENOENT, path)
        if diskRec and not diskRec.canwrite:
            self.log("mknod: diskPath=%s" % diskPath)
            raise IOError(errno.EPERM, path)

        # create the record
        rec = self.addToCache(path=path, isreg=True, perm=0644,
                              iswriting=True, haschanged=True)
        ret = 0

        # fall back on host os
        #if S_ISREG(mode):
        #    file(path, "w").close()
        #    ret = 0

    else:
        #ret = -EINVAL
        raise IOError(errno.EPERM, path)

    self.log("mknod: path=%s mode=0%o dev=%s\n  =&gt; %s" % (
                path, mode, dev, ret))

    return ret

</t>
<t tx="aum.20060521163823.18">def mkdir(self, path, mode):

    self.log("mkdir: path=%s mode=%s" % (path, mode))

    # barf if directory exists
    if self.files.has_key(path):
        raise IOError(errno.EEXIST, path)

    # barf if happening outside /usr/
    if not path.startswith("/usr/"):
        raise IOError(errno.EACCES, path)

    parentPath = os.path.split(path)[0]

    if parentPath == '/usr':
        # creating a new freedisk

        # create the directory record
        rec = self.addToCache(path=path, isdir=True, perm=0555)

        # create the pseudo-files within it
        for name in freediskSpecialFiles:
            subpath = os.path.join(path, name)
            rec = self.addToCache(path=subpath, isreg=True, perm=0644)
            if name == '.status':
                rec.data = "idle"

        # done here
        return 0

    elif path.startswith("/usr/"):
        # creating a dir within a freedisk

        # barf if no write permission in dir
        diskPath = "/".join(path.split("/")[:3])
        diskRec = self.files.get(diskPath, None)
        #if not diskRec:
        #    self.log("mkdir: diskPath=%s" % diskPath)
        #    raise IOError(errno.ENOENT, path)
        if diskRec and not diskRec.canwrite:
            self.log("mkdir: diskPath=%s" % diskPath)
            raise IOError(errno.EPERM, path)

        # ok to create
        self.addToCache(path=path, isdir=True, perm=0755)
    
    return 0
    
</t>
<t tx="aum.20060521163823.19">def utime(self, path, times):

	ret = os.utime(path, times)
    self.log("utime: path=%s times=%s\n  =&gt; %s" % (path, times, ret))
	return ret

</t>
<t tx="aum.20060521163823.20">def open(self, path, flags):

    self.log("open: path=%s flags=%s" % (path, flags))

    # see if it's an existing file
    rec = self.files.get(path, None)
    
    if rec:
        # barf if not regular file
        if not (rec.isreg or rec.ischr):
            self.log("open: %s is not regular file" % path)
            raise IOError(errno.EIO, "Not a regular file: %s" % path)

    else:
        # fall back to host fs
        raise IOError(errno.ENOENT, path)

    for flag in [os.O_WRONLY, os.O_RDWR, os.O_APPEND]:
        if flags &amp; flag:
            self.log("open: setting iswriting for %s" % path)
            rec.iswriting = True
            rec.haschanged = True

    self.log("open: open of %s succeeded" % path)

    # seems ok
    return 0

</t>
<t tx="aum.20060521163823.21">def read(self, path, length, offset):
    """
    """
    # forward to existing file if any
    rec = self.files.get(path, None)
    if rec:
        rec.seek(offset)
        buf = rec.read(length)
        
        self.log("read: path=%s length=%s offset=%s\n =&gt; %s" % (
                                    path, length, offset, len(buf)))
        #print repr(buf)
        return buf
        
    else:
        # fall back on host fs
        f = open(path, "r")
        f.seek(offset)
        buf = f.read(length)

    self.log("read: path=%s length=%s offset=%s\n  =&gt; (%s bytes)" % (
                                    path, length, offset, len(buf)))

    return buf

</t>
<t tx="aum.20060521163823.22">def write(self, path, buf, off):

    dataLen = len(buf)

    rec = self.files.get(path, None)
    if rec:
        # write to existing 'file'
        rec.seek(off)
        rec.write(buf)
        rec.hasdata = True
    else:
        f = open(path, "r+")
        f.seek(off)
        nwritten = f.write(buf)
        f.flush()

    self.log("write: path=%s buf=[%s bytes] off=%s" % (path, len(buf), off))

	#return nwritten
	return dataLen

</t>
<t tx="aum.20060521163823.23">def release(self, path, flags):

    rec = self.files.get(path, None)
    if not rec:
        return

    filename = os.path.split(path)[1]

    # ditch any encoded command files
    if path.startswith("/cmds/"):
        #print "got file %s" % path
        rec = self.files.get(path, None)
        if rec:
            self.delFromCache(rec)
        else:
            print "eh? not in cache"

    # if writing, save the thing
    elif rec.iswriting:
        
        self.log("release: %s: iswriting=True" % path)

        # what uri?
        rec.iswriting = False

        print "Release: path=%s" % path

        if path.startswith("/put/"):
            &lt;&lt;insert to freenet&gt;&gt;

        elif path.startswith("/usr/"):
            &lt;&lt;write to freedisk&gt;&gt;


    self.log("release: path=%s flags=%s" % (path, flags))
    return 0
</t>
<t tx="aum.20060521163823.24">def statfs(self):
    """
    Should return a tuple with the following 6 elements:
        - blocksize - size of file blocks, in bytes
        - totalblocks - total number of blocks in the filesystem
        - freeblocks - number of free blocks
        - totalfiles - total number of file inodes
        - freefiles - nunber of free file inodes

    Feel free to set any of the above values to 0, which tells
    the kernel that the info is not available.
    """
    self.log("statfs: returning fictitious values")
    blocks_size = 1024
    blocks = 100000
    blocks_free = 25000
    files = 100000
    files_free = 60000
    namelen = 80

    return (blocks_size, blocks, blocks_free, files, files_free, namelen)

</t>
<t tx="aum.20060521163823.25">def fsync(self, path, isfsyncfile):

    self.log("fsync: path=%s, isfsyncfile=%s" % (path, isfsyncfile))
    return 0

</t>
<t tx="aum.20060521163823.26">if __name__ == '__main__':

    main()
</t>
<t tx="aum.20060521175052">class ErrnoWrapper:

    def __init__(self, func):
        self.func = func

    def __call__(self, *args, **kw):
        try:
            return apply(self.func, args, kw)
        except (IOError, OSError), detail:
            if showAllExceptions:
                traceback.print_exc()
            # Sometimes this is an int, sometimes an instance...
            if hasattr(detail, "errno"): detail = detail.errno
            return -detail


</t>
<t tx="aum.20060521175052.4">def GetContext(self):
    print "GetContext: called"
    return _fuse.FuseGetContext(self)

</t>
<t tx="aum.20060521175052.5">def Invalidate(self, path):
    print "Invalidate: called"
    return _fuse.FuseInvalidate(self, path)

</t>
<t tx="aum.20060521175052.6">def run(self):

    import _fuse

    d = {'mountpoint': self.mountpoint,
         'multithreaded': self.multithreaded,
         }

    #print "run: d=%s" % str(d)

    if self.debug:
        d['lopts'] = 'debug'

    k=[]
    for opt in ['allow_other', 'kernel_cache']:
        if getattr(self, opt):
            k.append(opt)
    if k:
        d['kopts'] = ",".join(k)

    for a in self._attrs:
        if hasattr(self,a):
            d[a] = ErrnoWrapper(getattr(self, a))

    #thread.start_new_thread(self.tickThread, ())

    _fuse.main(**d)

</t>
<t tx="aum.20060521175433">argv = sys.argv
argc = len(argv)
progname = argv[0]

fcpHost = fcp.node.defaultFCPHost
fcpPort = fcp.node.defaultFCPPort

defaultVerbosity = fcp.DETAIL

quiet = 0

myuid = os.getuid()
mygid = os.getgid()

inodes = {}
inodesNext = 1

# set this to disable hits to node, for debugging
_no_node = 0

# special filenames in freedisk toplevel dirs
freediskSpecialFiles = [
    '.privatekey', '.publickey', '.cmd', '.status', ".passwd",
    ]

showAllExceptions = False

</t>
<t tx="aum.20060521180804">def invertprivate(self, privatekey):
    """
    Converts an SSK or USK private key to a public equivalent
    """
    bits = privatekey.split("/", 1)
    mainUri = bits[0]

    uri = self.put(mainUri+"/foo", data="bar", chkonly=1)

    uri = uri.split("/")[0]
    uri = "/".join([uri] + bits[1:])

    return uri

</t>
<t tx="aum.20060521182836"></t>
<t tx="aum.20060521183025">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060521183025.1">"""
fcpgenkey - a simple command-line program for freenet keypair generation
"""
@others
</t>
<t tx="aum.20060521183025.2">import sys, os, getopt, traceback, mimetypes

import fcp

</t>
<t tx="aum.20060521183025.3">argv = sys.argv
argc = len(argv)
progname = argv[0]

</t>
<t tx="aum.20060521183025.4">def usage(msg=None, ret=1):
    """
    Prints usage message then exits
    """
    if msg:
        sys.stderr.write(msg+"\n")
    sys.stderr.write("Usage: %s [options]\n" % progname)
    sys.stderr.write("Type '%s -h' for help\n" % progname)
    sys.exit(ret)

</t>
<t tx="aum.20060521183025.5">def help():
    """
    print help options, then exit
    """
    print "%s: a simple command-line freenet keypair"  % progname
    print "generation command"
    print
    print "Generates a simple SSK keypair, and prints"
    print "public key, then private key, each on its own line"
    print
    print "Usage: %s [options]" % progname
    print
    print "Options:"
    print "  -h, -?, --help"
    print "     Print this help message"
    print "  -v, --verbose"
    print "     Print verbose progress messages to stderr"
    print "  -H, --fcpHost=&lt;hostname&gt;"
    print "     Connect to FCP service at host &lt;hostname&gt;"
    print "  -P, --fcpPort=&lt;portnum&gt;"
    print "     Connect to FCP service at port &lt;portnum&gt;"
    print
    print "Environment:"
    print "  Instead of specifying -H and/or -P, you can define the environment"
    print "  variables FCP_HOST and/or FCP_PORT respectively"

    sys.exit(0)

</t>
<t tx="aum.20060521183025.6">def main():
    """
    Front end for fcpget utility
    """
    # default job options
    verbosity = fcp.ERROR
    verbose = False
    fcpHost = fcp.node.defaultFCPHost
    fcpPort = fcp.node.defaultFCPPort
    mimetype = None

    opts = {
            "Verbosity" : 0,
            }

    # process command line switches
    try:
        cmdopts, args = getopt.getopt(
            sys.argv[1:],
            "?hvH:P:",
            ["help", "verbose", "fcpHost=", "fcpPort=",
             ]
            )
    except getopt.GetoptError:
        # print help information and exit:
        usage()
        sys.exit(2)
    output = None
    verbose = False
    #print cmdopts
    for o, a in cmdopts:

        if o in ("-?", "-h", "--help"):
            help()

        if o in ("-v", "--verbosity"):
            verbosity = fcp.node.DETAIL
            opts['Verbosity'] = 1023
            verbose = True

        if o in ("-H", "--fcpHost"):
            fcpHost = a
        
        if o in ("-P", "--fcpPort"):
            try:
                fcpPort = int(a)
            except:
                usage("Invalid fcpPort argument %s" % repr(a))

    # try to create the node
    try:
        node = fcp.FCPNode(host=fcpHost, port=fcpPort, verbosity=verbosity,
                           logfile=sys.stderr)
    except:
        if verbose:
            traceback.print_exc(file=sys.stderr)
        usage("Failed to connect to FCP service at %s:%s" % (fcpHost, fcpPort))

    # grab the keypair
    pub, priv = node.genkey()

    node.shutdown()

    # successful, return the uri
    print pub
    print priv

    # all done
    sys.exit(0)

</t>
<t tx="aum.20060521183025.7">if __name__ == '__main__':
    main()

</t>
<t tx="aum.20060521183205">@first #!/usr/bin/env python
@others
</t>
<t tx="aum.20060521185642"># primitives required for actual fs operations

@others

</t>
<t tx="aum.20060521185946">def hashpath(self, path):
    
    return sha.new(path).hexdigest()

</t>
<t tx="aum.20060521190048">def getReadURI(self, path):
    """
    Converts to a pathname to a freenet URI for insertion,
    using public key
    """
    return self.pubkey + self.hashpath(path) + "/0"

</t>
<t tx="aum.20060521190048.1">def getWriteURI(self, path):
    """
    Converts to a pathname to a freenet URI for insertion,
    using private key if any
    """
    if not self.privkey:
        raise Exception("cannot write: no private key")
    
    return self.privkey + self.hashpath(path) + "/0"

</t>
<t tx="aum.20060521191057">def _loadConfig(self):
    """
    The 'physical device' argument to mount should be the pathname
    of a configuration file, with 'name=val' lines, including the
    following items:
        - publickey=&lt;freenet public key URI&gt;
        - privatekey=&lt;freenet private key URI&gt; (optional, without which we
          will have the fs mounted readonly
    """
    opts = {}

    # build a dict of all the 'name=value' pairs in config file
    for line in [l.strip() for l in file(self.config).readlines()]:
        if line == '' or line.startswith("#"):
            continue
        try:
            name, val = line.split("=", 1)
            opts[name.strip()] = val.strip()
        except:
            pass

    # mandate a pubkey
    try:
        self.pubkey = opts['pubkey'].replace("SSK@", "USK@").split("/")[0] + "/"
    except:
        raise Exception("Config file %s: missing or invalid publickey" \
                        % self.configfile)

    # accept optional privkey
    if opts.has_key("privkey"):

        try:
            self.privkey = opts['privkey'].replace("SSK@",
                                                 "USK@").split("/")[0] + "/"
        except:
            raise Exception("Config file %s: invalid privkey" \
                            % self.configfile)

    # mandate cachepath
    try:
        self.cachedir = opts['cachedir']
        if not os.path.isdir(self.cachedir):
            self.log("Creating cache directory %s" % self.cachedir)
            os.makedirs(self.cachedir)
            #raise hell
    except:
        raise Exception("config file %s: missing or invalid cache directory" \
                        % self.configfile)

</t>
<t tx="aum.20060521232922">def log(self, msg):
    #if not quiet:
    #    print "freedisk:"+msg
    file("/tmp/freedisk.log", "a").write(msg+"\n")

</t>
<t tx="aum.20060522200735">@nocolor
--------------------------------------------------
README file for freedisk - the freenet filesystem
--------------------------------------------------

Here's a basic checklist for getting your freenetfs up and running:

[  ]  FUSE library is installed (http://fuse.sf.net)
      (or debian package 'libfuse2')

[  ]  FUSE python bindings are installed (ditto)
      (or debian package 'python-fuse')

[  ]  FUSE kernel module is built and installed
      (debian package 'fuse-source')

[  ]  FUSE kernel module is loaded (su -c "modprobe fuse")

[  ]  A group called 'fuse' exists

[  ]  You are a member of group 'fuse'

[  ]  You have an entry in /etc/fstab like:

  /dev/fuse /mnt/freenet freenetfs defaults,noauto,user,exec,suid,config=/path/to/freedisk.conf 0 0

[  ]  Your chosen mountpoint (/mnt/freenet, or whatever you
      changed it to in /etc/fstab) exists as a writable directory

[  ]  You have create a symlink from freedisk.py to /sbin/mount.freenetfs


Debian installation instructions:

1) apt-get install fuse-source libfuse2 python-fuse

2) build and install the FUSE kernel module:

   $ su
   Password: 
   # cd /usr/src
   # tar xfj fuse.tar.bz2
   # cd modules/fuse/kernel
   # ./configure
   # make
   # make install

3) Add yourself to 'fuse' usergroup, via 'useradd' command or by hacking
   /etc/group

4) Edit 'freedisk.conf' and stick in your own keypair, and adjust the
   cache path as needed

Installation for other Linux distros:

 - sorry, you'll have to study the debian instructions and figure
   it out for your own distro. You could just download/install
   FUSE, the FUSE kernel module and the FUSE python module from source.


Running FreenetFS
-----------------

If you've succeeded with all the above, then you can just type:

    $ mount /mnt/freenet

Fetch a key:

    $ cat /mnt/freenet/get/KSK@hello

See that the key is cached:

    $ ls -las /mnt/freenet/get

Clear the key from the cache:

    $ rm /mnt/freenet/get/KSK@hello

Generate a couple SSK keypairs:

    $ cat /mnt/freenet/keys/fred
    $ cat /mnt/freenet/keys/mary

You'll see in each case a public key on one line, then a private key.

Now, let's insert something:

    $ echo "Hello" &gt; /mnt/freenet/put/KSK@something

Now, wait a bit, and do:

    $ ls -las /mnt/freenet/get

once the key is inserted, you'll see it in the 'get'
directory.

Now, something smarter - we can insert CHKs...

    $ echo "This is a chk" &gt; /mnt/freenet/put/CHK@mykey.txt

Now test it:

    $ ls -l /mnt/freenet/put

You should see a file CHK@mykey.txt

Type:

    $ cat /mnt/freenet/put/CHK@mykey.txt

and you should get a single word, 'pending'.

After a time, the file's contents will change to either
'failed', meaning the insert failed, or a freenet URI,
in which case it succeeded.

If it succeeded, do:

    $ ls -las /mnt/freenet/get

You should see an entry 'CHK@yadayadayadayada.txt'.

You can rm any of these entries.

------------------------------------------------------------------

STATUS:

 - key generation working:
    $ cat /mnt/freenet/genkey
    $ cat /mnt/freenet/genkeypair

 - partial key retrieve (only for URIs with no slashes):
    $ cat /mnt/freenet/keys/KSK@hello

 - key deletion from cache (via 'rm') working

 - write not done

 - fancy shit not done yet

</t>
<t tx="aum.20060522225626">def statToDict(self, info):
    """
    Converts a tuple returned by a stat call into
    a dict with keys:
        
        - isdir
        - ischr
        - isblk
        - isreg
        - isfifo
        - islnk
        - issock
        - mode
        - inode
        - dev
        - nlink
        - uid
        - gid
        - size
        - atime
        - mtime
        - ctime
    """
    print "statToDict: info=%s" % str(info)

    mode = info[stat.ST_MODE]
    return {
        'isdir'  : stat.S_ISDIR(mode),
        'ischr'  : stat.S_ISCHR(mode),
        'isblk'  : stat.S_ISBLK(mode),
        'isreg'  : stat.S_ISREG(mode),
        'isfifo' : stat.S_ISFIFO(mode),
        'islink'  : stat.S_ISLNK(mode),
        'issock' : stat.S_ISSOCK(mode),
        'mode'   : mode,
        'inode'  : info[stat.ST_INO],
        'dev'    : info[stat.ST_DEV],
        'nlink'  : info[stat.ST_NLINK],
        'uid'    : info[stat.ST_UID],
        'gid'    : info[stat.ST_GID],
        'size'   : info[stat.ST_SIZE],
        'atime'  : info[stat.ST_ATIME],
        'mtime'  : info[stat.ST_MTIME],
        'ctime'  : info[stat.ST_CTIME],
        }

</t>
<t tx="aum.20060522231936">def statFromKw(self, **kw):
    """
    Constructs a stat tuple from keywords
    """
    tup = [0] * 10

    # build mode mask
    mode = kw.get('mode', 0)
    if kw.get('isdir', False):
        mode |= stat.S_IFDIR
    if kw.get('ischr', False):
        mode |= stat.S_IFCHR
    if kw.get('isblk', False):
        mode |= stat.S_IFBLK
    if kw.get('isreg', False):
        mode |= stat.S_IFREG
    if kw.get('isfifo', False):
        mode |= stat.S_IFIFO
    if kw.get('islink', False):
        mode |= stat.S_IFLNK
    if kw.get('issock', False):
        mode |= stat.S_IFSOCK

    path = kw['path']

    # get inode number
    inode = self.pathToInode(path)
    
    dev = 0
    
    nlink = 1
    uid = myuid
    gid = mygid
    size = 0
    atime = mtime = ctime = timeNow()

    return (mode, inode, dev, nlink, uid, gid, size, atime, mtime, ctime)

    # st_mode, st_ino, st_dev, st_nlink,
    # st_uid, st_gid, st_size,
    # st_atime, st_mtime, st_ctime

</t>
<t tx="aum.20060525193858">def pathToInode(path):
    """
    Comes up with a unique inode number given a path
    """
    # try for existing known path/inode    
    inode = inodes.get(path, None)
    if inode != None:
        return inode

    # try hashing the path to 32bit
    inode = int(md5.new(path).hexdigest()[:7], 16)
    
    # and ensure it's unique
    while inodes.has_key(inode):
        inode += 1

    # register it
    inodes[path] = inode

    # done
    return inode
    
</t>
<t tx="aum.20060525194744">def __getDirStat(self, path):
    """
    returns a stat tuple for given path
    """
    return FileRecord(mode=0700, path=path, isdir=True)

</t>
<t tx="aum.20060525194744.1">def timeNow():
    return int(time.time()) &amp; 0xffffffffL

</t>
<t tx="aum.20060525225133">class FileRecord(list):
    """
    Encapsulates the info for a file, and can
    be returned by getattr
    """
    @others

</t>
<t tx="aum.20060525225133.1">def __init__(self, fs, statrec=None, **kw):
    """
    """
    # copy keywords cos we'll be popping them
    kw = dict(kw)

    # save fs ref
    self.fs = fs

    # got a statrec arg?
    if statrec:
        # yes, extract main items
        dev = statrec[stat.ST_DEV]
        nlink = statrec[stat.ST_NLINK]
        uid = statrec[stat.ST_UID]
        gid = statrec[stat.ST_GID]
        size = statrec[stat.ST_SIZE]
    else:
        # no, fudge a new one
        statrec = [0,0,0,0,0,0,0,0,0,0]
        dev = 0
        nlink = 1
        uid = myuid
        gid = mygid
        size = 0

    # convert tuple to list if need be
    if not hasattr(statrec, '__setitem__'):
        statrec = list(statrec)

    # build mode mask
    mode = kw.pop('mode', 0)
    if kw.pop('isdir', False):
        mode |= stat.S_IFDIR
    if kw.pop('ischr', False):
        mode |= stat.S_IFCHR
    if kw.pop('isblk', False):
        mode |= stat.S_IFBLK
    if kw.pop('isreg', False):
        mode |= stat.S_IFREG
    if kw.pop('isfifo', False):
        mode |= stat.S_IFIFO
    if kw.pop('islink', False):
        mode |= stat.S_IFLNK
    if kw.pop('issock', False):
        mode |= stat.S_IFSOCK

    # handle non-file-related keywords
    perm = kw.pop('perm', 0)
    mode |= perm

    # set path
    path = kw.pop('path')
    self.path = path

    # set up data stream
    if kw.has_key("data"):
        self.stream = StringIO(kw.pop('data'))
        self.hasdata = True
    else:
        self.stream = StringIO()
    
    # find parent, if any
    if path == '/':
        self.parent = None
    else:
        parentPath = os.path.split(path)[0]
        parentRec = fs.files[parentPath]
        self.parent = parentRec

    # child files/dirs
    self.children = []
    
    # get inode number
    inode = pathToInode(path)
    
    #size = kw.get('size', 0)
    now = timeNow()
    atime = kw.pop('atime', now)
    mtime = kw.pop('mtime', now)
    ctime = kw.pop('ctime', now)

    #print "statrec[stat.ST_MODE]=%s" % statrec[stat.ST_MODE]
    #print "mode=%s" % mode

    statrec[stat.ST_MODE] |= mode
    statrec[stat.ST_INO] = inode
    statrec[stat.ST_DEV] = dev
    statrec[stat.ST_NLINK] = nlink
    statrec[stat.ST_UID] = uid
    statrec[stat.ST_GID] = gid

    statrec[stat.ST_SIZE] = len(self.stream.getvalue())

    statrec[stat.ST_ATIME] = atime
    statrec[stat.ST_MTIME] = atime
    statrec[stat.ST_CTIME] = atime

    # throw remaining keywords into instance's attribs
    self.__dict__.update(kw)

    # finally, parent constructor, now that we have a complete stat list
    list.__init__(self, statrec)

    if self.isdir:
        self.size = 2

</t>
<t tx="aum.20060525225603">def __getattr__(self, attr):
    """
    Support read of pseudo-attributes:
        - mode, isdir, ischr, isblk, isreg, isfifo, islnk, issock,
        - inode, dev, nlink, uid, gid, size, atime, mtime, ctime
    """
    if attr == 'mode':
        return self[stat.ST_MODE]

    if attr == 'isdir':
        return stat.S_ISDIR(self.mode)

    if attr == 'ischr':
        return stat.S_ISCHR(self.mode)

    if attr == 'isblk':
        return stat.S_ISBLK(self.mode)

    if attr in ['isreg', 'isfile']:
        return stat.S_ISREG(self.mode)

    if attr == 'isfifo':
        return stat.S_ISFIFO(self.mode)

    if attr == 'islnk':
        return stat.S_ISLNK(self.mode)

    if attr == 'issock':
        return stat.S_ISSOCK(self.mode)

    if attr == 'inode':
        return self[stat.ST_INO]
    
    if attr == 'dev':
        return self[stat.ST_DEV]
    
    if attr == 'nlink':
        return self[stat.ST_NLINK]
    
    if attr == 'uid':
        return self[stat.ST_UID]

    if attr == 'gid':
        return self[stat.ST_GID]

    if attr == 'size':
        return self[stat.ST_SIZE]
    
    if attr == 'atime':
        return self[stat.ST_ATIME]
    
    if attr == 'mtime':
        return self[stat.ST_ATIME]
    
    if attr == 'ctime':
        return self[stat.ST_ATIME]

    if attr == 'data':
        return self.stream.getvalue()
    
    try:
        return getattr(self.stream, attr)
    except:
        pass

    raise AttributeError(attr)

</t>
<t tx="aum.20060525225713">def __setattr__(self, attr, val):
    """
    Support write of pseudo-attributes:
        - mode, isdir, ischr, isblk, isreg, isfifo, islnk, issock,
        - inode, dev, nlink, uid, gid, size, atime, mtime, ctime
    """
    if attr == 'isdir':
        if val:
            self[stat.ST_MODE] |= stat.S_IFDIR
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFDIR
    elif attr == 'ischr':
        if val:
            self[stat.ST_MODE] |= stat.S_IFCHR
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFCHR
    elif attr == 'isblk':
        if val:
            self[stat.ST_MODE] |= stat.S_IFBLK
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFBLK
    elif attr in ['isreg', 'isfile']:
        if val:
            self[stat.ST_MODE] |= stat.S_IFREG
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFREG
    elif attr == 'isfifo':
        if val:
            self[stat.ST_MODE] |= stat.S_IFIFO
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFIFO
    elif attr == 'islnk':
        if val:
            self[stat.ST_MODE] |= stat.S_IFLNK
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFLNK
    elif attr == 'issock':
        if val:
            self[stat.ST_MODE] |= stat.S_IFSOCK
        else:
            self[stat.ST_MODE] &amp;= ~stat.S_IFSOCK

    elif attr == 'mode':
        self[stat.ST_MODE] = val
    elif attr == 'inode':
        self[stat.ST_IMO] = val
    elif attr == 'dev':
        self[stat.ST_DEV] = val
    elif attr == 'nlink':
        self[stat.ST_NLINK] = val
    elif attr == 'uid':
        self[stat.ST_UID] = val
    elif attr == 'gid':
        self[stat.ST_GID] = val
    elif attr == 'size':
        self[stat.ST_SIZE] = val
    elif attr == 'atime':
        self[stat.ST_ATIME] = val
    elif attr == 'mtime':
        self[stat.ST_MTIME] = val
    elif attr == 'ctime':
        self[stat.ST_CTIME] = val

    elif attr == 'data':
        oldPos = self.stream.tell()
        self.stream = StringIO(val)
        self.stream.seek(min(oldPos, len(val)))
        self.size = len(val)

    else:
        self.__dict__[attr] = val

</t>
<t tx="aum.20060526071442">def setupFiles(self):
    """
    Create initial file/directory layout, according
    to attributes 'initialFiles' and 'chrFiles'
    """
    # easy map of files
    self.files = {}

    # now create records for initial files
    for path in self.initialFiles:

        # initial attribs
        isReg = isDir = isChr = isSock = isFifo = False
        perm = size = 0

        # determine file type
        if path.endswith("/"):
            isDir = True
            path = path[:-1]
            if not path:
                path = "/"
        elif path in self.chrFiles:
            # it's a char file
            #isChr = True
            isReg = True
            perm |= 0666
            size = 1024
        else:
            # by default, it's a regular file
            isReg = True

        # create permissions field
        if isDir:
            perm |= 0755
            size = 2
        else:
            perm |= 0444

        # create record for this path
        self.addToCache(
            path=path,
            perm=perm,
            size=size,
            isdir=isDir, isreg=isReg, ischr=isChr,
            issock=isSock, isfifo=isFifo,
            )

</t>
<t tx="aum.20060526072230">def addChild(self, rec):
    """
    Adds a child file rec as a child of this rec
    """
    if not isinstance(rec, FileRecord):
        raise Exception("Not a FileRecord: %s" % rec)

    self.children.append(rec)
    self.size += 1

    #print "addChild: path=%s size=%s" % (self.path, self.size)

</t>
<t tx="aum.20060526112020">def connectToNode(self):
    """
    Attempts a connection to an fcp node
    """
    if self.node:
        return
    
    #self.verbosity = fcp.DETAIL

    self.log("connectToNode: verbosity=%s" % self.verbosity)

    try:
        self.node = fcp.FCPNode(host=self.fcpHost,
                                port=self.fcpPort,
                                verbosity=self.verbosity)
    except:
        raise IOError(errno.EIO, "Failed to reach FCP service at %s:%s" % (
                        self.fcpHost, self.fcpPort))

    #self.log("pubkey=%s" % self.pubkey)
    #self.log("privkey=%s" % self.privkey)
    #self.log("cachedir=%s" % self.cachedir)

</t>
<t tx="aum.20060526123909">@language c
#include &lt;stdio.h&gt;

int main(int argc, char *argv[])
{
    FILE *fp;
    int fd;
    char buf[2048];
    int n;
    int len;

/**    
    fp = fopen("/mnt/freenet/cmd/genkey", "r");
    printf("got fp=0x%lx\n", fp);
    n = 0;
    while ((n = fread(&amp;buf[len], (size_t)1, (size_t)1, fp)) &gt; 0)
    {
        printf("len=%d\n", len);
        ++len;
    }
**/
    
    fd = open("/mnt/freenet/cmd/genkey", 0);
    printf("got fd=0x%lx\n", fd);
    len = 0;
    while ((n = read(fd, &amp;buf[len], 1)) &gt; 0)
    {
        printf("len=%d\n", len);
        ++len;
    }
    
    printf("len=%d\n", len);
    
}

</t>
<t tx="aum.20060526163608"># check the cache
if _no_node:
    print "FIXME: returning IOerror"
    raise IOError(errno.ENOENT, path)

# get a key
uri = path.split("/", 2)[-1]
try:
    self.connectToNode()
    mimetype, data = self.node.get(uri)
    rec = self.addToCache(
        path=path,
        isreg=True,
        perm=0644,
        data=data,
        )

except:
    traceback.print_exc()
    #print "ehhh?? path=%s" % path
    raise IOError(errno.ENOENT, path)

</t>
<t tx="aum.20060527114053">def delChild(self, rec):
    """
    Tries to remove a child entry
    """
    if rec in self.children:
        self.children.remove(rec)
        self.size -= 1

    else:
        print "eh? trying to remove %s from %s" % (rec.path, self.path)

    #print "delChild: path=%s size=%s" % (self.path, self.size)

</t>
<t tx="aum.20060527114534">def addToCache(self, rec=None, **kw):
    """
    Tries to 'cache' a given file/dir record, and
    adds it to parent dir
    """
    if rec == None:
        rec = FileRecord(self, **kw)

    path = rec.path

    # barf if file/dir already exists
    if self.files.has_key(path):
        self.log("addToCache: already got %s !!!" % path)
        return

    #print "path=%s" % path

    # if not root, add to parent
    if path != '/':
        parentPath = os.path.split(path)[0]
        parentRec = self.files.get(parentPath, None)
        parentRec.addChild(rec)
        if not parentRec:
            self.log("addToCache: no parent of %s ?!?!" % path)
            return

    # ok, add to our table
    self.files[path] = rec

    # done
    return rec

</t>
<t tx="aum.20060527114743">def delFromCache(self, rec):
    """
    Tries to remove file/dir record from cache
    """
    if isinstance(rec, str):
        path = rec
        rec = self.files.get(path, None)
        if not rec:
            print "delFromCache: no such path %s" % path
            return
    else:
        path = rec.path

    parentPath = os.path.split(path)[0]
    
    if self.files.has_key(path):
        rec = self.files[path]
        del self.files[path]
        for child in rec.children:
            self.delFromCache(child)
    
    parentRec = self.files.get(parentPath, None)
    if parentRec:
        parentRec.delChild(rec)

</t>
<t tx="aum.20060527140140.2">def write(self, buf):
    
    self.stream.write(buf)
    self.size = len(self.stream.getvalue())

</t>
<t tx="aum.20060527195652"># generate a new keypair
self.connectToNode()
pubkey, privkey = self.node.genkey()
rec = self.addToCache(
    path=path,
    isreg=True,
    data=pubkey+"\n"+privkey+"\n",
    perm=0444,
    )

</t>
<t tx="aum.20060528175118">"""
Allows XML files to be operated on like Python objects.

Features:
    - load XML source from file pathnames, readable file objects or raw strings
    - add, get and set tag attributes like with python attributes
    - iterate over nodes
    - save the modified XMLFile or XMLObject to file

Example XML file::

    &lt;?xml version="1.0" encoding="UTF-8"?&gt;
    &lt;rapsheets&gt;
     &lt;person name="John Smith" age="42"&gt;
        &lt;!-- John Smith has an appeal in process against his last conviction --&gt;
        &lt;crime name="Armed robbery" date="March 11, 1994"/&gt;
        &lt;crime name="Aggravated burglary" date="June 9, 2001"/&gt;
     &lt;/person&gt;
     &lt;person name="Mary Jones" age="33"&gt;
        &lt;crime name="Prostitution" date="January 8, 1997"/&gt;
        &lt;crime name="Selling heroin" date="September 4, 2002"/&gt;
        &lt;crime name="Manslaughter" date="December 21, 2004"/&gt;
     &lt;/person&gt;
    &lt;/rapsheets&gt;

Example usage::

    &gt;&gt;&gt; from xmlobject import XMLFile
    
    &gt;&gt;&gt; x = XMLFile(path="sample.xml)

    &gt;&gt;&gt; print x
    &lt;xmlobj.XMLFile instance at 0xb7ccc52c&gt;

    &gt;&gt;&gt; print x.root
    &lt;XMLNode: rapsheets&gt;

    &gt;&gt;&gt; print x.root._children
    [&lt;XMLNode: text&gt;, &lt;XMLNode: person&gt;, &lt;XMLNode: text&gt;,
     &lt;XMLNode: person&gt;, &lt;XMLNode: text&gt;]

    &gt;&gt;&gt; print x.root.person
    [&lt;XMLNode: person&gt;, &lt;XMLNode: person&gt;]

    &gt;&gt;&gt; print x.root.person[0].name
    John Smith

    &gt;&gt;&gt; john = x.root.person[0]
    
    &gt;&gt;&gt; john.height = 184

    &gt;&gt;&gt; c = john._addNode("crime")

    &gt;&gt;&gt; c.name = "Grand Theft Auto"
    
    &gt;&gt;&gt; c.date = "4 May, 2005"

    &gt;&gt;&gt; print x.toxml()
    &lt;?xml version="1.0" ?&gt;
    &lt;rapsheets&gt;
     &lt;person age="42" height="184" name="John Smith"&gt;
        &lt;!-- John Smith has an appeal in process against his last conviction --&gt;
        &lt;crime date="March 11, 1994" name="Armed robbery"/&gt;
        &lt;crime date="June 9, 2001" name="Aggravated burglary"/&gt;
     &lt;crime date="4 May, 2005" name="Grand Theft Auto"/&gt;&lt;/person&gt;
     &lt;person age="33" name="Mary Jones"&gt;
        &lt;crime date="January 8, 1997" name="Prostitution"/&gt;
        &lt;crime date="September 4, 2002" name="Selling heroin"/&gt;
        &lt;crime date="December 21, 2004" name="Manslaughter"/&gt;
     &lt;/person&gt;
    &lt;/rapsheets&gt;

    &gt;&gt;&gt;

"""

@others</t>
<t tx="aum.20060528175118.1">import sys, os
import xml.dom
import xml.dom.minidom
from xml.dom.minidom import parse, parseString, getDOMImplementation

</t>
<t tx="aum.20060528175118.2">impl = getDOMImplementation()

</t>
<t tx="aum.20060528175118.3">class MissingRootTag(Exception):
    """root tag name was not given"""

class InvalidXML(Exception):
    """failed to parse XML input"""

class CannotSave(Exception):
    """unable to save"""

class InvalidNode(Exception):
    """not a valid minidom node"""

</t>
<t tx="aum.20060528175118.4">class XMLFile:
    """
    Allows an xml file to be viewed and operated on
    as a python object.

    (If you're viewing the epydoc-generated HTML documentation, click the 'show private'
    link at the top right of this page to see all the methods)

    Holds the root node in the .root attribute, also in an attribute
    with the same name as this root node.
    """
    @others

</t>
<t tx="aum.20060528175118.5">def __init__(self, **kw):
    """
    Create an XMLFile
    
    Keywords:
        - path - a pathname from which the file can be read
        - file - an open file object from which the raw xml
          can be read
        - raw - the raw xml itself
        - root - name of root tag, if not reading content

    Usage scenarios:
        1. Working with existing content - you must supply input in
           one of the following ways:
               - 'path' must be an existing file, or
               - 'file' must be a readable file object, or
               - 'raw' must contain raw xml as a string
        2. Creating whole new content - you must give the name
           of the root tag in the 'root' keyword
    
    Notes:
        - Keyword precedence governing existing content is:
            1. path (if existing file)
            2. file
            3. raw
        - If working with existing content:
            - if the 'root' is given, then the content's toplevel tag
              MUST match the value given for 'root'
            - trying to _save will raise an exception unless 'path'
              has been given
        - if not working with existing content:
            - 'root' must be given
            - _save() will raise an exception unless 'path' has been given
    """
    path = kw.get("path", None)
    fobj = kw.get("file", None)
    raw = kw.get("raw", None)
    root = kw.get("root", None)
    
    if path:
        self.path = path
        try:
            fobj = file(path)
        except IOError:
            pass
    else:
        self.path = None

    if fobj:
        raw = fobj.read()

    if raw:
        self.dom = xml.dom.minidom.parseString(raw)
    else:
        # could not source content, so create a blank slate
        if not root:
            # in which case, must give a root node name
            raise MissingRootTag(
                    "No existing content, so must specify root")

        # ok, create a blank dom
        self.dom = impl.createDocument(None, root, None)

    # get the root node, save it as attributes 'root' and name of node
    rootnode = self.dom.documentElement

    # now validate root tag
    if root:
        if rootnode.nodeName != root:
            raise IncorrectRootTag("Gave root='%s', input has root='%s'" % (
                root, rootnode.nodeName))

    # need this for recursion in XMLNode
    self._childrenByName = {}
    self._children = []

    # add all the child nodes    
    for child in self.dom.childNodes:
        childnode = XMLNode(self, child)
        #print "compare %s to %s" % (rootnode, child)
        if child == rootnode:
            #print "found root"
            self.root = childnode
    setattr(self, rootnode.nodeName, self.root)

</t>
<t tx="aum.20060528175118.6">def save(self, where=None, obj=None):
    """
    Saves the document.
    
    If argument 'where' is given, saves to it, otherwise
    tries to save to the original given 'path' (or barfs)
    
    Value can be a string (taken to be a file path), or an open
    file object.
    """
    obj = obj or self.dom

    if not where:
        if self.path:
            where = self.path

    if isinstance(where, str):
        where = file(where, "w")

    if not where:
        raise CannotSave("No save destination, and no original path")

    where.write(obj.toxml())
    where.flush()

</t>
<t tx="aum.20060528175118.7">def saveAs(self, path):
    """
    save this time, and all subsequent times, to filename 'path'
    """
    self.path = path
    self.save()

</t>
<t tx="aum.20060528175118.8">def toxml(self):
    return self.dom.toxml()

</t>
<t tx="aum.20060528175118.9">def __len__(self):
    """
    returns number of child nodes
    """
    return len(self._children)

</t>
<t tx="aum.20060528175118.10">def __getitem__(self, idx):
    if isinstance(idx, int):
        return self._children[idx]
    else:
        return self._childrenByName[idx]

</t>
<t tx="aum.20060528175118.11">class XMLNode:
    """
    This is the workhorse for the xml object interface

    (If you're viewing the epydoc-generated HTML documentation, click the 'show private'
    link at the top right of this page to see all the methods)

    """
    @others
</t>
<t tx="aum.20060528175118.12">def __init__(self, parent, node):
    """
    You shouldn't need to instantiate this directly
    """
    self._parent = parent
    if isinstance(parent, XMLFile):
        self._root = parent
    else:
        self._root = parent._root
    self._node = node
    self._childrenByName = {}
    self._children = []

    # add ourself to parent's children registry
    parent._children.append(self)

    # the deal with named subtags is that we store the first instance
    # as itself, and with second and subsequent instances, we make a list
    parentDict = self._parent._childrenByName
    nodeName = node.nodeName
    if not parentDict.has_key(nodeName):
        parentDict[nodeName] = parent.__dict__[nodeName] = self
    else:
        if isinstance(parentDict[nodeName], XMLNode):
            # this is the second child node of a given tag name, so convert
            # the instance to a list
            parentDict[nodeName] = parent.__dict__[nodeName] = [parentDict[nodeName]]
        parentDict[nodeName].append(self)

    # figure out our type
    self._value = None
    if isinstance(node, xml.dom.minidom.Text):
        self._type = "text"
        self._value = node.nodeValue
    elif isinstance(node, xml.dom.minidom.Element):
        self._type = "node"
        self._name = nodeName
    elif isinstance(node, xml.dom.minidom.Comment):
        self._type = "comment"
        self._value = node.nodeValue
    else:
        raise InvalidNode("node class %s" % node.__class__)

    # and wrap all the child nodes
    for child in node.childNodes:
        XMLNode(self, child)

</t>
<t tx="aum.20060528175118.13">def _render(self):
    """
    Produces well-formed XML of this node's contents,
    indented as required
    """
    return self._node.toxml()

</t>
<t tx="aum.20060528175118.14">def __repr__(self):
    if self._type == "node":
        return "&lt;XMLNode: %s&gt;" % self._node.nodeName
    else:
        return "&lt;XMLNode: %s&gt;" % self._type

</t>
<t tx="aum.20060528175118.15">def __getattr__(self, attr):
    """
    Fetches an attribute or child node of this tag
    
    If it's an attribute, then returns the attribute value as a string.
    
    If a child node, then:
        - if there is only one child node of that name, return it
        - if there is more than one child node of that name, return a list
          of child nodes of that tag name

    Supports some magic attributes:
        - _text - the value of the first child node of type text
    """
    #print "%s: __getattr__: attr=%s" % (self, attr)

    # magic attribute to return text
    if attr == '_text':
        tnode = self['#text']
        if isinstance(tnode, list):
            tnode = tnode[0]
        return tnode._value

    if self._type in ['text', 'comment']:
        if attr == '_value':
            return self._node.nodeValue
        else:
            raise AttributeError(attr)

    if self._node.hasAttribute(attr):
        return self._node.getAttribute(attr)
    elif self._childrenByName.has_key(attr):
        return self._childrenByName[attr]
    
    #elif attr == 'value':
        # magic attribute
        
    else:
        raise AttributeError(attr)


</t>
<t tx="aum.20060528175118.16">def __setattr__(self, attr, val):
    """
    Change the value of an attribute of this tag

    The magic attribute '_text' can be used to set the first child
    text node's value
    
    For example::
        
        Consider:
        
          &lt;somenode&gt;
            &lt;child&gt;foo&lt;/child&gt;
          &lt;/somenode&gt;

        &gt;&gt;&gt; somenode
        &lt;XMLNODE: somenode&gt;
        &gt;&gt;&gt; somenode.child
        &lt;XMLNODE: child&gt;
        &gt;&gt;&gt; somenode.child._text
        'foo'
        &gt;&gt;&gt; somenode._toxml()
        u'&lt;somenode&gt;&lt;child&gt;foo&lt;/child&gt;&lt;/somenode&gt;'
        &gt;&gt;&gt; somenode.child._text = 'bar'
        &gt;&gt;&gt; somenode.child._text
        'bar'
        &gt;&gt;&gt; somenode.child._toxml()
        u'&lt;somenode&gt;&lt;child&gt;bar/child&gt;&lt;/somenode&gt;'
        
    """
    if attr.startswith("_"):

        # magic attribute for setting _text
        if attr == '_text':
            tnode = self['#text']
            if isinstance(tnode, list):
                tnode = tnode[0]
            tnode._node.nodeValue = val
            tnode._value = val
            return
            
        self.__dict__[attr] = val
    elif self._type in ['text', 'comment']:
        self._node.nodeValue = val
    else:
        # discern between attribute and child node
        if self._childrenByName.has_key(attr):
            raise Exception("Attribute Exists")
        self._node.setAttribute(attr, str(val))

</t>
<t tx="aum.20060528175118.17">def _keys(self):
    """
    Return a list of attribute names
    """
    return self._node.attributes.keys()

def _values(self):
    """
    Returns a list of (attrname, attrval) tuples for this tag
    """
    return [self._node.getAttribute(k) for k in self._node.attributes.keys()]

def _items(self):
    """
    returns a list of attribute values for this tag
    """
    return [(k, self._node.getAttribute(k)) for k in self._node.attributes.keys()]

def _has_key(self, k):
    """
    returns True if this tag has an attribute of the given name
    """
    return self._node.hasAttribute(k) or self._childrenByName.has_key(k)

def _get(self, k, default=None):
    """
    returns the value of attribute k, or default if no such attribute
    """
    if self._has_key(k):
        return getattr(self, k)
    else:
        return default
</t>
<t tx="aum.20060528175118.18">def __len__(self):
    """
    returns number of child nodes
    """
    return len(self._children)

</t>
<t tx="aum.20060528175118.19">def __getitem__(self, idx):
    """
    if given key is numeric, return the nth child, otherwise
    try to return the child tag (or list of child tags) having
    the key as the tag name
    """
    #print "__getitem__: idx=%s" % str(idx)

    if isinstance(idx, slice) or isinstance(idx, int):
        return self._children[idx]
    elif isinstance(idx, str):
        return self._childrenByName[idx]
    else:
        raise IndexError(idx)

</t>
<t tx="aum.20060528175118.20">def _addNode(self, child):
    """
    Tries to append a child node to the tree, and returns it
    
    Value of 'child' must be one of:
        - a string (in which case it is taken to be the name
          of the new node's tag)
        - a dom object, in which case it will be wrapped and added
        - an XMLNode object, in which case it will be added without
          wrapping
    """

    if isinstance(child, XMLNode):

        # add it to our children registry
        self._children.append(child)

        parentDict = self._childrenByName
        nodeName = child._node.nodeName

        if not parentDict.has_key(nodeName):
            parentDict[nodeName] = self.__dict__[nodeName] = child
        else:
            if isinstance(parentDict[nodeName], XMLNode):
                # this is the second child node of a given tag name, so convert
                # the instance to a list
                parentDict[nodeName] \
                    = self.__dict__[nodeName] \
                        = [parentDict[nodeName]]

            parentDict[nodeName].append(child)

        # and stick it in the dom
        self._node.appendChild(child._node)
        
        return child

    elif isinstance(child, str):
        childNode = self._root.dom.createElement(child)
        self._node.appendChild(childNode)

    elif isinstance(child, xml.dom.minidom.Element):
        childNode = child
        child = childNode.nodeName
        self._node.appendChild(childNode)

        
    return XMLNode(self, childNode)

</t>
<t tx="aum.20060528175118.21">def _addText(self, value):
    """
    Tries to append a child text node, with the given text, to the tree,
    and returns the created node object
    """
    childNode = self._root.dom.createTextNode(value)
    self._node.appendChild(childNode)
    return XMLNode(self, childNode)

</t>
<t tx="aum.20060528175118.22">def _addComment(self, comment):
    """
    Tries to append a child comment node (with the given text value)
    to the tree, and returns the create node object
    """
    childNode = self._root.dom.createCommentNode(comment)
    self._node.appendChild(childNode)
    return XMLNode(self, childNode)

</t>
<t tx="aum.20060528175118.23">def _save(self, where=None):
    """
    Generates well-formed XML from just this node, and saves it
    to a file.
    
    Argument 'where' is either an open file object, or a pathname

    If 'where' is not given, then saves the entire document tree.
    """
    if not where:
        self._root.save()
    else:
        self._root.save(where, self._node)

</t>
<t tx="aum.20060528175118.24">def _toxml(self):
    """
    renders just this node out to raw xml code
    """
    return self._node.toxml()

</t>
<t tx="aum.20060528180449">@nocolor

pyfcp notes

</t>
<t tx="aum.20060528180449.1">notes on freedisk

 - freedisk, n. A shareable disk residing within freenet, that can
   be mounted within a freenetfs

structure of a freedisk

 - a single xml file containing all file/directory entries within
   the disk

 - top-level pseudo-files:
    - /_cmd - write commands
    - /_status - write status

usage procedure

 1. mount it
        - mkdir /mnt/freenet/usr/fred

 2. either:
        - mount a new disk, by writing an SSK private key, eg:
            freenet:SSK@yadayada/
          to /mnt/freenet/usr/fred/_privatekey
    or
        - mount an existing disk read/write, by writing an
          SSK private key, eg:
            SSK@blahprivateblah/
          to /mnt/freenet/usr/fred/_privatekey

          then writing to /mnt/freenet/usr/fred/_cmd the line:
            import

    or
        - mount an existing disk readonly, by writing an
          SSK public key, eg:
            SSK@blahpublicblah/
          to /mnt/freenet/usr/fred/_publickey

          then writing to /mnt/freenet/usr/fred/_cmd the line:
            import

 3. If the disk is mounted with write permission, then write to
    _cmd the line:
            export

 4. when finished with it, do:
        - rmdir /mnt/freenet/usr/fred

status file

 reading from /mnt/freenet/usr/fred/_status will return one of:
    - idle - no syncing is occurring
    - importing - synchronising inbound
    - exporting - synchronising outbound

xml file format

  &lt;freedisk name="mydiskname" owner="fred"&gt;
    &lt;!-- plain files have path, uri and size attributes --&gt;
    &lt;node path="/fred.txt" uri="CHK@blahblahblah" size="2232"/&gt;

    &lt;!-- directory nodes have paths ending with a '/', and no uri or size--&gt;
    &lt;node path="/mary/"/&gt;

  &lt;/freedisk&gt;

export of freedisk inserts as SSK

</t>
<t tx="aum.20060528214253"># insert directly to freenet as a key

uri = os.path.split(path)[1]

# frigs to allow fancy CHK@ inserts
if uri.startswith("CHK@"):
    putUri = "CHK@"
else:
    putUri = uri

ext = os.path.splitext(uri)[1]

try:
    self.log("release: inserting %s" % uri)

    mimetype = fcp.node.guessMimetype(path)
    data = rec.data

    # empty the pseudo-file till a result is through
    rec.data = 'inserting'

    self.connectToNode()

    #print "FIXME: data=%s" % repr(data)

    if _no_node:
        print "FIXME: not inserting"
        getUri = "NO_URI"
    else:
        # perform the insert
        getUri = self.node.put(
                    putUri,
                    data=data,
                    mimetype=mimetype)

        # strip 'freenet:' prefix
        if getUri.startswith("freenet:"):
            getUri = getUri[8:]

        # restore file extension
        if getUri.startswith("CHK@"):
            getUri += ext

        # now cache the read-back
        self.addToCache(
            path="/get/"+getUri,
            data=data,
            perm=0444,
            isreg=True,
            )

        # and adjust the written file to reveal read uri
        rec.data = getUri

    self.log("release: inserted %s as %s ok" % (
                uri, mimetype))

except:
    traceback.print_exc()
    rec.data = 'failed'
    self.log("release: insert of %s failed" % uri)
    raise IOError(errno.EIO, "Failed to insert")
self.log("release: done with insertion")

</t>
<t tx="aum.20060528214707"># releasing a file being written into a freedisk

bits = path.split("/")

self.log("release: bits=%s" % str(bits))

if bits[0] == '' and bits[1] == 'usr':
    diskName = bits[2]
    fileName = bits[3]
    
    self.log("diskName=%s fileName=%s" % (diskName, fileName))
    
    if fileName == '.privatekey':
        # written a private key, make the directory writeable
        parentPath = os.path.split(path)[0]
        parentRec = self.files[parentPath]
        parentRec.canwrite = True
        self.log("release: got privkey, mark dir %s read/write" % parentRec)

    elif fileName == '.cmd':
        # wrote a command

        self.log("got release of .cmd")

        cmd = rec.data.strip()
        rec.data = ""
        
        self.log("release: cmd=%s" % cmd)

        # execute according to command
        if cmd == 'commit':
            self.commitDisk(diskName)
        elif cmd == 'update':
            self.updateDisk(diskName)
        elif cmd == 'merge':
            self.mergeDisk(diskName)

</t>
<t tx="aum.20060528221744"># methods for freedisk operations

@others

</t>
<t tx="aum.20060528221758">def delDisk(self, name):
    """
    drops a freedisk mount
    
    Arguments:
        - name - the name of the disk
    """
    diskPath = "/usr/" + name
    rec = self.freedisks.pop(diskPath)
    self.delFromCache(rec)

</t>
<t tx="aum.20060529123536">def main():

    kw = {}
    args = []

    if argc != 5:
        usage("Bad argument count")

    mountpoint = argv[2]

    for o in argv[4].split(","):
        try:
            k, v = o.split("=", 1)
            kw[k] = v
        except:
            args.append(o)

    kw['multithreaded'] = True
    #kw['multithreaded'] = False
    print "main: kw=%s" % str(kw)
    

    if os.fork() == 0:
        server = FreenetFuseFS(mountpoint, *args, **kw)
        server.run()


</t>
<t tx="aum.20060529123536.1">"""
freedisk is a command-line utility for creating,
mounting and synchronising freenet freedisks

Invoke with -h for help
"""
@others

</t>
<t tx="aum.20060529163723">import sys, os
import getopt
import traceback
import time
import sha
import getpass

try:
    import fcp
    from fcp import node, freenetfs
    from fcp.xmlobject import XMLFile, XMLNode
except:
    print "** PyFCP core module 'fcp' not installed."
    print "** Please refer to the INSTALL file within the PyFCP source package"
    sys.exit(1)

try:
    import SSLCrypto


except:
    SSLCrypto = None
    print "** WARNING! SSLCrypto module not installed"
    print "** Please refer to the INSTALL file within the PyFCP source package"

</t>
<t tx="aum.20060529163723.1"># args shorthand
argv = sys.argv
argc = len(argv)
progname = argv[0]

# default config file stuff
homedir = os.path.expanduser("~")
configFile = os.path.join(homedir, ".freediskrc")

defaultMountpoint = os.path.join(homedir, "freedisk")

</t>
<t tx="aum.20060529163723.2">def main():
    """
    Front end
    """
    &lt;&lt;set defaults&gt;&gt;

    &lt;&lt;process args&gt;&gt;

    &lt;&lt;execute command&gt;&gt;

</t>
<t tx="aum.20060529163723.4">if __name__ == '__main__':
    main()

</t>
<t tx="aum.20060529164147">def usage(msg=None, ret=1):
    """
    Prints usage message then exits
    """
    if msg:
        sys.stderr.write(msg+"\n")
    sys.stderr.write("Usage: %s [options] [&lt;command&gt; [&lt;args&gt;]]\n" % progname)
    sys.stderr.write("Type '%s -h' for help\n" % progname)
    sys.exit(ret)

</t>
<t tx="aum.20060529164147.1">def help():
    """
    Display help info then exit
    """
    print "%s: manage a freenetfs filesystem" % progname
    print "Usage: %s [&lt;options&gt;] &lt;command&gt; [&lt;arguments&gt;]" % progname
    print "Options:"
    print "  -h, --help            Display this help"
    print "  -c, --config=         Specify config file, default ~/.freediskrc"
    print "Commands:"
    print "  init                  Edit configuration interactively"
    print "  mount                 Mount the freenetfs"
    print "  unmount               Unmount the freenetfs"
    print "  new &lt;name&gt;            Create a new freedisk of name &lt;name&gt;"
    print "                        A new keypair will be generated."
    print "  add &lt;name&gt; &lt;URI&gt;      Add an existing freedisk of name &lt;name&gt;"
    print "                        and public key URI &lt;URI&gt;"
    print "  del &lt;name&gt;            Remove freedisk of name &lt;name&gt;"
    print "  update &lt;name&gt;         Sync freedisk &lt;name&gt; from freenet"
    print "  commit &lt;name&gt;         Commit freedisk &lt;name&gt; into freenet"
    print
    print "Environment variables:"
    print "  FREEDISK_CONFIG - set this in place of '-c' argument"

    sys.exit(0)

</t>
<t tx="aum.20060529184826">def usage(msg, ret=1):

    print "Usage: %s mountpoint -o args" % progname

    sys.exit(ret)

</t>
<t tx="aum.20060529191729">@first #!/usr/bin/env python
@language shell
import fcp
fcp.freenetfs.main()

</t>
<t tx="aum.20060530142805.1"># create defaults

opts = {
    'debug' : False,
    'multithreaded' : False,
    'configFile' : configFile,
    'verbosity' : fcp.ERROR,
    'Verbosity' : 1023,
    }

</t>
<t tx="aum.20060530143459"># process args

try:
    cmdopts, args = getopt.getopt(
        sys.argv[1:],
        "?hvc:dm",
        ["help", "verbose",
         "multithreaded",
         "config=", "debug",
         ]
        )
except getopt.GetoptError:
    # print help information and exit:
    usage()
    sys.exit(2)

#print cmdopts
for o, a in cmdopts:

    if o in ("-?", "-h", "--help"):
        help()

    if o in ("-v", "--verbose"):
        opts['verbosity'] = fcp.node.DETAIL
        opts['Verbosity'] = 1023
        verbose = True

    if o in ("-c", "--config"):
        opts['configFile'] = a

    if o in ("-d", "--debug"):
        opts['debug'] = True

    if o in ("-m", "--multithreaded"):
        opts['multithreaded'] = True

</t>
<t tx="aum.20060530143459.3">def cmd_start(self, *args):

    conf = self.conf
    kw = self.kw

    # spawn the child
    print "Spawning freenetfs filesystem process..."
    os.system("freedisk run &amp;")
    
    # wait for child to bring up the fs, via a very crude test
    keyDir = os.path.join(conf.mountpoint, "keys")
    print "Waiting for disk to come up..."
    while not os.path.isdir(keyDir):
        time.sleep(1)
    disks = conf.getDisks()

    if disks:
        print "Freenetfs now mounted, adding existing disks..."
    else:
        print "Freenetfs now mounted, no freedisks at present"

    for disk in disks:

        #break

        diskPath = os.path.join(conf.mountpoint, "usr", disk.name)

        # barf if a freedisk of that name is already mounted
        if os.path.exists(diskPath):
            usage("Freedisk %s seems to be already mounted" % disk.name)

        self.doFsCommand("mount %s|%s|%s" % (
            disk.name, disk.uri, disk.passwd))

        if 0:
            # mkdir to create the freedisk dir
            os.mkdir(diskPath)
    
            pubKeyPath = os.path.join(diskPath, ".publickey")
            privKeyPath = os.path.join(diskPath, ".privatekey")
            passwdPath = os.path.join(diskPath, ".passwd")
    
            # wait for the pseudo-files to come into existence
            while not os.path.isfile(privKeyPath):
                time.sleep(0.1)
    
            # set the key and password
            file(pubKeyPath, "w").write(disk.uri)
            file(privKeyPath, "w").write(disk.privUri)
            file(passwdPath, "w").write(disk.passwd)

    #while True:
    #    time.sleep(1)

</t>
<t tx="aum.20060530143459.4">def cmd_stop(self, *args):
    """
    Unmount the freenetfs
    """
    os.system("umount %s" % self.conf.mountpoint)

</t>
<t tx="aum.20060530143459.5">def cmd_new(self, *args):
    """
    Creates a new freedisk with a random key
    """
    #print "new: %s: NOT IMPLEMENTED" % diskname
    
    conf = self.conf
    diskname = self.diskname
    diskPath = self.diskPath

    if os.path.exists(diskPath):
        usage("Freedisk %s seems to be already mounted" % diskname)
    
    # get a password if desired
    passwd = getpasswd("Encrypt disk with password", True)
    
    # get a new private key
    keyDir = os.path.join(conf.mountpoint, "keys")
    if not os.path.isdir(keyDir):
        print "No keys directory %s" % keyDir
        print "Is your freenetfs mounted?"
        usage("Freenetfs not mounted")
    keyName = "freedisk_%s_%s" % (diskname, int(time.time()*1000000))
    keyPath = os.path.join(keyDir, keyName)
    
    keys = file(keyPath).read().strip().split("\n")
    pubKey, privKey = [k.split("/")[0].split("freenet:")[-1] for k in keys]

    print self.doFsCommand("mount %s|%s|%s" % (diskname, privKey, passwd))

    # and, of course, update config
    conf.addDisk(diskname, privKey, passwd)

    return


    # deprecated

    if 0:
        # mkdir to create the freedisk dir
        os.mkdir(diskPath)
        
        # wait for the pseudo-files to come into existence
        while not os.path.isfile(privKeyPath):
            time.sleep(0.1)
        
        #status("About to write to %s" % privKeyPath)
        
        file(self.pubKeyPath, "w").write(pubKey)
        file(self.privKeyPath, "w").write(privKey)
        file(self.passwdPath, "w").write(passwd)

</t>
<t tx="aum.20060530143459.6">def cmd_add(self, *args):

    nargs = len(args)

    diskname = self.diskname
    conf = self.conf

    # get uri
    if nargs &lt; 2:
        usage("add: Missing URI")
    uri = args[1]

    #print "add: %s: NOT IMPLEMENTED" % diskname
    
    # barf if a freedisk of that name is already mounted
    if os.path.exists(self.diskPath):
        usage("Freedisk %s seems to be already mounted" % diskname)

    # get a password if desired
    passwd = getpasswd("Disk's password", True)

    print self.doFsCommand("mount %s|%s|%s" % (diskname, uri, passwd))

    # and, of course, update config
    conf.addDisk(diskname, uri, passwd)

    return

    # deprecated

    if 0:    
        # mkdir to create the freedisk dir
        os.mkdir(self.diskPath)
        
        # wait for the pseudo-files to come into existence
        while not os.path.isfile(self.privKeyPath):
            time.sleep(0.1)
        
        # set the keys
        
        if fcp.node.uriIsPrivate(uri):
            path = privKeyPath
        else:
            path = pubKeyPath
        f = file(path, "w")
        f.write(uri)
        f.flush()
        f.close()
    
    </t>
<t tx="aum.20060530143459.7">def cmd_del(self, *args):
    """
    unmounts a freedisk
    """
    conf = self.conf
    diskname = self.diskname

    disk = conf.getDisk(diskname)
    
    if not isinstance(disk, XMLNode):
        usage("No such disk '%s'" % diskname)

    self.doFsCommand("umount %s" % diskname)
    
    conf.delDisk(diskname)
    
    return

    # deprecated

    path = os.path.join(conf.mountpoint, "usr", diskname)
    os.rmdir(path)

</t>
<t tx="aum.20060530143459.8">def cmd_update(self, *args):
    """
    Updates a freedisk *from* freenet
    """
    conf = self.conf
    diskname = self.diskname

    disk = conf.getDisk(diskname)
    
    if not isinstance(disk, XMLNode):
        usage("No such disk '%s'" % diskname)

    self.doFsCommand("update %s" % diskname)
    
    return

    # deprecated

    cmdPath = self.cmdPath
    diskname = self.diskname

    print "update: %s: NOT IMPLEMENTED" % diskname
    
    f = file(cmdPath, "w")
    f.write("update")
    f.flush()
    f.close()

</t>
<t tx="aum.20060530143459.9">def cmd_commit(self, *args):
    """
    commits a freedisk *to* freenet
    """
    conf = self.conf
    diskname = self.diskname

    disk = conf.getDisk(diskname)
    
    if not isinstance(disk, XMLNode):
        usage("No such disk '%s'" % diskname)

    res = self.doFsCommand("commit %s" % diskname)
    
    return res

    # deprecated

    cmdPath = self.cmdPath
    diskname = self.diskname

    print "commit: %s: launching.." % diskname
    
    f = file(cmdPath, "w")
    f.write("commit")
    f.flush()
    f.close()

</t>
<t tx="aum.20060530151453">def updateDisk(self, name):
    """
    synchronises a freedisk FROM freenet
    
    Arguments:
        - name - the name of the disk
    """
    self.log("updateDisk: disk=%s" % name)

    startTime = time.time()

    # determine freedisk's absolute path within the freenetfs
    rootPath = os.path.join("/usr", name)

    # get the freedisk root's record, barf if nonexistent
    rootRec = self.files.get(rootPath, None)
    if not rootRec:
        self.log("updateDisk: no disk '%s' mounted!" % name)
        return

    # determine pseudo-file paths
    statusFile = self.files[os.path.join(rootPath, ".status")]
    pubKeyFile = self.files[os.path.join(rootPath, ".publickey")]

    # and get the private key, sans 'freenet:'
    pubKey = pubKeyFile.data.split("freenet:")[-1]

    # process further
    pubKey = privKey.replace("SSK@", "USK@").split("/")[0] + "/" + name + "/0"

    self.log("update: pubKey=%s" % pubKey)

    # fetch manifest

    # mark disk as readonly
        
    # for each entry in manifest
    #     if not localfile has changed
    #         replace the file record

</t>
<t tx="aum.20060530151453.1">def commitDisk(self, name):
    """
    synchronises a freedisk TO freenet
    
    Arguments:
        - name - the name of the disk
    """
    self.log("commitDisk: disk=%s" % name)

    startTime = time.time()

    # determine freedisk's absolute path within the freenetfs
    rootPath = os.path.join("/usr", name)

    # get the freedisk root's record, barf if nonexistent
    diskRec = self.freedisks.get(name, None)
    if not diskRec:
        self.log("commitDisk: no such disk '%s'" % name)
        return "No such disk '%s'" % name
    
    rootRec = diskRec.root

    # get private key, if any
    privKey = diskRec.privKey
    if not privKey:
        # no private key - disk was mounted readonly with only a pubkey
        raise IOError(errno.EIO, "Disk %s is read-only" % name)

    # process the private key to needed format
    privKey = privKey.split("freenet:")[-1]
    privKey = privKey.replace("SSK@", "USK@").split("/")[0] + "/" + name + "/0"

    self.log("commit: privKey=%s" % privKey)

    self.log("commitDisk: checking files in %s" % rootPath)

    # update status
    #statusFile.data = "committing\nAnalysing files\n"

    # get list of records of files within this freedisk
    fileRecs = []
    for f in self.files.keys():
        # is file/dir within the freedisk?
        if f.startswith(rootPath+"/"):
            # yes, get its record
            fileRec = self.files[f]

            # is it a file, and not a special file?
            if fileRec.isfile and (os.path.split(f)[1] not in freediskSpecialFiles):
                # yes, grab it
                fileRecs.append(fileRec)

    # now sort them
    fileRecs.sort(lambda r1, r2: cmp(r1.path, r2.path))

    # make sure we have a node to talk to
    self.connectToNode()
    node = self.node

    # now insert all these files
    maxJobs = 5
    jobsWaiting = fileRecs[:]
    jobsRunning = []
    jobsDone = []

    # determine CHKs for all these jobs
    for rec in jobsWaiting:
        rec.mimetype = guessMimetype(rec.path)
        rec.uri = node.put(
            "CHK@file",
            data=rec.data,
            chkonly=True,
            mimetype=rec.mimetype)
    
    # now, create the manifest
    manifest = XMLFile(root="freedisk")
    root = manifest.root
    for rec in jobsWaiting:
        fileNode = root._addNode("file")
        fileNode.path = rec.path
        fileNode.uri = rec.uri
        try:
            fileNode.mimetype = rec.mimetype
        except:
            fileNode.mimetype = "text/plain"
        fileNode.hash = sha.new(rec.data).hexdigest()

    # and add the manifest as a waiting job
    manifestJob = node.put(
        privKey,
        data=manifest.toxml(),
        mimetype="text/xml",
        async=True,
        )

    #jobsRunning.append(manifestJob)
    #manifestUri = manifestJob.wait()
    #print "manifestUri=%s" % manifestUri
    #time.sleep(6)

    # the big insert/wait loop
    while jobsWaiting or jobsRunning:
        nWaiting = len(jobsWaiting)
        nRunning = len(jobsRunning)
        self.log("commit: %s waiting, %s running" % (nWaiting,nRunning))

        # launch jobs, if available, and if spare slots
        while len(jobsRunning) &lt; maxJobs and jobsWaiting:

            rec = jobsWaiting.pop(0)

            # if record has data, insert it, otherwise take as done            
            if rec.hasdata:
                uri = rec.uri
                if not uri:
                    uri = "CHK@somefile" + os.path.splitext(rec.path)[1]
                job = node.put(uri, data=rec.data, async=True)
                rec.job = job
                jobsRunning.append(rec)
            else:
                # record should already have the hash, uri, mimetype
                jobsDone.append(rec)

        # check running jobs
        for rec in jobsRunning:
            if rec == manifestJob:
                job = rec
            else:
                job = rec.job

            if job.isComplete():
                jobsRunning.remove(rec)

                uri = job.wait()

                if job != manifestJob:
                    rec.uri = uri
                    rec.job = None
                    jobsDone.append(rec)

        # breathe!!
        if jobsRunning:
            time.sleep(5)
        else:
            time.sleep(1)

    manifestUri = manifestJob.wait()
    self.log("commitDisk: done, manifestUri=%s" % manifestUri)

    #pubKeyFile.data = manifestJob.uri

    endTime = time.time()
    commitTime = endTime - startTime

    self.log("commitDisk: commit completed in %s seconds" % commitTime)

    return manifestUri

</t>
<t tx="aum.20060530151504">def addDisk(self, name, uri, passwd):
    """
    Adds (mounts) a freedisk within freenetfs
    
    Arguments:
        - name - name of disk - will be mounted in as /usr/&lt;name&gt;
        - uri - a public or private SSK key URI. Parsing of the key will
          reveal whether it's public or private. If public, the freedisk
          will be mounted read-only. If private, the freedisk will be
          mounted read/write
        - passwd - the encryption password for the disk, or empty string
          if the disk is to be unencrypted
    """
    print "addDisk: name=%s uri=%s passwd=%s" % (name, uri, passwd)

    diskPath = "/usr/" + name
    rec = self.addToCache(path=diskPath, isdir=True, perm=0755, canwrite=True)
    disk = Freedisk(rec)
    self.freedisks[name] = disk

    if uriIsPrivate(uri):
        privKey = uri
        pubKey = None
    else:
        privKey = None
        pubKey = uri
    
    disk.privKey = privKey
    disk.pubKey = pubKey

    #print "addDisk: done"

</t>
<t tx="aum.20060530160322">def removeDirAndContents(path):
    
    files = os.listdir(path)
    
    for f in files:
        fpath = os.path.join(path, f)
        if os.path.isfile(fpath):
            os.unlink(fpath)
        elif os.path.isdir(fpath):
            removeDirAndContents(fpath)
    os.rmdir(path)

</t>
<t tx="aum.20060530170840">@first #! /usr/bin/env python
@language python
@others
</t>
<t tx="aum.20060530170840.1">@first #! /usr/bin/env python
@language python
@others

</t>
<t tx="aum.20060530202714">class FreediskMgr:
    """
    Gateway for mirroring a local directory to/from freenet
    """
    @others

</t>
<t tx="aum.20060530202714.1">def __init__(self, **kw):
    """
    Creates a freediskmgr object
    
    Keywords:
        - name - mandatory - the name of the disk
        - fcpNode - mandatory - an FCPNode instance
        - root - mandatory - the root directory
        - publicKey - the freenet public key URI
        - privateKey - the freenet private key URI
    Notes:
        - exactly one of publicKey, privateKey keywords must be given
    """

</t>
<t tx="aum.20060530202714.2">def update(self):
    """
    Update from freenet to local directory
    """

</t>
<t tx="aum.20060530202714.3">def commit(self):
    """
    commit from local directory into freenet
    """

</t>
<t tx="aum.20060530234330">def setupFreedisks(self):
    """
    Initialises the freedisks
    """
    self.freedisks = {}

</t>
<t tx="aum.20060530234330.1">def getManifest(self, name):
    """
    Retrieves the manifest of a given disk
    """
</t>
<t tx="aum.20060530234330.2">def putManifest(self, name):
    """
    Inserts a freedisk manifest into freenet
    """
</t>
<t tx="aum.20060531160838">def status(msg):
    sys.stdout.write(msg + "...")
    time.sleep(1)
    print


</t>
<t tx="aum.20060601233442"># default attribs, can be overwritten by constructor keywords
haschanged = False
hasdata = False
canwrite = False
iswriting = False
uri = None

</t>
<t tx="aum.20060602094531"></t>
<t tx="aum.20060602094531.1"></t>
<t tx="aum.20060602094531.2">@first #! /usr/bin/env python
"""
Small script to test freedisk
"""
import sys, os, time

mountpoint = "/mnt/freenet"

diskName = "fred"

def sh(cmd):
    print "Executing: %s" % cmd
    os.system(cmd)
    time.sleep(0.5)

def mkfile(name):
    path = os.path.join(mountpoint, "usr", diskName, name)
    parent = os.path.split(path)[0]
    if not os.path.isdir(parent):
        os.makedirs(parent)
    f = file(path, "w")
    f.write(str(time.time()))
    f.close()

sh("freedisk start")
sh("freedisk new fred")

mkfile("file1.txt")
mkfile("file2.html")
mkfile("dir1/file3.txt")
mkfile("dir1/file4.txt")
mkfile("dir2/file5.txt")
mkfile("dir3/file6.txt")
mkfile("dir3/dir4/file7.txt")
time.sleep(1)
sh("freedisk commit fred")

</t>
<t tx="aum.20060603100604">def encrypt(passwd, s):

    passwd = sha.new(passwd).digest()

    if SSLCrypto:
        # encrypt with blowfish 256, key=sha(password), IV=00000000
        return SSLCrypto.blowfish(passwd).encrypt(s)
    else:
        # no encyrption available, return plaintext
        return s

</t>
<t tx="aum.20060603100604.1">def decrypt(passwd, s):

    passwd = sha.new(passwd).digest()

    if SSLCrypto:
        # decrypt with blowfish 256, key=sha(password), IV=00000000
        return SSLCrypto.blowfish(passwd).decrypt(s)
    else:
        # no encyrption available, return plaintext
        return s

</t>
<t tx="aum.20060603100604.2">def getpasswd(prompt="Password", confirm=False):

    if not confirm:
        return getpass.getpass(prompt+": ").strip()

    while 1:
        passwd = getpass.getpass(prompt+": ").strip()
        if passwd:
            passwd1 = getpasswd("Verify password").strip()
            if passwd == passwd1:
                break
            print "passwords do not match, please try again"
        else:
            break

    return passwd

</t>
<t tx="aum.20060603114247">def cmd_init(self, *args):

    conf = self.conf

    # initialise/change freedisk config
    
    print "Freedisk configuration"
    print
    print "Your freedisk config will normally be stored in the file:"
    print "  %s" % self.configFile
    
    # allow password change
    if conf.passwd:
        # got a password already
        prmt = "Do you wish to change your config password"
    else:
        # new password
        prmt = "Do you wish to encrypt this file"
    if getyesno(prmt):
        passwd = getpasswd("New Password", True)
        conf.setPassword(passwd)
        print "Password successfully changed"
    
    # host parms
    fcpHost = raw_input("Freenet FCP Hostname: [%s] " % conf.fcpHost).strip()
    if fcpHost:
        conf.fcpHost = fcpHost
    
    fcpPort = raw_input("Freenet FCP Port: [%s] "%  conf.fcpPort).strip()
    if fcpPort:
        conf.fcpPort = fcpPort
    
    print "Freenet verbosity:"
    print "  (0=SILENT, 1=FATAL, 2=CRITICAL, 3=ERROR"
    print "   4=INFO, 5=DETAIL, 6=DEBUG)"
    v = raw_input("[%s] " % conf.fcpVerbosity).strip()
    if v:
        conf.fcpVerbosity = v
    
    while 1:
        m = raw_input("Mountpoint [%s] " % conf.mountpoint).strip() \
            or conf.mountpoint
        if m:
            if not os.path.isdir(m):
                print "No such directory '%s'" % m
            elif not os.path.exists(m):
                print "%s is not a directory" % m
            else:
                conf.mountpoint = m
                mountpoint = m
                break
    
    print "Freedisk configuration successfully changed"
    
</t>
<t tx="aum.20060603114446">class FreediskMgr:
    """
    Freedisk manager class
    """
    @others

</t>
<t tx="aum.20060603121718">class FreediskConfig:
    """
    allows for loading/saving/changing freedisk configs
    """
    @others

</t>
<t tx="aum.20060603121718.1">def __init__(self, path, passwd=None):
    """
    Create a config object from file at 'path', if it exists
    """
    #print "FreediskConfig: path=%s" % path

    self.path = path
    self.passwd = passwd
    
    if os.path.isfile(path):
        self.load()
    else:
        self.create()

    self.root = self.xml.root

</t>
<t tx="aum.20060603121848">def load(self):
    """
    Loads config from self.config
    """
    # get the raw xml, plain or encrypted
    ciphertext = file(self.path, "rb").read()

    plaintext = ciphertext

    # try to wrap into xml object
    try:
        xml = self.xml = XMLFile(raw=plaintext)
    except:
        i = 0
        while i &lt; 3:
            passwd = self.passwd = getpasswd("Freedisk config password")
            plaintext = decrypt(self.passwd, ciphertext)
            try:
                xml = XMLFile(raw=plaintext)
                break
            except:
                i += 1
                continue
        if i == 3:
            self.abort()

    self.xml = xml
    self.root = xml.root

</t>
<t tx="aum.20060603122324">def create(self):
    """
    Creates a new config object
    """
    self.xml = XMLFile(root="freedisk")
    root = self.root = self.xml.root

    self.fcpHost = fcp.node.defaultFCPHost
    self.fcpPort = fcp.node.defaultFCPPort
    self.fcpVerbosity = fcp.node.defaultVerbosity
    self.mountpoint = defaultMountpoint

    self.save()

</t>
<t tx="aum.20060603125105">_intAttribs = ["fcpPort", "fcpVerbosity"]

_strAttribs = ["fcpHost", "mountpoint"]

</t>
<t tx="aum.20060603125405">def __getattr__(self, attr):
    
    if attr in self._intAttribs:
        try:
            return int(getattr(self.root, attr))
        except:
            raise AttributeError(attr)

    elif attr in self._strAttribs:
        try:
            return str(getattr(self.root, attr))
        except:
            raise AttributeError(attr)

    else:
        raise AttributeError(attr)

</t>
<t tx="aum.20060603125405.1">def __setattr__(self, attr, val):
    
    if attr in self._intAttribs:
        val = str(val)
        setattr(self.root, attr, val)
        self.save()
    elif attr in self._strAttribs:
        setattr(self.root, attr, val)
        self.save()
    else:
        self.__dict__[attr] = val

</t>
<t tx="aum.20060603125812">def ipython(o=None):

    from IPython.Shell import IPShellEmbed

    ipshell = IPShellEmbed()

    ipshell() # this call anywhere in your program will start IPython 

</t>
<t tx="aum.20060603125848">def save(self):

    plain = self.xml.toxml()

    if self.passwd:
        cipher = encrypt(self.passwd, plain)
    else:
        cipher = plain
    
    f = file(self.path, "wb")
    f.write(cipher)
    f.flush()
    f.close()

</t>
<t tx="aum.20060603131227">def setPassword(self, passwd):
    
    self.passwd = passwd
    self.save()

</t>
<t tx="aum.20060603132247">def getyesno(prmt, dflt=True):
    
    if dflt:
        ynprmt = "[Y/n] "
    else:
        ynprmt = "[y/N] "

    resp = raw_input(prmt + "? " + ynprmt).strip()
    if not resp:
        return dflt
    resp = resp.lower()[0]
    return resp == 'y'

</t>
<t tx="aum.20060603132557">def abort(self):

    print "freedisk: Cannot decrypt freedisk config file '%s'" % self.path
    print
    print "If you truly can't remember the password, your only"
    print "option now is to delete the config file and start again"
    sys.exit(1)

</t>
<t tx="aum.20060603153411">def _getChild(self, name):
    """
    Returns a list of zero or more child nodes whose
    tag name is &lt;name&gt;
    """
    try:
        item = getattr(self, name)
    except AttributeError:
        return []
    
    if not isinstance(item, list):
        item = [item]
    
    return item

</t>
<t tx="aum.20060603154804">def addDisk(self, name, uri, passwd):

    d = self.getDisk(name)
    if isinstance(d, XMLNode):
        raise Exception("Disk '%s' already exists" % name)
    
    diskNode = self.root._addNode("disk")
    diskNode.name = name
    diskNode.uri = uri
    diskNode.passwd = passwd
    
    self.save()

</t>
<t tx="aum.20060603155318">def getDisk(self, name):
    """
    Returns a record for a freedisk of name &lt;name&gt;
    """
    disks = self.root._getChild("disk")
    
    for d in disks:
        if d.name == name:
            return d
    
    return None

</t>
<t tx="aum.20060603155642">def delDisk(self, name):
    """
    Removes disk of given name
    """
    d = self.getDisk(name)
    if not isinstance(d, XMLNode):
        raise Exception("No such freedisk '%s'" % name)
    
    self.root._delChild(d)

    self.save()

</t>
<t tx="aum.20060603160206">def _delChild(self, child):
    """
    Removes given child node
    """
    node = self
    while True:
        print "Trying to remove %s from %s" % (child, node)
        if child in node._children:
            print "removing"
            node._children.remove(child)
            node._node.removeChild(child._node)
    
        for k,v in node._childrenByName.items():
            if child == v:
                del node._childrenByName[k]
            elif isinstance(v, list):
                if child in v:
                    v.remove(child)
        
        if isinstance(node, XMLFile):
            break
        
        node = node._parent

</t>
<t tx="aum.20060603162815">def getDisks(self):
    """
    Returns all freedisk records
    """
    return self.root._getChild("disk")

</t>
<t tx="aum.20060603164555">def cmd_list(self, *args):
    """
    Produces a list of mounted freedisks
    """
    conf = self.conf

    disks = conf.getDisks()
    
    if disks:
        print "Currently mounted freedisks:"
        for d in disks:
            print "  %s:" % d.name
            print "    uri=%s" % d.uri
            print "    passwd=%s" % d.passwd
    else:
        print "No freedisks mounted"
    
</t>
<t tx="aum.20060603170554">def uriIsPrivate(uri):
    """
    analyses an SSK URI, and determines if it is an SSK or USK private key
    """
    if uri.startswith("freenet:"):
        uri = uri[8:]
    
    if not (uri.startswith("SSK@") or uri.startswith("USK@")):
        return False
    
    # rip off any path stuff
    uri = uri.split("/")[0]

    # blunt rule of thumb - 2 commas is pubkey, 1 is privkey
    if len(uri.split(",")) == 2:
        return True
    
    return False

</t>
<t tx="aum.20060603231840"># functions to encode/decode base64, freenet alphabet
@others

</t>
<t tx="aum.20060603231840.1">def base64encode(raw):
    """
    Encodes a string to base64, using the Freenet alphabet
    """
    # encode using standard RFC1521 base64
    enc = base64.encodestring(raw)
    
    # convert the characters to freenet encoding scheme
    enc = enc.replace("+", "~")
    enc = enc.replace("/", "-")
    enc = enc.replace("=", "_")
    enc = enc.replace("\n", "")

    return enc

</t>
<t tx="aum.20060603231840.2">def base64decode(enc):
    """
    Decodes a freenet-encoded base64 string back to a binary string

    Arguments:
     - enc - base64 string to decode
    """
    # convert from Freenet alphabet to RFC1521 format
    enc = enc.replace("~", "+")
    enc = enc.replace("-", "/")
    enc = enc.replace("_", "=")

    # now ready to decode
    raw = base64.decodestring(enc)

    return raw

</t>
<t tx="aum.20060604143559"># a command has been encoded via base64

cmdBase64 = path.split("/cmds/", 1)[-1]

cmd = base64decode(cmdBase64)

result = self.executeCommand(cmd)

rec = self.addToCache(path=path, isreg=True, data=result, perm=0644)

</t>
<t tx="aum.20060604143852">def doFsCommand(self, cmd):
    """
    Executes a command via base64-encoded file
    """
    cmdBase64 = fcp.node.base64encode(cmd)
    if len(cmdBase64) &gt; 254:
        raise Exception("Command too long")

    path = self.conf.mountpoint + "/cmds/" + cmdBase64
    return file(path).read()

</t>
<t tx="aum.20060604144241">def cmd_cmd(self, *args):

    # arbitrary command, for testing
    cmd = args[0] + "|".join(args[1:])
    print repr(self.doFsCommand(cmd))

</t>
<t tx="aum.20060604194409">def __init__(self, *args, **kw):

    self.args = args
    self.kw = kw

    configFile = self.configFile = kw['configFile']
    conf = self.conf = FreediskConfig(configFile)
    #ipython(conf)


    # validate args
    nargs = len(args)
    if nargs == 0:
        usage("No command given")

    cmd = self.cmd = args[0]
    
    # barf if not 'init' and no config
    if cmd != 'init' and not os.path.isfile(configFile):
        usage("Config file %s does not exist\nRun '%s init' to create it" % (
            configFile, progname))
    
    # validate args count for cmds needing diskname arg
    if cmd in ['new', 'add', 'del', 'update', 'commit']:
        if nargs &lt; 2:
            usage("%s: Missing argument &lt;freediskname&gt;" % cmd)
        diskname = self.diskname = args[1]
    
        # get paths to freedisk dir and pseudo-files
        self.diskPath = os.path.join(conf.mountpoint, "usr", diskname)
        self.pubKeyPath = os.path.join(self.diskPath, ".publickey")
        self.privKeyPath = os.path.join(self.diskPath, ".privatekey")
        self.passwdPath = os.path.join(self.diskPath, ".passwd")
        self.cmdPath = os.path.join(self.diskPath, ".cmd")
        self.statusPath = os.path.join(self.diskPath, ".status")

    # implement command synonyms
    self.cmd_setup = self.cmd_init
    self.cmd_mount = self.cmd_start
    self.cmd_unmoutn = self.cmd_umount = self.cmd_stop

</t>
<t tx="aum.20060604194834">def run(self):
    """
    Executes the given command
    """
    cmd = self.cmd
    method = getattr(self, "cmd_"+cmd, None)
    if not method:
        usage("Unrecognised command '%s'" % cmd)
    
    result = method(*self.args[1:]) or ""

    return result

</t>
<t tx="aum.20060604200719">mgr = FreediskMgr(*args, **opts)

print mgr.run()

</t>
<t tx="aum.20060604204143">def waitTillReqSent(self):
    """
    Waits till the request has been sent to node
    """
    self.reqSentLock.acquire()

</t>
<t tx="aum.20060604210617">def executeCommand(self, cmd):
    """
    Executes a single-line command that was submitted as
    a base64-encoded filename in /cmds/
    """
    self.log("executeCommand:cmd=%s" % repr(cmd))

    try:
        cmd, args = cmd.split(" ", 1)
        args = args.split("|")
    except:
        return "error\nInvalid command %s" % repr(cmd)

    method = getattr(self, "cmd_"+cmd, None)
    if method:
        return method(*args)
    else:
        return "error\nUnrecognised command %s" % repr(cmd)

</t>
<t tx="aum.20060604212311"># methods which handle filesystem commands

@others

</t>
<t tx="aum.20060604212311.1">def cmd_hello(self, *args):
    
    return "ok\nhello: args=%s" % repr(args)

</t>
<t tx="aum.20060604212812">class Freedisk:
    """
    Encapsulates a freedisk
    """
    @others

</t>
<t tx="aum.20060604212812.1">def __init__(self, rootrec):
    
    self.root = rootrec

</t>
<t tx="aum.20060604213643">def cmd_mount(self, *args):
    """
    tries to mount a freedisk
    
    arguments:
        - diskname
        - uri (may be public or private)
        - password
    """
    #print "mount: args=%s" % repr(args)

    try:
        name, uri, passwd = args
    except:
        return "error\nmount: invalid arguments %s" % repr(args)

    try:
        self.addDisk(name, uri, passwd)
    except:
        return "error\nmount: failed to mount disk %s" % name

    return "ok\nmount: successfully mounted disk %s" % name

</t>
<t tx="aum.20060604223923">def cmd_umount(self, *args):
    """
    tries to unmount a freedisk
    
    arguments:
        - diskname
    """
    #print "mount: args=%s" % repr(args)

    try:
        name = args[0]
    except:
        return "error\numount: invalid arguments %s" % repr(args)

    try:
        self.delDisk(name)
    except:
        traceback.print_exc()
        return "error\numount: failed to unmount freedisk '%s'" % name
    
    return "ok\numount: successfully unmounted freedisk %s" % name

</t>
<t tx="aum.20060604223923.1">def cmd_update(self, *args):
    """
    Does an update of a freedisk from freenet
    """
    #print "update: args=%s" % repr(args)

    try:
        name = args[0]
    except:
        return "error\nupdate: invalid arguments %s" % repr(args)

    try:
        self.updateDisk(name)
    except:
        traceback.print_exc()
        return "error\nupdate: failed to update freedisk '%s'" % name
    
    return "ok\nupdate: successfully updated freedisk '%s'" % name

</t>
<t tx="aum.20060604223923.2">def cmd_commit(self, *args):
    """
    Does an commit of a freedisk into freenet
    """
    try:
        name = args[0]
    except:
        return "error\ninvalid arguments %s" % repr(args)

    try:
        uri = self.commitDisk(name)
    except:
        traceback.print_exc()
        return "error\nfailed to commit freedisk '%s'" % name
    
    return "ok\n%s" % uri

</t>
<t tx="aum.20060606204304"># utility methods

@others

</t>
<t tx="aum.20060606204304.1"># deprecated methods

@others

</t>
<t tx="aum.20060606204304.2">class FreenetFuseFS(FreenetBaseFS):
    """
    Interfaces with FUSE
    """
    @others
</t>
<t tx="aum.20060606204304.3">_attrs = ['getattr', 'readlink', 'getdir', 'mknod', 'mkdir',
      'unlink', 'rmdir', 'symlink', 'rename', 'link', 'chmod',
      'chown', 'truncate', 'utime', 'open', 'read', 'write', 'release',
      'statfs', 'fsync']

</t>
<t tx="aum.20060606232825">def tickThread(self, *args, **kw):
    
    print "tickThread: starting"
    i = 0
    while True:
        print "tickThread: n=%s" % i
        time.sleep(10)
        i += 1

</t>
<t tx="aum.20060607085345">noCloseSocket = True

</t>
<t tx="aum.20060607092808">def cmd_run(self, *args):
    """
    become the foreground FUSE process.
    
    This is launched by 'freedisk start'
    """
    conf = self.conf
    kw = self.kw

    print "Creating freenetfs filesystem..."
    fs = freenetfs.FreenetFuseFS(
            conf.mountpoint,
            fcpHost=conf.fcpHost,
            fcpPort=conf.fcpPort,
            verbosity=conf.fcpVerbosity,
            debug=kw['debug'],
            multithreaded=kw['multithreaded'],
            )

    # never returns, until fs is unmounted
    print "Freenetfs filesystem now alive..."
    fs.run()

</t>
</tnodes>
</leo_file>
